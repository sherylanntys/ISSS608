[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "",
    "text": "```"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! I’m Sheryl. In this webpage, you will find my learning journey and deliverables for ISSS608 Visual Analytics and Applications."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using the read_csv() function of the readr package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere data set contains seven attributes:\n\nCategorical Attributes: ID, CLASS, GENDER and RACE. These columns are denoted as chr (“character type”).\nContinuous Attributes: ENGLISH, MATHS, and SCIENCE. These columns are stored as dbl (“double type”), i.e. numeric values."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#loading-the-required-libraries",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#loading-the-required-libraries",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "",
    "text": "pacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#importing-data",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "Importing Data",
    "text": "Importing Data\nThe code chunk below imports exam_data.csv into R environment by using the read_csv() function of the readr package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere data set contains seven attributes:\n\nCategorical Attributes: ID, CLASS, GENDER and RACE. These columns are denoted as chr (“character type”).\nContinuous Attributes: ENGLISH, MATHS, and SCIENCE. These columns are stored as dbl (“double type”), i.e. numeric values."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs.-ggplot",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs.-ggplot",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "R Graphics vs. ggplot",
    "text": "R Graphics vs. ggplot\nThe tabset below compares how R Graphics and ggplot plot a simple histogram:\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths Scores\")\n\n\n\n\n\n\n\n\n\n\n\n\nSide Note: Attempting to Customise the R Graphics Histogram\nThe code chunk below customises the R Graphics histogram so that it’s similar to the ggplot2 histogram.\n\nhist(exam_data$MATHS, \n     breaks = 20,                     \n     col = \"grey\",                \n     border = \"black\",                 \n     main = \"Distribution of Maths Scores\",  \n     xlab = \"MATHS\",            \n     ylab = \"Count\")               \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter plotting the histograms using both R Graphics and ggplot2, I noted the following:\n\nX-Axis Labels: R Graphics automatically labels the x-axis with the column reference (“exam_data$MATHS”). This reduces the plot’s readability and interpretability as it directly reflects the code rather than a clear, descriptive label. On the other hand, ggplot2 retains the column name (”MATHS”) as the x-axis label, providing a more intuitive presentation by default.\nLayers: ggplot2 uses a layered approach, where data, aesthetics and geometric objects are added step-by-step using +."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "3.0 Essential Grammatical Elements in ggplot2: Data",
    "text": "3.0 Essential Grammatical Elements in ggplot2: Data\nThe code chunk below is used to call the ggplot() function.\n\nggplot(data=exam_data)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetics-mappings",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetics-mappings",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "4.0 Essential Grammatical Elements in ggplot2: Aesthetics Mappings",
    "text": "4.0 Essential Grammatical Elements in ggplot2: Aesthetics Mappings\nThe aesthetic mappings take attributes of the data and use them to influence visual characteristics. Each visual characteristics can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call.\n\nggplot(data=exam_data, aes(x=MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOther aesthetic mappings include - x, y, color, size, shape, alpha (transparency)."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "5.0 Essential Grammatical Elements in ggplot2: geom",
    "text": "5.0 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom.\n\n5.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart using geom_bar():\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n5.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe y-scale is misleading.\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n5.3 Geometric Objects: geom_histogram\nThe code chunk below uses geom_histogram() to create a simple histogram.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()  \n\n\n\n\n\n\n\n\n\n\n5.4 Modifying a Geometric Object by Changing geom\nIn the code chunk below:\n\nbins is used to change the number of bins to 20\nfill is used to shade the histogram with light blue\ncolor is used to change the outline colour of the bars in black.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n5.5 Modifying a Geometric Object by Changing aes( )\nThe code chunk below changes the interior colour of the histogram by using sub-group of aes():\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n5.6 Geometric Objects: geom_density\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n5.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGenerally, the notches serve as a visual indicator of the confidence interval around the median.\nNotched Box Plots are particularly useful in assessing whether the medians are meaningfully different across groups.\n\n\n\n\n5.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe shape of the violin represents the density of the data at different values. Wider sections indicate higher data concentration.\nSome factors to consider when interpreting violin plots include the shape of the violin (width, number of peaks, etc.) and its symmetry. Symmetry represents the skewness of the data.\n\n\n\n\n5.9 Geometric Objects: geom_point\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n5.10 Geom Objects can be Combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "6.0 Essential Grammatical Elements in ggplot2: stat",
    "text": "6.0 Essential Grammatical Elements in ggplot2: stat\n\n6.1 Working with stat( )\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n6.2 Working with stat - the stat_summary( ) Method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n6.3 Working with stat - the geom( ) Method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n6.4 Adding a Best Fit Curve on a Scatterplot\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\nThe default method used is loess. The default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "7.0 Essential Grammatical Elements in ggplot2: Facets",
    "text": "7.0 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables.\n\n7.1 Working with facet_wrap\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n7.2 facet_grid() Function\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "8.0 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "8.0 Essential Grammatical Elements in ggplot2: Coordinates\n\n8.1 Working with Coordinates\nBy default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nHowever, you can flip the bar chart into a horizontal bar chart.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n8.2 Changing the y- and x-axis Range\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\nFixing both y-axis and x-axis range from 0 to 100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-theme",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-theme",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "9.0 Essential Grammatical Elements in ggplot2: Theme",
    "text": "9.0 Essential Grammatical Elements in ggplot2: Theme\nThemes control elements of the graph not related to the data,\n\n9.1 Working with theme\n\ntheme_gray()theme_classic()theme_minimal()\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html",
    "href": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html",
    "title": "Hands-on Exercise 00: Working with tidyverse",
    "section": "",
    "text": "Loading tidyverse onto the R environment by using the code chunk below:\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#getting-started",
    "href": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#getting-started",
    "title": "Hands-on Exercise 00: Working with tidyverse",
    "section": "",
    "text": "Loading tidyverse onto the R environment by using the code chunk below:\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#importing-data",
    "title": "Hands-on Exercise 00: Working with tidyverse",
    "section": "Importing Data",
    "text": "Importing Data\nThe code chunk below uses read_csv() of readr to import REALIS2019.csv into the R environment as a tibble data frame.\n\nrealis2019 &lt;- read_csv(\"data/REALIS2019.csv\")\n\n\npopdata_fat &lt;- read_csv(\"data/PopData2019_fat.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#pivoting-data",
    "href": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#pivoting-data",
    "title": "Hands-on Exercise 00: Working with tidyverse",
    "section": "Pivoting Data",
    "text": "Pivoting Data\n\npopdata_long &lt;- popdata_fat %&gt;%\n  pivot_longer(c(3:21),\n               names_to = \"Age Group\",\n               values_to = \"Population\")\n\n\nwrite_rds(popdata_long,\"rds/popdata_long.rds\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#working-with-dplyr",
    "href": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#working-with-dplyr",
    "title": "Hands-on Exercise 00: Working with tidyverse",
    "section": "Working with dplyr",
    "text": "Working with dplyr\n\nrealis2019_selected &lt;- realis2019 %&gt;%\n  select('Project Name',\n         'Transacted Price ($)',\n         'Type of Sale',\n         'Unit Price ($ psm)',\n         'Property Type')\nrealis2019_selected\n\n# A tibble: 19,515 × 5\n   `Project Name`     `Transacted Price ($)` `Type of Sale` `Unit Price ($ psm)`\n   &lt;chr&gt;                               &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n 1 PEIRCE VIEW                        840000 Resale                         7434\n 2 FLORIDA PARK                      3040000 Resale                         9737\n 3 BULLION PARK                       860000 Resale                        11467\n 4 CASTLE GREEN                      1000000 Resale                         9346\n 5 HAPPY ESTATE                      7000000 Resale                        10183\n 6 TEACHER'S HOUSING…                2880000 Resale                        12659\n 7 THE PANORAMA                      1510000 Resale                        16064\n 8 THE PANORAMA                       710000 Resale                        16905\n 9 CHIP THYE GARDEN                  2800000 Resale                        13500\n10 TEACHER'S HOUSING…                2300000 Resale                         9935\n# ℹ 19,505 more rows\n# ℹ 1 more variable: `Property Type` &lt;chr&gt;\n\n\nTake note that only the first ten results of a tibble data frame would be displayed."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#working-with-filter-of-dplyr",
    "href": "Hands-on Exercise/Hands-on_Ex00/Hands-on_Ex00.html#working-with-filter-of-dplyr",
    "title": "Hands-on Exercise 00: Working with tidyverse",
    "section": "Working with filter() of dplyr",
    "text": "Working with filter() of dplyr\n\nrealis2019_filtered &lt;- realis2019_selected %&gt;%\n  filter(`Property Type` == \"Condominium\" |\n           `Property Type` == \"Apartment\") %&gt;%\n  filter(`Type of Sale` == \"New Sale\") %&gt;%\n  filter(`Unit Price ($ psm)` &lt;= 13000)\n\nrealis2019_filtered\n\n# A tibble: 87 × 5\n   `Project Name`     `Transacted Price ($)` `Type of Sale` `Unit Price ($ psm)`\n   &lt;chr&gt;                               &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n 1 RIVERFRONT RESIDE…                1029000 New Sale                      12863\n 2 RIVERFRONT RESIDE…                 871000 New Sale                      12809\n 3 RIVERFRONT RESIDE…                1940000 New Sale                      12848\n 4 RIVERFRONT RESIDE…                1030000 New Sale                      12875\n 5 RIVERFRONT RESIDE…                2061000 New Sale                      12962\n 6 RIVERFRONT RESIDE…                 762000 New Sale                      12915\n 7 RIVERFRONT RESIDE…                1001000 New Sale                      12513\n 8 RIVERFRONT RESIDE…                1271000 New Sale                      12838\n 9 RIVERFRONT RESIDE…                1310000 New Sale                      12970\n10 RIVERFRONT RESIDE…                1339000 New Sale                      13000\n# ℹ 77 more rows\n# ℹ 1 more variable: `Property Type` &lt;chr&gt;\n\n\n\nPutting It All Together\nAlternatively, you can combine the select() and filter() functions together as shown in the code chunk below:\n\nrealis2019_filtered2 &lt;- realis2019 %&gt;%\n  select('Project Name',\n         'Transacted Price ($)',\n         'Type of Sale',\n         'Unit Price ($ psm)',\n         'Property Type') %&gt;%\n  filter(`Property Type` == \"Condominium\" |\n           `Property Type` == \"Apartment\") %&gt;%\n  filter(`Type of Sale` == \"New Sale\") %&gt;%\n  filter(`Unit Price ($ psm)` &lt;= 13000)\n\nrealis2019_filtered2\n\n# A tibble: 87 × 5\n   `Project Name`     `Transacted Price ($)` `Type of Sale` `Unit Price ($ psm)`\n   &lt;chr&gt;                               &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n 1 RIVERFRONT RESIDE…                1029000 New Sale                      12863\n 2 RIVERFRONT RESIDE…                 871000 New Sale                      12809\n 3 RIVERFRONT RESIDE…                1940000 New Sale                      12848\n 4 RIVERFRONT RESIDE…                1030000 New Sale                      12875\n 5 RIVERFRONT RESIDE…                2061000 New Sale                      12962\n 6 RIVERFRONT RESIDE…                 762000 New Sale                      12915\n 7 RIVERFRONT RESIDE…                1001000 New Sale                      12513\n 8 RIVERFRONT RESIDE…                1271000 New Sale                      12838\n 9 RIVERFRONT RESIDE…                1310000 New Sale                      12970\n10 RIVERFRONT RESIDE…                1339000 New Sale                      13000\n# ℹ 77 more rows\n# ℹ 1 more variable: `Property Type` &lt;chr&gt;"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using the read_csv() function of the readr package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere data set contains seven attributes:\n\nCategorical Attributes: ID, CLASS, GENDER and RACE. These columns are denoted as chr (“character type”).\nContinuous Attributes: ENGLISH, MATHS, and SCIENCE. These columns are stored as dbl (“double type”), i.e. numeric values."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "2.0 Introducing ggplot",
    "text": "2.0 Introducing ggplot\n\n2.1 R Graphics vs. ggplot\nThe tabset below compares how R Graphics and ggplot plot a simple histogram:\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths Scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.1 Side Note: Attempting to Customise the R Graphics Histogram\nThe code chunk below customises the R Graphics histogram so that it’s similar to the ggplot2 histogram.\n\nhist(exam_data$MATHS, \n     breaks = 20,                     \n     col = \"grey\",                \n     border = \"black\",                 \n     main = \"Distribution of Maths Scores\",  \n     xlab = \"MATHS\",            \n     ylab = \"Count\")               \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter plotting the histograms using both R Graphics and ggplot2, I noted the following:\n\nX-Axis Labels: R Graphics automatically labels the x-axis with the column reference (“exam_data$MATHS”). This reduces the plot’s readability and interpretability as it directly reflects the code rather than a clear, descriptive label. On the other hand, ggplot2 retains the column name (”MATHS”) as the x-axis label, providing a more intuitive presentation by default.\nLayers: ggplot2 uses a layered approach, where data, aesthetics and geometric objects are added step-by-step using +."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on Exercise/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 Methods",
    "section": "10.0 Reference",
    "text": "10.0 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "index.html#latest-posts",
    "href": "index.html#latest-posts",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "Latest Posts",
    "text": "Latest Posts\n\n\n\n\n\n\n\n\nHands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8.3: Analytical Mapping\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8.2: Visualising Geospatial Point Data\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "The following R packages will be used:\n\nggrepel: Provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: Provides extra themes, geoms and scales for ggplot2.\nhrbrthemes: Provides typography-centric themes and theme components for ggplot2.\npatchwork: Prepares composite figure created using ggplot2.\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "The following R packages will be used:\n\nggrepel: Provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: Provides extra themes, geoms and scales for ggplot2.\nhrbrthemes: Provides typography-centric themes and theme components for ggplot2.\npatchwork: Prepares composite figure created using ggplot2.\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel.",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel.",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.1 Working with ggrepel.",
    "text": "2.1 Working with ggrepel.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ngeom_label_repel(aes(label = ID), fontface = “bold”): Replaces geom_label to dynamically adjust label positions and prevent overlapping.\nThe density of points in certain regions of the graph may lead to labels being omitted.\n\n\n\n2.1.1 Exploring Other Arguments in geom_label_repel\nA list of arguments that can be used with geom_label_repel() can be found here."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#max.overlaps",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#max.overlaps",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "max.overlaps",
    "text": "max.overlaps\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\",\n                   max.overlaps=20) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nmax.overlaps\nBy default, geom_label_repel exclude text labels when they overlap too many other labels. The default is 10. Increasing the max.overlaps argument would increase the number of labels displayed in the graph."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.1 Working with ggrepel",
    "text": "2.1 Working with ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ngeom_label_repel(aes(label = ID), fontface = \"bold\"): Replaces geom_label() to dynamically adjust label positions and prevent overlapping.\nThe density of points in certain regions of the graph may lead to labels being omitted.\n\n\n\n2.1.1 Exploring Other Arguments in geom_label_repel\nA list of arguments that can be used with geom_label_repel() can be found here.\nmax.overlaps\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\",\n                   max.overlaps=20) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nmax.overlaps\nBy default, geom_label_repel exclude text labels when they overlap too many other labels. The default is 10. Increasing the max.overlaps argument would increase the number of labels displayed in the graph."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "3.1 Working with ggtheme Package",
    "text": "3.1 Working with ggtheme Package\nIn the example below, The Economist theme is used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "3.2 Working with hrbthems Package",
    "text": "3.2 Working with hrbthems Package\nThe hrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed, and fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\naxis_title_size: Adjust the font size of the axis title.\nbase_size: Adjust the font size of the axis labels.\ngrid: Remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-patchwork-methods",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-patchwork-methods",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "4.1 Creating Composite Graphics: patchwork Methods",
    "text": "4.1 Creating Composite Graphics: patchwork Methods\nGenerally syntax that can be used:\n\n+: Used to create a two-column layout\n( ): Used to create a subplot group.\n/: Used to create a two-row layout.\n\n\n4.1.1 Combining Two ggplot2 Graphs\n\nUsing +Using ()Using /\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n(p1 + p2)/p1\n\n\n\n\n\n\n\n\n\n\n\np1 / p3\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Combining Three ggplot2 Graphs\nThe following syntax can be used:\n\n/: Used to stack two graphs.\n|: Used to place the plots beside each other.\n( ): Used to define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\n4.1.3 Creating a Composite Figure with Tag\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nplot_annotation(): Adds annotations to the composite plot.\ntag_levels = 'I': Automatically tags each subplot with Roman numerals. Other options for tag_levels include: A, a, 1\n\n\n\n\n4.1.3.1 Other Arguments for plot_annotation()\nA list of arguments that can be used with plot_annotation() can be found here.\nUsing tag_prefix:\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = '1', tag_prefix=\"Figure \")\n\n\n\n\n\n\n\n\n\n\n\n4.1.4 Creating Figure with inset\ninset_element() of patchwork enables us to place several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n4.1.5 Creating a Composite Figure by Using patchwork and ggtheme\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\n\n\n\n\n\n4.1.6 Attempting to Modify the Plot in 4.1.5\nAs the plot title of p3 was cut off, with the titles of p2 overlapping p3, we will attempt to modify the plot by reducing the title size. At the same time, I will also try other themes.\n\nReducing the Title SizeUsing theme_wsj()\n\n\nAdding plot.title = element_text(size=10) will reduce the respective plots’ title size.\n\npatchwork & \n  theme_economist() & \n  theme(\n    plot.title = element_text(size = 9),        # Reduce plot title size\n    axis.text = element_text(size = 6),         # Reduce axis tick text size\n    axis.title = element_text(size = 6)         # Reduce axis labels size\n  )\n\n\n\n\n\n\n\n\n\n\n\npatchwork & \n  theme_wsj() & \n  theme(\n    plot.title = element_text(size = 8),        # Reduce plot title size\n    axis.text = element_text(size = 6),         # Reduce axis tick text size\n    axis.title = element_text(size = 6)         # Reduce axis labels size\n  )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#disclaimer",
    "href": "Hands-on Exercise/Hands-on_Ex02/Hands-on_Ex02.html#disclaimer",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.1 Disclaimer",
    "text": "5.1 Disclaimer\nThis document includes content written with the assistance of ChatGPT, which was used for grammar correction and the explanation of arguments for the various packages."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The following R packages would installed and loaded:\n\n\n\nR Package\nDescription\n\n\n\n\nggiraph\nMakes ggplot graphics interactive.\n\n\nplotly\nPlots interactive statistical graphs.\n\n\nDT\nCreates interactive tables on a html page.\n\n\ntidyverse\n\n\n\npatchwork\nCombines multiple ggplot2 graphs into one figure.\n\n\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\nThe code chunk below uses read_csv( ) to import the Exam_data.csv data file into R and save it as a tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The code chunk below uses read_csv( ) to import the Exam_data.csv data file into R and save it as a tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#tooltip-effect-with-tooltip-aesthetic",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#tooltip-effect-with-tooltip-aesthetic",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "2.1 Tooltip Effect with tooltip Aesthetic",
    "text": "2.1 Tooltip Effect with tooltip Aesthetic\nThe code chunk below plots an interactive statistical graph using the ggiraph package.\nThe code chunk consists of the following parts:\n\nGgplot object, and\ngirafe( ) of ggiraph will be used to create an interactive svg object.\n\ngeom_dotplot_interactive( ) will be used to create a basic graph while girafe( ) will be used to generate a svg object to be displayed on a html page.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.1 Displaying Multiple Information on tooltip",
    "text": "3.1 Displaying Multiple Information on tooltip\nThe code chunk below can be customised by including a list object:\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) # Modify the tooltip here.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#customising-tooltip-style",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#customising-tooltip-style",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.2 Customising tooltip Style",
    "text": "3.2 Customising tooltip Style\nopts_tooltip( ) of ggiraph customises tooltip rendering by adding CSS declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\n# CSS declarations in the code above.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#displaying-statistics-on-tooltip",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#displaying-statistics-on-tooltip",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.3 Displaying Statistics on tooltip",
    "text": "3.3 Displaying Statistics on tooltip\nThe code chunk below uses a function to compute 90% confidence interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.4 Hover Effect with data_id Aesthetic",
    "text": "3.4 Hover Effect with data_id Aesthetic\nElements associated with data_id will be highlighted upon mouse over. The default value of the hover css is hover_css=\"fill:orange;\".\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#styling-hover-effect",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#styling-hover-effect",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.5 Styling Hover Effect",
    "text": "3.5 Styling Hover Effect\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"), #  Highlighted elements in #202020 colour.\n    opts_hover_inv(css = \"opacity:0.2;\") # Non-highlighted elements would have lower opacity.\n  )                                        \n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#combining-tooltip-and-hover-effects",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#combining-tooltip-and-hover-effects",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.6 Combining tooltip and hover Effects",
    "text": "3.6 Combining tooltip and hover Effects\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#click-effect-with-onclick",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#click-effect-with-onclick",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.7 Click Effect with onclick",
    "text": "3.7 Click Effect with onclick\nThe data object would link to a web document, which would be displayed in a new window once clicked.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "3.8 Coordinated Multiple Views with ggiraph",
    "text": "3.8 Coordinated Multiple Views with ggiraph\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), # patchwork\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\nWhen a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\npatchwork will be used inside the girafe function to create the interactive coordinated multiple views."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "4.1 Creating an Interactive Scatter Plot: plot_ly( ) Method",
    "text": "4.1 Creating an Interactive Scatter Plot: plot_ly( ) Method\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#working-with-visual-variable-plot_ly-method",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#working-with-visual-variable-plot_ly-method",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "4.2 Working with Visual Variable: plot_ly( ) Method",
    "text": "4.2 Working with Visual Variable: plot_ly( ) Method\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatterplot-ggplotly-method",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatterplot-ggplotly-method",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "4.3 Creating an Interactive Scatterplot: ggplotly( ) Method",
    "text": "4.3 Creating an Interactive Scatterplot: ggplotly( ) Method\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-plotly",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-plotly",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "4.4 Coordinated Multiple Views with plotly",
    "text": "4.4 Coordinated Multiple Views with plotly\n\nhighlight_key( ) is used as shared data\nTwo scatterplots would be created via ggplot2\nsubplot( ) will be used to place them next to each other.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-table-dt-package",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-table-dt-package",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "5.1 Interactive Data Table: DT Package",
    "text": "5.1 Interactive Data Table: DT Package\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#linked-brushing-crosstalk-method",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#linked-brushing-crosstalk-method",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "5.2 Linked Brushing: crosstalk Method",
    "text": "5.2 Linked Brushing: crosstalk Method\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#disclaimer",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#disclaimer",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "7.1 Disclaimer",
    "text": "7.1 Disclaimer\nThis document includes content written with the assistance of ChatGPT, which was used for grammar correction and the explanation of arguments for the various packages."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#loading-the-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03.html#loading-the-r-packages",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The following R packages would installed and loaded:\n\n\n\nR Package\nDescription\n\n\n\n\nggiraph\nMakes ggplot graphics interactive.\n\n\nplotly\nPlots interactive statistical graphs.\n\n\nDT\nCreates interactive tables on a html page.\n\n\ntidyverse\n\n\n\npatchwork\nCombines multiple ggplot2 graphs into one figure.\n\n\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The following code chunk imports and loads the following R packages:\n\n\n\n\n\n\n\nR Package\nDescription\n\n\n\n\ngifski\nConverts image frames into high-quality GIF animations.\n\n\ngganimate\nA ggplot extension for creating animated statistical graphs.\n\n\ngapminder\nAn excerpt of the data available at Gapminder.org. The country_colors scheme will be used in this exercise.\n\n\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nThe following code chunk is used to import the Data worksheet from GlobalPopulation Excel workbook into R:\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\nmutate_each( ) of the dplyr package is used to convert all data type into factor. In R, a factor is a data type that is used to represent categorical data.\nHowever, mutate_each( ) and funs( ) were deprecated in dplyr 0.7.0 and dplyr 0.8.0 respectively. As such, the code chunk will be re-written using mutate_at( ).\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nAlternatively, across( ) can also be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#loading-the-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#loading-the-r-packages",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The following code chunk imports and loads the following R packages:\n\n\n\n\n\n\n\nR Package\nDescription\n\n\n\n\ngifski\nConverts image frames into high-quality GIF animations.\n\n\ngganimate\nA ggplot extension for creating animated statistical graphs.\n\n\ngapminder\nAn excerpt of the data available at Gapminder.org. The country_colors scheme will be used in this exercise.\n\n\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#importing-the-data",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#importing-the-data",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The following code chunk is used to import the Data worksheet from GlobalPopulation Excel workbook into R:\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\nmutate_each( ) of the dplyr package is used to convert all data type into factor. In R, a factor is a data type that is used to represent categorical data.\nHowever, mutate_each( ) and funs( ) were deprecated in dplyr 0.7.0 and dplyr 0.8.0 respectively. As such, the code chunk will be re-written using mutate_at( ).\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nAlternatively, across( ) can also be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-a-static-population-bubble-plot",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-a-static-population-bubble-plot",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "2.1 Building a Static Population Bubble Plot",
    "text": "2.1 Building a Static Population Bubble Plot\nThe code chunk below uses the basic ggplot2 functions to create a static bubble plot:\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-an-animated-bubble-plot",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-an-animated-bubble-plot",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "2.2 Building an Animated Bubble Plot",
    "text": "2.2 Building an Animated Bubble Plot\n\ntransition_time( ) is used to create the transition through distinct states of time.\nease_aes( ) is used to control the easing of aesthetics. The default is linear. Other methods include quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce. For example, cubic-in-out would start with the animation slowly easing in, speeding up in the middle and then slowly easing out.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "3.1 Building an Animated Bubble Plot: ggplotly( ) Method",
    "text": "3.1 Building an Animated Bubble Plot: ggplotly( ) Method\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\nThe animated bubble plot includes a play/pause button and a slider to control the animation.\nAlthough show.legend = FALSE was used, the legend still appears on the plot. Hence, theme(legend.position='none') will be used to replace the affected code chunk.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "3.2 Building an Animated Bubble Plot: plot_ly( ) Method",
    "text": "3.2 Building an Animated Bubble Plot: plot_ly( ) Method\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#disclaimer",
    "href": "Hands-on Exercise/Hands-on_Ex03/Hands-on_Ex03b.html#disclaimer",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "5.1 Disclaimer",
    "text": "5.1 Disclaimer\nThis document includes content written with the assistance of ChatGPT, which was used for grammar and code correction, and the explanation of arguments for the various packages."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "Welcome",
    "text": "Welcome\nHello and welcome to my webpage for ISSS608 Visual Analytics and Applications taught by Prof. Kam Tin Seong. Here, you'll find my coursework and projects for the module. Enjoy!"
  },
  {
    "objectID": "index.html#explore",
    "href": "index.html#explore",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "Explore",
    "text": "Explore"
  },
  {
    "objectID": "Hands-on_Ex_Landing.html",
    "href": "Hands-on_Ex_Landing.html",
    "title": "Hands-on Exercise Landing Page",
    "section": "",
    "text": "Sheryl Ann Tan Yi-Shi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nJan 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 18, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex_Landing.html#overview-of-hands-on-exercises",
    "href": "Hands-on_Ex_Landing.html#overview-of-hands-on-exercises",
    "title": "Hands-on Exercise Landing Page",
    "section": "",
    "text": "Sheryl Ann Tan Yi-Shi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nJan 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nJan 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nFeb 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSheryl Ann Tan Yi-Shi\n\n\nMar 18, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "Cardiovascular diseases, including heart attacks, are a leading cause of mortality worldwide. In recent years, Japan has experienced a steady increase in heart disease-related mortality, largely driven by its aging population, thus making it a growing public health concern (Ohira et al., 2023).\n\n\n\nThis exercise involves assuming the role of a graphical editor at an international media company that regularly publishes content on digital platforms. The company plans to release articles focused on one of the following themes:\n\nHeart Attack in Japan\nShip Performance in the Gulf of Guinea\n\nFor the purposes of this take-home exercise, the theme, Heart Attack in Japan, was selected for the preparation of data visualizations for the article.\n\n\n\nThe dataset used in this exercise is sourced from Kaggle and can be accessed via this link.\nThis dataset provides the opportunity to perform a comprehensive analysis of heart attack incidents in Japan as it includes a range of features such as:\n\nAge and Demographics including gender and region.\nMedical Indicators including cholesterol level, heart rate, systolic blood pressure, and diastolic blood pressure.\nPhysical Metrics including Body Mass Index (BMI) measurements.\nBehavioural Factors including physical activity levels and levels of alcohol consumption."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#background",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#background",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "Cardiovascular diseases, including heart attacks, are a leading cause of mortality worldwide. In recent years, Japan has experienced a steady increase in heart disease-related mortality, largely driven by its aging population, thus making it a growing public health concern (Ohira et al., 2023)."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#the-task",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#the-task",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "This exercise involves assuming the role of a graphical editor at an international media company that regularly publishes content on digital platforms. The company plans to release articles focused on one of the following themes:\n\nHeart Attack in Japan\nShip Performance in the Gulf of Guinea\n\nFor the purposes of this take-home exercise, the theme, Heart Attack in Japan, was selected for the preparation of data visualizations for the article."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#about-the-dataset",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#about-the-dataset",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "The dataset used in this exercise is sourced from Kaggle and can be accessed via this link.\nThis dataset provides the opportunity to perform a comprehensive analysis of heart attack incidents in Japan as it includes a range of features such as:\n\nAge and Demographics including gender and region.\nMedical Indicators including cholesterol level, heart rate, systolic blood pressure, and diastolic blood pressure.\nPhysical Metrics including Body Mass Index (BMI) measurements.\nBehavioural Factors including physical activity levels and levels of alcohol consumption."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#loading-r-packages",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#loading-r-packages",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.1 Loading R Packages",
    "text": "2.1 Loading R Packages\nThe following R packages were used:\n\n\n\nR Package\nDescription\n\n\n\n\ndplyr\n\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse, dplyr)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#importing-the-data",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#importing-the-data",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.2 Importing the Data",
    "text": "2.2 Importing the Data\nThe dataset was imported into R using the read_csv function from the readr package, which is part of the tidyverse suite.\n\nheartattack_data &lt;- read_csv(\"data/japan_heart_attack_dataset.csv\")"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#understanding-the-data",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#understanding-the-data",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.3 Understanding the Data",
    "text": "2.3 Understanding the Data\nThe following code chunk allows us to understand the structure of the dataset.\n\nCodeResults\n\n\n\nglimpse(heartattack_data)\n\n\n\n\n\nRows: 30,000\nColumns: 32\n$ Age                     &lt;dbl&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Region                  &lt;chr&gt; \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Rural\", \"…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Hypertension_History    &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Diet_Quality            &lt;chr&gt; \"Poor\", \"Good\", \"Average\", \"Good\", \"Good\", \"Go…\n$ Alcohol_Consumption     &lt;chr&gt; \"Low\", \"Low\", \"Moderate\", \"High\", \"High\", \"Hig…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Heart_Rate              &lt;dbl&gt; 72.30153, 57.45764, 64.65870, 55.13147, 76.667…\n$ Systolic_BP             &lt;dbl&gt; 123.90209, 129.89331, 145.65490, 131.78522, 10…\n$ Diastolic_BP            &lt;dbl&gt; 85.68281, 73.52426, 71.99481, 68.21133, 92.902…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ Extra_Column_1          &lt;dbl&gt; 0.40498852, 0.03627815, 0.85297888, 0.39085280…\n$ Extra_Column_2          &lt;dbl&gt; 0.43330004, 0.51256694, 0.21959083, 0.29684675…\n$ Extra_Column_3          &lt;dbl&gt; 0.62871236, 0.66839275, 0.61343656, 0.15572404…\n$ Extra_Column_4          &lt;dbl&gt; 0.70160955, 0.11552874, 0.50800995, 0.87025144…\n$ Extra_Column_5          &lt;dbl&gt; 0.49814235, 0.42381938, 0.90066981, 0.39035591…\n$ Extra_Column_6          &lt;dbl&gt; 0.007901312, 0.083932768, 0.227205241, 0.40318…\n$ Extra_Column_7          &lt;dbl&gt; 0.79458257, 0.68895108, 0.49634358, 0.74140891…\n$ Extra_Column_8          &lt;dbl&gt; 0.29077922, 0.83016364, 0.75210679, 0.22396813…\n$ Extra_Column_9          &lt;dbl&gt; 0.49719307, 0.63449028, 0.18150125, 0.32931387…\n$ Extra_Column_10         &lt;dbl&gt; 0.52199452, 0.30204337, 0.62918031, 0.14319054…\n$ Extra_Column_11         &lt;dbl&gt; 0.79965663, 0.04368285, 0.01827617, 0.90778075…\n$ Extra_Column_12         &lt;dbl&gt; 0.72239788, 0.45166789, 0.06322702, 0.54232201…\n$ Extra_Column_13         &lt;dbl&gt; 0.1487387, 0.8786714, 0.1465122, 0.9224606, 0.…\n$ Extra_Column_14         &lt;dbl&gt; 0.8340099, 0.5356022, 0.9972962, 0.6262165, 0.…\n$ Extra_Column_15         &lt;dbl&gt; 0.061632229, 0.617825340, 0.974455410, 0.22860…"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "",
    "text": "The following R packages will be used in this exercise:\n\n\n\n\n\n\n\nR Package\nDescription\n\n\n\n\nggridges\nFor plotting ridgeline plots.\n\n\nggdist\nFor visualising distribution and uncertainty.\n\n\ntidyverse\n\n\n\nggthemes\nProvides additional themes, scales, and geoms for ggplots package.\n\n\ncolorspace\nFor selecting individual colors or color palettes and employing them in various kinds of visualisations.\n\n\n\nThe following code chunk will be used to load these packages into R:\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\nThe code chunk below uses read_csv( ) to import exam_data.csv into R and save it into a tibble data frame:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "",
    "text": "The following R packages will be used in this exercise:\n\n\n\n\n\n\n\nR Package\nDescription\n\n\n\n\nggridges\nFor plotting ridgeline plots.\n\n\nggdist\nFor visualising distribution and uncertainty.\n\n\ntidyverse\n\n\n\nggthemes\nProvides additional themes, scales, and geoms for ggplots package.\n\n\ncolorspace\nFor selecting individual colors or color palettes and employing them in various kinds of visualisations.\n\n\n\nThe following code chunk will be used to load these packages into R:\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#data-import",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#data-import",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "",
    "text": "The code chunk below uses read_csv( ) to import exam_data.csv into R and save it into a tibble data frame:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#plotting-ridgeline-graphs-ggridges-method",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#plotting-ridgeline-graphs-ggridges-method",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "2.1 Plotting Ridgeline Graphs: ggridges Method",
    "text": "2.1 Plotting Ridgeline Graphs: ggridges Method\nMain Geoms Used to Plot Ridgeline Plots: geom_ridgeline( ) and geom_density_ridges( ).\n\n2.1.1 Using geom_density_ridges( )\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n2.1.2 Using geom_ridgeline()\n\nexam_dens &lt;- do.call(rbind, lapply(split(exam, exam$CLASS), function(df) {\n  dens &lt;- density(df$ENGLISH, adjust = 0.9) # Change the adjust parameter to control how detailed the density estimates are.\n  data.frame(ENGLISH = dens$x, density = dens$y, CLASS = unique(df$CLASS))\n}))\n\nggplot(exam_dens, aes(x = ENGLISH, y = CLASS, height = density, group = CLASS)) +\n  geom_ridgeline(\n    scale = 50,  # Adjust the scale variable  to change overlap and height of ridges.\n    fill = \"#7097BB\",\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.1, 0.1))\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngeom_ridgeline() requires an explicitly provided height aesthetic, which is set to the manually calculated density.\ngeom_density_ridges() does not seem to require any pre-processing steps for density calculation. Density estimation is handled internally by the geom_density_ridges() function."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#varying-fill-colours-along-the-x-axis",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#varying-fill-colours-along-the-x-axis",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "2.2 Varying Fill Colours Along the X-Axis",
    "text": "2.2 Varying Fill Colours Along the X-Axis\nThis can be achieved via geom_ridgeline_gradient() or geom_density_ridges_gradient().\n\n2.2.1 Using geom_density_ridges_gradient()\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#mapping-the-probabilities-directly-onto-colour",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#mapping-the-probabilities-directly-onto-colour",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "2.3 Mapping the Probabilities Directly onto Colour",
    "text": "2.3 Mapping the Probabilities Directly onto Colour\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#ridgeline-plots-with-quantile-lines",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#ridgeline-plots-with-quantile-lines",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "2.4 Ridgeline Plots with Quantile Lines",
    "text": "2.4 Ridgeline Plots with Quantile Lines\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\nAlternatively, cut-off points can also be specified as shown in the code chunk below:\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#plotting-a-half-eye-graph",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#plotting-a-half-eye-graph",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "3.1. Plotting a Half Eye Graph",
    "text": "3.1. Plotting a Half Eye Graph\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#adding-the-boxplot-with-geom_boxplot",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#adding-the-boxplot-with-geom_boxplot",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "3.2 Adding the Boxplot with geom_boxplot( )",
    "text": "3.2 Adding the Boxplot with geom_boxplot( )\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#adding-the-dot-plots-with-stat_dots",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#adding-the-dot-plots-with-stat_dots",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "3.3 Adding the Dot Plots with stat_dots( )",
    "text": "3.3 Adding the Dot Plots with stat_dots( )\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#finishing-touch---flipping-the-plot-horizontally",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#finishing-touch---flipping-the-plot-horizontally",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "3.4 Finishing Touch - Flipping the Plot Horizontally",
    "text": "3.4 Finishing Touch - Flipping the Plot Horizontally\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#disclaimer",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex041.html#disclaimer",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "4.1 Disclaimer",
    "text": "4.1 Disclaimer\nThis document includes content written with the assistance of ChatGPT, which was used for grammar correction, correction of code and the explanation of arguments for the various packages."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "",
    "text": "In this exercise, ggstatsplot would be used to create visual graphics with rich statistical information.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nThe code chunk below uses read_csv( ) to import exam_data.csv into R and save it into a tibble data frame:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#installing-and-loading-the-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#installing-and-loading-the-r-packages",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "",
    "text": "In this exercise, ggstatsplot would be used to create visual graphics with rich statistical information.\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#importing-data",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "",
    "text": "The code chunk below uses read_csv( ) to import exam_data.csv into R and save it into a tibble data frame:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#one-sample-test-gghistostats-method",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#one-sample-test-gghistostats-method",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "2.1 One-Sample Test: gghistostats() Method",
    "text": "2.1 One-Sample Test: gghistostats() Method\nThe code chunk below uses gghistostats() to build a visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ntype specifies the type of statistical analysis to be performed.\ntest.value refers to the value which the observed data (English scores) will be compared against.\nBased on the plot above, the very negative loge(BF01) of -31.45 suggests a strong statistical evidence against the null hypothesis, implying that the mean English score is different from 60."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#two-sample-mean-test-ggbetweenstats",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#two-sample-mean-test-ggbetweenstats",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "2.2. Two-Sample Mean Test: ggbetweenstats()",
    "text": "2.2. Two-Sample Mean Test: ggbetweenstats()\nThe code chunk below uses ggbetweenstats() to build a bisual for two-sample mean test of Math scores by gender:\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe Mann-Whitney U test is a non-parametric test, which is used to compare differences between two independent groups when the data cannot be assumed to be normally distributed.\nSince the p-value is 0.91 (&gt;0.05) suggests that there is no statistically significant difference in Math scores between males and females. The high p-value implies that any observed differences in median scores is likely due to random chance rather than systematic differences between genders."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#one-way-anova-test-ggbetweenstats-method",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#one-way-anova-test-ggbetweenstats-method",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "2.3 One-Way ANOVA Test: ggbetweenstats() Method",
    "text": "2.3 One-Way ANOVA Test: ggbetweenstats() Method\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe Welch ANOVA test is used to determine if there are statistically significant differences in the mean for &gt;3 groups. It is tailored for situations where the groups do not have equal variances (“heteroscedasticity”).\nSince the p-value is 1.71e-04 (&lt;0.05), the differences in English scores amongst racial groups is statistically significant."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#significant-test-of-correlation-ggscatterstats",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#significant-test-of-correlation-ggscatterstats",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "2.4 Significant Test of Correlation: ggscatterstats()",
    "text": "2.4 Significant Test of Correlation: ggscatterstats()\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\np-value of 1.70e-83 (&lt;0.05) suggests that the relationship between English and Maths is statistically significant.\nCorrelation Coefficient of 0.83 indicates a strong positive correlation between Math and English scores."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#significant-test-of-association",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#significant-test-of-association",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "2.5 Significant Test of Association",
    "text": "2.5 Significant Test of Association\nThe code chunk below bins the Math scores into a 4-class variable:\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nThe code chunk below uses ggbarstats() to build a visual for significant test of association:\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#getting-started-1",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#getting-started-1",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.1 Getting Started",
    "text": "3.1 Getting Started\n\n3.1.1 Installing and Loading the Required Libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n3.1.2 Importing Excel File\nThe code chunk below uses read_xls() to import the data worksheet of ToyotaCorolla.xls workbook into R:\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model          Price Age_08_04 Mfg_Month Mfg_Year    KM Fuel_Type    HP\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1     1 TOYOTA Coroll… 13500        23        10     2002 46986 Diesel       90\n 2     2 TOYOTA Coroll… 13750        23        10     2002 72937 Diesel       90\n 3     3  TOYOTA Corol… 13950        24         9     2002 41711 Diesel       90\n 4     4 TOYOTA Coroll… 14950        26         7     2002 48000 Diesel       90\n 5     5 TOYOTA Coroll… 13750        30         3     2002 38500 Diesel       90\n 6     6 TOYOTA Coroll… 12950        32         1     2002 61000 Diesel       90\n 7     7  TOYOTA Corol… 16900        27         6     2002 94612 Diesel       90\n 8     8 TOYOTA Coroll… 18600        30         3     2002 75889 Diesel       90\n 9     9  TOYOTA Corol… 21500        27         6     2002 19700 Petrol      192\n10    10  TOYOTA Corol… 12950        23        10     2002 71138 Diesel       69\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Met_Color &lt;dbl&gt;, Color &lt;chr&gt;, Automatic &lt;dbl&gt;, CC &lt;dbl&gt;,\n#   Doors &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Gears &lt;dbl&gt;, Quarterly_Tax &lt;dbl&gt;,\n#   Weight &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;, BOVAG_Guarantee &lt;dbl&gt;,\n#   Guarantee_Period &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#multiple-regression-model-using-lm",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#multiple-regression-model-using-lm",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.2 Multiple Regression Model Using lm()",
    "text": "3.2 Multiple Regression Model Using lm()\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostic-checking-for-multicollinearity",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostic-checking-for-multicollinearity",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.3 Model Diagnostic: Checking for Multicollinearity",
    "text": "3.3 Model Diagnostic: Checking for Multicollinearity\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\nVariables that are highly collinear with one or more other variables in the model. High VIF for these variables indicates that they share a substantial amount of information with other predictors, reducing the precision of the estimates of the model coefficients. Potential actions for high VIF variables include removing one of the highly collinear variables (either Age_08_04 or Mfg_Year) to reduce multicollinearity."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostics-checking-normality-assumption",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostics-checking-normality-assumption",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.4 Model Diagnostics: Checking Normality Assumption",
    "text": "3.4 Model Diagnostics: Checking Normality Assumption\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\n\nThe assumption of normality of residuals is not fully met, as indicated by the outliers and the heavy tails."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostics-check-model-for-homogeneity-of-variances",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostics-check-model-for-homogeneity-of-variances",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.5 Model Diagnostics: Check Model for Homogeneity of Variances",
    "text": "3.5 Model Diagnostics: Check Model for Homogeneity of Variances\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostics-complete-check",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#model-diagnostics-complete-check",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.6 Model Diagnostics: Complete Check",
    "text": "3.6 Model Diagnostics: Complete Check\n\ncheck_model(model1)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#visualising-regression-parameters-see-methods",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#visualising-regression-parameters-see-methods",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.7 Visualising Regression Parameters: see Methods",
    "text": "3.7 Visualising Regression Parameters: see Methods\n\nplot(parameters(model1))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#visualising-regression-parameters-ggcoefstats-methods",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex042.html#visualising-regression-parameters-ggcoefstats-methods",
    "title": "Hands-on Exercise 4.2: Visual Statistics Analysis",
    "section": "3.8 Visualising Regression Parameters: ggcoefstats() Methods",
    "text": "3.8 Visualising Regression Parameters: ggcoefstats() Methods\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "The following R packages will be used in this exercise:\n\n\n\nR Package\nDescription\n\n\n\n\ntidyverse\n\n\n\nplotly\nFor creating interactive plots.\n\n\ngganimate\nFor creating animated plots\n\n\nDT\nFor displaying interactive html tables.\n\n\ncrosstalk\nFor implementing cross-widget interactions\n\n\nggdist\nFor visualising distribution and uncertainty\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\nThe code chunk below uses read_csv() to import exam_data.csv into R:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nA point estimate is a single number (e.g. mean). Uncertainty can be expressed as standard error or confidence interval.\nThe following code chunk derives the summary statistics:\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\nThe following code chunk would be used to display the my_sum tibble data frame in a html table format:\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "The following R packages will be used in this exercise:\n\n\n\nR Package\nDescription\n\n\n\n\ntidyverse\n\n\n\nplotly\nFor creating interactive plots.\n\n\ngganimate\nFor creating animated plots\n\n\nDT\nFor displaying interactive html tables.\n\n\ncrosstalk\nFor implementing cross-widget interactions\n\n\nggdist\nFor visualising distribution and uncertainty\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#data-import",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#data-import",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "The code chunk below uses read_csv() to import exam_data.csv into R:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "A point estimate is a single number (e.g. mean). Uncertainty can be expressed as standard error or confidence interval.\nThe following code chunk derives the summary statistics:\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\nThe following code chunk would be used to display the my_sum tibble data frame in a html table format:\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#plotting-standard-error-bars-of-point-estimates",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#plotting-standard-error-bars-of-point-estimates",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#plotting-confidence-interval-of-point-estimates",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "shared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "3.1 Visualising the Uncertainty of Point Estimates: ggdist Methods",
    "text": "3.1 Visualising the Uncertainty of Point Estimates: ggdist Methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "3.2 Visualising the Uncertainty of Point Estimates: ggdist Methods",
    "text": "3.2 Visualising the Uncertainty of Point Estimates: ggdist Methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods-2",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex043.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods-2",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "3.3 Visualising the Uncertainty of Point Estimates: ggdist Methods",
    "text": "3.3 Visualising the Uncertainty of Point Estimates: ggdist Methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#duplicate-check",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#duplicate-check",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.4 Duplicate Check",
    "text": "2.4 Duplicate Check\n\nduplicate &lt;- heartattack_data %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 32\n# ℹ 32 variables: Age &lt;dbl&gt;, Gender &lt;chr&gt;, Region &lt;chr&gt;, Smoking_History &lt;chr&gt;,\n#   Diabetes_History &lt;chr&gt;, Hypertension_History &lt;chr&gt;,\n#   Cholesterol_Level &lt;dbl&gt;, Physical_Activity &lt;chr&gt;, Diet_Quality &lt;chr&gt;,\n#   Alcohol_Consumption &lt;chr&gt;, Stress_Levels &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   Heart_Rate &lt;dbl&gt;, Systolic_BP &lt;dbl&gt;, Diastolic_BP &lt;dbl&gt;,\n#   Family_History &lt;chr&gt;, Heart_Attack_Occurrence &lt;chr&gt;, Extra_Column_1 &lt;dbl&gt;,\n#   Extra_Column_2 &lt;dbl&gt;, Extra_Column_3 &lt;dbl&gt;, Extra_Column_4 &lt;dbl&gt;, …"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#understanding-the-data-and-data-wrangling",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01.html#understanding-the-data-and-data-wrangling",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.3 Understanding the Data and Data Wrangling",
    "text": "2.3 Understanding the Data and Data Wrangling\nTo gain an initial understanding of the dataset, the following code chunk utilises the glimpse function from the dplyr package. This function provides a quick overview of the dataset’s structure by displaying the first few entries of each column along with their data types.\n\nCodeResults\n\n\n\nglimpse(heartattack_data)\n\n\n\n\n\nRows: 30,000\nColumns: 32\n$ Age                     &lt;dbl&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Region                  &lt;chr&gt; \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Rural\", \"…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Hypertension_History    &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Diet_Quality            &lt;chr&gt; \"Poor\", \"Good\", \"Average\", \"Good\", \"Good\", \"Go…\n$ Alcohol_Consumption     &lt;chr&gt; \"Low\", \"Low\", \"Moderate\", \"High\", \"High\", \"Hig…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Heart_Rate              &lt;dbl&gt; 72.30153, 57.45764, 64.65870, 55.13147, 76.667…\n$ Systolic_BP             &lt;dbl&gt; 123.90209, 129.89331, 145.65490, 131.78522, 10…\n$ Diastolic_BP            &lt;dbl&gt; 85.68281, 73.52426, 71.99481, 68.21133, 92.902…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ Extra_Column_1          &lt;dbl&gt; 0.40498852, 0.03627815, 0.85297888, 0.39085280…\n$ Extra_Column_2          &lt;dbl&gt; 0.43330004, 0.51256694, 0.21959083, 0.29684675…\n$ Extra_Column_3          &lt;dbl&gt; 0.62871236, 0.66839275, 0.61343656, 0.15572404…\n$ Extra_Column_4          &lt;dbl&gt; 0.70160955, 0.11552874, 0.50800995, 0.87025144…\n$ Extra_Column_5          &lt;dbl&gt; 0.49814235, 0.42381938, 0.90066981, 0.39035591…\n$ Extra_Column_6          &lt;dbl&gt; 0.007901312, 0.083932768, 0.227205241, 0.40318…\n$ Extra_Column_7          &lt;dbl&gt; 0.79458257, 0.68895108, 0.49634358, 0.74140891…\n$ Extra_Column_8          &lt;dbl&gt; 0.29077922, 0.83016364, 0.75210679, 0.22396813…\n$ Extra_Column_9          &lt;dbl&gt; 0.49719307, 0.63449028, 0.18150125, 0.32931387…\n$ Extra_Column_10         &lt;dbl&gt; 0.52199452, 0.30204337, 0.62918031, 0.14319054…\n$ Extra_Column_11         &lt;dbl&gt; 0.79965663, 0.04368285, 0.01827617, 0.90778075…\n$ Extra_Column_12         &lt;dbl&gt; 0.72239788, 0.45166789, 0.06322702, 0.54232201…\n$ Extra_Column_13         &lt;dbl&gt; 0.1487387, 0.8786714, 0.1465122, 0.9224606, 0.…\n$ Extra_Column_14         &lt;dbl&gt; 0.8340099, 0.5356022, 0.9972962, 0.6262165, 0.…\n$ Extra_Column_15         &lt;dbl&gt; 0.061632229, 0.617825340, 0.974455410, 0.22860…\n\n\n\n\n\nBased on the output generated, the dataset consists of 30,000 rows and 32 columns.\n\n2.3.1 Filtering of Columns\nFrom the output generated in Section 2.3, the dataset includes 15 columns labelled from Extra_Column_1 to Extra_Column_15 . These columns do not have clear descriptions nor apparent relevance to the study. Hence, in order to streamline the dataset, these columns were removed. This would allow us to focus on variables that would be more relevant to the analysis.\nAfter filtering out the irrelevant columns, the dataset now comprises of 17 columns as shown in the Results tab below:\n\nCodeResults\n\n\n\nheartattack_data_filtered &lt;- select(heartattack_data, -matches(\"Extra_Column_\"))\n\n\n\n\n\nRows: 30,000\nColumns: 17\n$ Age                     &lt;dbl&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Region                  &lt;chr&gt; \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Rural\", \"…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Hypertension_History    &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Diet_Quality            &lt;chr&gt; \"Poor\", \"Good\", \"Average\", \"Good\", \"Good\", \"Go…\n$ Alcohol_Consumption     &lt;chr&gt; \"Low\", \"Low\", \"Moderate\", \"High\", \"High\", \"Hig…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Heart_Rate              &lt;dbl&gt; 72.30153, 57.45764, 64.65870, 55.13147, 76.667…\n$ Systolic_BP             &lt;dbl&gt; 123.90209, 129.89331, 145.65490, 131.78522, 10…\n$ Diastolic_BP            &lt;dbl&gt; 85.68281, 73.52426, 71.99481, 68.21133, 92.902…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n\n\n\n\n\n\n\n2.3.2 Duplicate and Missing Value Checks\nDuplicate Data Check\nWe performed a check for duplicate records using the dplyr package. Duplicates can skew analysis results. Hence, identifying and removing them is crucial.\n\nCodeResults\n\n\n\nheartattack_data_v3 &lt;- heartattack_data_filtered %&gt;%\n  mutate(is_duplicate = duplicated(.) | duplicated(., fromLast = TRUE))\n\n# Filtering to obtain only the rows that are duplicates\nduplicates_only &lt;- filter(heartattack_data_v3, is_duplicate == TRUE)\n\n# Displaying the first few rows of the duplicates\nhead(duplicates_only)\n\n\n\n\n\n# A tibble: 0 × 18\n# ℹ 18 variables: Age &lt;dbl&gt;, Gender &lt;chr&gt;, Region &lt;chr&gt;, Smoking_History &lt;chr&gt;,\n#   Diabetes_History &lt;chr&gt;, Hypertension_History &lt;chr&gt;,\n#   Cholesterol_Level &lt;dbl&gt;, Physical_Activity &lt;chr&gt;, Diet_Quality &lt;chr&gt;,\n#   Alcohol_Consumption &lt;chr&gt;, Stress_Levels &lt;dbl&gt;, BMI &lt;dbl&gt;,\n#   Heart_Rate &lt;dbl&gt;, Systolic_BP &lt;dbl&gt;, Diastolic_BP &lt;dbl&gt;,\n#   Family_History &lt;chr&gt;, Heart_Attack_Occurrence &lt;chr&gt;, is_duplicate &lt;lgl&gt;\n\n\n\n\n\nAfter applying the duplicate check, the output indicated a tibble data frame of 0 × 18, which implies that there are no duplicate records in our dataset.\nMissing Value Check\nMissing values in a dataset can introduce bias and affect the accuracy of statistical analysis, leading to misleading results. Hence, the dplyr package was utilised to identify and summarise the missing values across each variable in the dataset.\n\nCodeResults\n\n\n\nmissing_values_summary &lt;- heartattack_data_filtered %&gt;%\n  summarise_all(~ sum(is.na(.)))\n\nmissing_values_summary\n\n\n\n\n\n# A tibble: 1 × 17\n    Age Gender Region Smoking_History Diabetes_History Hypertension_History\n  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;           &lt;int&gt;            &lt;int&gt;                &lt;int&gt;\n1     0      0      0               0                0                    0\n# ℹ 11 more variables: Cholesterol_Level &lt;int&gt;, Physical_Activity &lt;int&gt;,\n#   Diet_Quality &lt;int&gt;, Alcohol_Consumption &lt;int&gt;, Stress_Levels &lt;int&gt;,\n#   BMI &lt;int&gt;, Heart_Rate &lt;int&gt;, Systolic_BP &lt;int&gt;, Diastolic_BP &lt;int&gt;,\n#   Family_History &lt;int&gt;, Heart_Attack_Occurrence &lt;int&gt;\n\n\n\n\n\nThe output indicates the count of missing values for each variable in the dataset. In this case, all columns have a count of 0, indicating that this dataset has no missing values.\n\n\n2.3.3 Recoding Variables\nRecoding BMI\nRaw BMI values alone do not provide an intuitive interpretation of body weight, making interpretation difficult for both technical and non-technical audiences. As such, there is a need to recode the BMI values into meaningful groups.\nIn this exercise, the BMI values were categorised into four distinct groups in accordance to the World Health Organisation’s International BMI Classification. Applying this classification would simplify the interpretation of BMI values, allowing readers of the article to easily determine whether an individual falls within a healthy range or an at-risk category, and the potential relationship with heart attack incidence.\nThe categories used are as follows:\n\n\n\nClassification\nBMI\n\n\n\n\nUnderweight\n&lt;18.5\n\n\nNormal Weight\n18.5 - 24.9\n\n\nPre-Obese\n25.0 - 29.9\n\n\nObese\n&gt;=30\n\n\n\nThe cut function in R was employed to implement this classification. This function assigns each BMI value to one of the specified categories, creating a new column, BMI_Category, in the dataset.\n\nCodeResults\n\n\n\n# Categorizing BMI according to WHO standards\nheartattack_data_filtered$BMI_Category &lt;- cut(\n  heartattack_data_filtered$BMI,\n  breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),\n  labels = c(\"Underweight\", \"Normal Weight\", \"Pre-Obese\", \"Obese\"),\n  right = TRUE\n)\n\n\n\n\n\n\n  Underweight Normal Weight     Pre-Obese         Obese \n         2875         11980         10215          4930 \n\n\n\n\n\nRecoding Age\nIn epidemiological studies, age is often grouped into categories rather than analysed as a continuous variable. While age is a key determinant of health risks, raw age variables do not immediately provide clear insights. Binning age into meaningful categories simplifies interpretation, making it easier to identify trends across different life stages.\nThe age variable was binned into the following categories:\n\n\n\nClassification\nAge Range\n\n\n\n\nYouth\n0 - 17\n\n\nYoung Adult\n18 - 35\n\n\nMiddle-Aged Adults\n36 - 64\n\n\nElderly\n&gt;= 65\n\n\n\nThe code chunk below uses the cut() function in R to categorise the age variable into the aforementioned groupings. A new variable called age_group would be created:\n\nCodeResults\n\n\n\nheartattack_data_filtered$Age_Group &lt;- cut(\n  heartattack_data_filtered$Age,\n  breaks = c(-Inf, 17, 35, 64, Inf), \n  labels = c(\"Youth\", \"Young Adult\", \"Middle-Aged Adult\", \"Elderly\"),\n  right = TRUE\n)\n\n# Verify the new categories\ntable(heartattack_data_filtered$Age_Group)\n\n\n\n\n\n\n            Youth       Young Adult Middle-Aged Adult           Elderly \n                0              8766             13905              7329 \n\n\n\n\n\n\n\n2.3.4 Data Type Conversion\nThe data table below shows the current data type of each of the 17 columns, along with the proposed data type for conversion. To improve data handling and ensure accurate analysis, the proposed data type for each column should align with the nature of the data.\n\n\n\nVariable\nCurrent Data Type\nProposed Data Type\n\n\n\n\nAge_Group\nCharacter\nOrdered Factor\n\n\nCholesterol_Level\nDouble\nDouble\n\n\nStress_Levels\nDouble\nDouble\n\n\nHeart_Rate\nDouble\nDouble\n\n\nSystolic_BP\nDouble\nDouble\n\n\nDiastolic_BP\nDouble\nDouble\n\n\nGender\nCharacter\nFactor\n\n\nRegion\nCharacter\nFactor\n\n\nSmoking_History\nCharacter\nFactor\n\n\nDiabetes_History\nCharacter\nFactor\n\n\nHypertension_History\nCharacter\nFactor\n\n\nPhysical_Activity\nCharacter\nOrdered Factor\n\n\nDiet_Quality\nCharacter\nOrdered Factor\n\n\nAlcohol_Consumption\nCharacter\nOrdered Factor\n\n\nFamily_History\nCharacter\nFactor\n\n\nHeart_Attack_Occurrence\nCharacter\nFactor\n\n\nBMI_Category\nCharacter\nOrdered Factor\n\n\n\nThe following code chunk is used to implement the proposed data type conversions:\n\nCodeResults\n\n\n\n# Convert numeric variables\nheartattack_data_filtered &lt;- heartattack_data_filtered %&gt;%\n  mutate(\n    Age = as.integer(Age)\n  )\n\n# Convert categorical variables to factors\nheartattack_data_filtered &lt;- heartattack_data_filtered %&gt;%\n  mutate(\n    Gender = as.factor(Gender),\n    Region = as.factor(Region),\n    Smoking_History = as.factor(Smoking_History),\n    Diabetes_History = as.factor(Diabetes_History),\n    Hypertension_History = as.factor(Hypertension_History),\n    Family_History = as.factor(Family_History),\n    Heart_Attack_Occurrence = as.factor(Heart_Attack_Occurrence)\n  )\n\n# Convert ordered categorical variables\nheartattack_data_filtered &lt;- heartattack_data_filtered %&gt;%\n  mutate(\n    Physical_Activity = factor(Physical_Activity, \n                               levels = c(\"Low\", \"Moderate\", \"High\"), \n                               ordered = TRUE),\n    Diet_Quality = factor(Diet_Quality, \n                          levels = c(\"Poor\", \"Average\", \"Good\"), \n                          ordered = TRUE),\n    Alcohol_Consumption = factor(Alcohol_Consumption, \n                                 levels = c(\"None\", \"Low\", \"Moderate\", \"High\"), \n                                 ordered = TRUE),\n    BMI_Category = factor(BMI_Category, \n                          levels = c(\"Underweight\", \"Normal Weight\", \"Pre-Obese\", \"Obese\"), \n                          ordered = TRUE),\n    Age_Group = factor(Age_Group, \n                       levels = c(\"Youth\", \"Young Adult\", \"Middle-Aged Adult\", \"Elderly\"), \n                       ordered = TRUE)\n  )\n\n\n\n\n\nRows: 30,000\nColumns: 19\n$ Age                     &lt;int&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;fct&gt; Male, Male, Male, Female, Female, Female, Male…\n$ Region                  &lt;fct&gt; Urban, Urban, Rural, Urban, Rural, Rural, Urba…\n$ Smoking_History         &lt;fct&gt; Yes, No, Yes, No, No, No, No, Yes, No, No, No,…\n$ Diabetes_History        &lt;fct&gt; No, No, No, No, No, No, Yes, No, No, No, No, N…\n$ Hypertension_History    &lt;fct&gt; No, No, No, No, No, No, Yes, No, Yes, No, Yes,…\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Physical_Activity       &lt;ord&gt; Moderate, Low, Low, Moderate, High, Low, High,…\n$ Diet_Quality            &lt;ord&gt; Poor, Good, Average, Good, Good, Good, Poor, P…\n$ Alcohol_Consumption     &lt;ord&gt; Low, Low, Moderate, High, High, High, High, No…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Heart_Rate              &lt;dbl&gt; 72.30153, 57.45764, 64.65870, 55.13147, 76.667…\n$ Systolic_BP             &lt;dbl&gt; 123.90209, 129.89331, 145.65490, 131.78522, 10…\n$ Diastolic_BP            &lt;dbl&gt; 85.68281, 73.52426, 71.99481, 68.21133, 92.902…\n$ Family_History          &lt;fct&gt; No, Yes, No, No, No, No, No, No, No, Yes, Yes,…\n$ Heart_Attack_Occurrence &lt;fct&gt; No, No, No, No, No, No, No, No, Yes, No, No, N…\n$ BMI_Category            &lt;ord&gt; Obese, Pre-Obese, Pre-Obese, Normal Weight, No…\n$ Age_Group               &lt;ord&gt; Middle-Aged Adult, Elderly, Middle-Aged Adult,…"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities.\n\n\nThe following R packages would be used:\n\n\n\nR Package\nDescription\n\n\n\n\nreadr\n\n\n\nFunnelPlotR\nFor creating funnel plots.\n\n\nggplot2\nFor creating funnel plots manually.\n\n\nknitr\nFor building static html tables.\n\n\nplotly\nFor creating interactive funnel plots.\n\n\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nThe code chunk below utilises read_csv() to import the data into R:\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#installing-and-loading-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "",
    "text": "The following R packages would be used:\n\n\n\nR Package\nDescription\n\n\n\n\nreadr\n\n\n\nFunnelPlotR\nFor creating funnel plots.\n\n\nggplot2\nFor creating funnel plots manually.\n\n\nknitr\nFor building static html tables.\n\n\nplotly\nFor creating interactive funnel plots.\n\n\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#importing-data",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "",
    "text": "The code chunk below utilises read_csv() to import the data into R:\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#funnelplotr-methods-the-basic-plot",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#funnelplotr-methods-the-basic-plot",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "2.1 FunnelPlotR Methods: The Basic Plot",
    "text": "2.1 FunnelPlotR Methods: The Basic Plot\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#funnelplotr-methods-makeover-1",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#funnelplotr-methods-makeover-1",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "2.2 FunnelPlotR Methods: Makeover 1",
    "text": "2.2 FunnelPlotR Methods: Makeover 1\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#funnelplotr-methods-makeover-2",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#funnelplotr-methods-makeover-2",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "2.3 FunnelPlotR Methods: Makeover 2",
    "text": "2.3 FunnelPlotR Methods: Makeover 2\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#computing-the-basic-derived-fields",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#computing-the-basic-derived-fields",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "3.1 Computing the Basic Derived Fields",
    "text": "3.1 Computing the Basic Derived Fields\nThe following code chunk derives the cumulative death rate, and standard error of cumulative death rate:\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nfit.mean is then computed via the code chunk below:\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#calculate-lower-and-upper-limits-fo-95-and-99.9-ci",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#calculate-lower-and-upper-limits-fo-95-and-99.9-ci",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "3.2 Calculate Lower and Upper Limits fo 95% and 99.9% CI",
    "text": "3.2 Calculate Lower and Upper Limits fo 95% and 99.9% CI\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#plotting-a-static-funnel-plot",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#plotting-a-static-funnel-plot",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "3.3 Plotting a Static Funnel Plot",
    "text": "3.3 Plotting a Static Funnel Plot\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#interactive-funnel-plot-plotly-ggplot2",
    "href": "Hands-on Exercise/Hands-on_Ex04/Hands-on_Ex044.html#interactive-funnel-plot-plotly-ggplot2",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "3.4 Interactive Funnel Plot: plotly + ggplot2",
    "text": "3.4 Interactive Funnel Plot: plotly + ggplot2\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "The maritime sector is one of the most critical components of global trade, contributing significantly to economic growth and sustainability. Understanding ship performance through financial and operational metrics provides valuable insights into profitability and efficiency of shipping operations in the Gulf of Guinea.\n\n\n\nThis exercise involves assuming the role of a graphical editor at an international media company that regularly publishes content on digital platforms. The company plans to release articles focused on one of the following themes:\n\nHeart Attack in Japan\nShip Performance in the Gulf of Guinea\n\nThe selected theme for this task is Ship Performance in the Gulf of Guinea and the objective is to prepare data visualisation for the article.\n\n\n\nThe dataset used in this exercise is sourced from Kaggle. It can be accessed via this link.\nThis dataset contains information on key operational metrics and attributes of various ship types in the Gulf of Guinea. The dataset includes numerical (e.g. speed_over_ground_knots, revenue_per_voyage_usd) and categorical variables (e.g. ship_type, maintenance_status) relevant to ship performance evaluation."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#background",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#background",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "The maritime sector is one of the most critical components of global trade, contributing significantly to economic growth and sustainability. Understanding ship performance through financial and operational metrics provides valuable insights into profitability and efficiency of shipping operations in the Gulf of Guinea."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#the-task",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#the-task",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "This exercise involves assuming the role of a graphical editor at an international media company that regularly publishes content on digital platforms. The company plans to release articles focused on one of the following themes:\n\nHeart Attack in Japan\nShip Performance in the Gulf of Guinea\n\nThe selected theme for this task is Ship Performance in the Gulf of Guinea and the objective is to prepare data visualisation for the article."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#about-the-dataset",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#about-the-dataset",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "",
    "text": "The dataset used in this exercise is sourced from Kaggle. It can be accessed via this link.\nThis dataset contains information on key operational metrics and attributes of various ship types in the Gulf of Guinea. The dataset includes numerical (e.g. speed_over_ground_knots, revenue_per_voyage_usd) and categorical variables (e.g. ship_type, maintenance_status) relevant to ship performance evaluation."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#loading-r-packages",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#loading-r-packages",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.1 Loading R Packages",
    "text": "2.1 Loading R Packages\nThe following R packages were used:\n\n\n\n\n\n\n\nR Package\nDescription\n\n\n\n\ndplyr\nFor data manipulation, data wrangling and summarisation.\n\n\ntidyverse\n\n\n\nlubridate\nFor working with dates and times.\n\n\nscales\nFor formatting numeric data\n\n\nplotly\nFor creating interactive plots.\n\n\nggthemes\nFor providing additional themes for ggplot2.\n\n\nggridges\nFor creating ridgeline plots.\n\n\nggplot2\nFor creating plots.\n\n\nggdist\nFor visualising probability distributions in ggplot2.\n\n\npatchwork\nFor combining multiple ggplot2 plots into a single layout.\n\n\n\n\npacman::p_load(plotly, ggthemes, ggridges,\n               patchwork, ggplot2, tidyverse, dplyr, lubridate, ggdist)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#importing-the-data",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#importing-the-data",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.2 Importing the Data",
    "text": "2.2 Importing the Data\nThe dataset was imported into R using the read_csv function from the readr package, which is part of the tidyverse suite.\n\nship_data &lt;- read_csv(\"data/ship_performance_dataset.csv\")"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#understanding-the-data-and-data-wrangling",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#understanding-the-data-and-data-wrangling",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "2.3 Understanding the Data and Data Wrangling",
    "text": "2.3 Understanding the Data and Data Wrangling\nTo gain an initial understanding of the dataset, the following code chunk utilises the glimpse function from the dplyr package. This function provides a quick overview of the dataset’s structure by displaying the first few entries of each column along with their data types.\n\nCodeResults\n\n\n\nglimpse(ship_data)\n\n\n\n\n\nRows: 2,736\nColumns: 18\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\n\n\nBased on the output generated, the dataset consists of 2,736 rows and 18 columns. Based on the Date column, it seems that each row represents weekly data of shipping routes.\n\n2.3.1 Duplicate and Missing Value Checks\nDuplicate Data Check\nAs duplicates can skew analysis results, identifying and removing them is crucial for subsequent analysis. Thus, a check for duplicate records was done using the dplyr package as shown in the code chunk below:\n\nCodeResults\n\n\n\nduplicate_count &lt;- sum(duplicated(ship_data))\ncat(\"Number of duplicate rows:\", duplicate_count, \"\\n\")\n\nif (duplicate_count &gt; 0) {\n  duplicate_rows &lt;- ship_data[duplicated(ship_data), ]\n  print(duplicate_rows)\n} else {\n  cat(\"No duplicate rows found.\\n\")\n}\n\n\n\n\n\nNumber of duplicate rows: 0 \n\n\nNo duplicate rows found.\n\n\n\n\n\nBased on the output, there are no duplicate records in the dataset.\nMissing Value Check\nMissing values in a dataset can introduce bias and affect the accuracy of subsequent analysis, potentially leading to misleading results. The following code chunk counts the number of missing values (NA) in the dataset:\n\nmissing_value_count &lt;- sum(rowSums(is.na(ship_data)) &gt; 0)\ncat(\"Number of rows with missing values:\", missing_value_count, \"\\n\")\n\nNumber of rows with missing values: 0 \n\n\nAlthough the output indicates that there are no missing values (NA) in the dataset, a further assessment of categorical columns is required to check for unrecorded data. The following code chunk generates the unique values for each categorical column in the dataset:\n\nCodeResults\n\n\n\ncategorical_columns &lt;- names(ship_data)[sapply(ship_data, is.character)]\n\nfor (col in categorical_columns) {\n  cat(\"\\nUnique values in\", col, \":\\n\")\n  print(unique(ship_data[[col]]))\n}\n\n\n\n\n\n\nUnique values in Ship_Type :\n[1] \"Container Ship\" \"Fish Carrier\"   \"Bulk Carrier\"   \"None\"          \n[5] \"Tanker\"        \n\nUnique values in Route_Type :\n[1] \"None\"         \"Short-haul\"   \"Long-haul\"    \"Transoceanic\" \"Coastal\"     \n\nUnique values in Engine_Type :\n[1] \"Heavy Fuel Oil (HFO)\" \"Steam Turbine\"        \"Diesel\"              \n[4] \"None\"                \n\nUnique values in Maintenance_Status :\n[1] \"Critical\" \"Good\"     \"Fair\"     \"None\"    \n\nUnique values in Weather_Condition :\n[1] \"Moderate\" \"Rough\"    \"Calm\"     \"None\"    \n\n\n\n\n\nFrom the results, it was observed that some of the columns containing categorical data contained the value None, which may indicate missing or unrecorded data rather than an actual category. To quantify this, the following code counts the occurrences of None values in the affected categorical columns:\n\nCodeResults\n\n\n\ncategorical_columns &lt;- names(ship_data)[sapply(ship_data, is.character)]\n\nmissing_categorical_counts &lt;- data.frame(Column = categorical_columns, \n                                         Missing_Count = sapply(ship_data[categorical_columns], function(x) sum(is.na(x) | x == \"None\")))\n\n\n\n\n\n                               Column Missing_Count\nShip_Type                   Ship_Type           136\nRoute_Type                 Route_Type           136\nEngine_Type               Engine_Type           136\nMaintenance_Status Maintenance_Status           136\nWeather_Condition   Weather_Condition           136\n\n\n\n\n\nBased on the results obtained above, each affected column contains 136 None values, representing approximately 5% of the total observations in the dataset. Since the percentage of missing values is relatively low, records containing None will be excluded from subsequent analysis.\n\n\n2.3.2 Creating New Variables\nThe dataset covers the following time period: 4 June 2023 to 30 June 2024. To facilitate time-based analysis, the dates have been grouped into a new variable called Month, which will represent the month of each record in a \"MM-YYYY\" format.\nThe following code was used to generate these variables:\n\nship_data$Month &lt;- format(ship_data$Date, \"%Y-%m\")  \n\nhead(ship_data$Month)\n\n[1] \"2023-06\" \"2023-06\" \"2023-06\" \"2023-06\" \"2023-07\" \"2023-07\"\n\n\nProfit (USD)\nProfit is a key financial metric that reflects the overall economic performance of a ship’s operation. To incorporate profit into the dataset, a new variable was created based on the difference between Revenue_per_Voyage_USD and Operational_Cost_USD.\n\nship_data$Profit_USD &lt;- ship_data$Revenue_per_Voyage_USD - ship_data$Operational_Cost_USD\n\nsummary(ship_data$Profit_USD)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-444584   40885  262716  266219  492216  977168 \n\n\nBased on the summary statistics of the newly created Profit_USD, we can observe that some of the ships are loss-making, as shown by the minimum value.\n\n\n2.3.3 Data Type Conversion\nThe data table below shows the current data type of each of the 19 columns, along with the proposed data type for conversion. To improve data handling and ensure accurate analysis, the proposed data type for each column should align with the nature of the data.\n\n\n\nVariable\nCurrent Data Type\nProposed Data Type\n\n\n\n\nDate\nDate\nDate\n\n\nShip_Type\nCharacter\nFactor\n\n\nRoute_Type\nCharacter\nFactor\n\n\nEngine_Type\nCharacter\nFactor\n\n\nMaintenance_Status\nCharacter\nOrdered Factor\n\n\nSpeed_Over_Ground_knots\nDouble\nDouble\n\n\nEngine_Power_kW\nDouble\nDouble\n\n\nDistance_Traveled_nm\nDouble\nDouble\n\n\nDraft_meters\nDouble\nDouble\n\n\nWeather_Condition\nCharacter\nOrdered Factor\n\n\nCargo_Weight_tons\nDouble\nDouble\n\n\nOperational_Cost_USD\nDouble\nDouble\n\n\nRevenue_per_Voyage_USD\nDouble\nDouble\n\n\nTurnaround_Time_hours\nDouble\nDouble\n\n\nEfficiency_nm_per_kWh\nDouble\nDouble\n\n\nSeasonal_Impact_Score\nDouble\nDouble\n\n\nWeekly_Voyage_Count\nDouble\nInteger\n\n\nAverage_Load_Percentage\nDouble\nDouble\n\n\nMonth\nCharacter\nDate\n\n\nProfit_USD\nDouble\nDouble\n\n\n\nThe following code chunk is used to implement the proposed data type conversions:\n\nCodeResults\n\n\n\nship_data$Ship_Type &lt;- as.factor(ship_data$Ship_Type)\nship_data$Route_Type &lt;- as.factor(ship_data$Route_Type)\nship_data$Engine_Type &lt;- as.factor(ship_data$Engine_Type)\n\nship_data$Maintenance_Status &lt;- factor(ship_data$Maintenance_Status, \n                                       levels = c(\"Critical\", \"Fair\", \"Good\",\"None\"), \n                                       ordered = TRUE)\n\nship_data$Weather_Condition &lt;- factor(ship_data$Weather_Condition, \n                                      levels = c(\"Calm\", \"Moderate\", \"Rough\", \"Severe\",\"None\"), \n                                      ordered = TRUE)\n\nship_data$Month &lt;- as.Date(paste0(ship_data$Month, \"-01\"), format=\"%Y-%m-%d\")\n\nship_data$Weekly_Voyage_Count &lt;- as.integer(ship_data$Weekly_Voyage_Count)\n\n\n\n\n\nRows: 2,736\nColumns: 20\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;fct&gt; Container Ship, Fish Carrier, Container Ship, …\n$ Route_Type              &lt;fct&gt; None, Short-haul, Long-haul, Transoceanic, Tra…\n$ Engine_Type             &lt;fct&gt; Heavy Fuel Oil (HFO), Steam Turbine, Diesel, S…\n$ Maintenance_Status      &lt;ord&gt; Critical, Good, Fair, Fair, Fair, Fair, Critic…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;ord&gt; Moderate, Rough, Moderate, Moderate, Moderate,…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;int&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n$ Month                   &lt;date&gt; 2023-06-01, 2023-06-01, 2023-06-01, 2023-06-0…\n$ Profit_USD              &lt;dbl&gt; -191649.081, 400377.787, -54524.657, -173798.2…"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html",
    "title": "Hands-on Exercise 5.1: Creating Ternary Plot with R",
    "section": "",
    "text": "The following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nggtern\nPlots ternary diagrams\n\n\nPlotly R\nCreates interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js.\n\n\n\nThe following code chunk loads the required packages into R:\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\nThe read_csv() function of the readr package will be used to import espopagsex2000to2018_tidy.csv into R:\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nThe mutate() function of the dplyr package is used to derive three new measures: young, active and old.\n\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5.1: Creating Ternary Plot with R",
    "section": "",
    "text": "The following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nggtern\nPlots ternary diagrams\n\n\nPlotly R\nCreates interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js.\n\n\n\nThe following code chunk loads the required packages into R:\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#importing-data",
    "title": "Hands-on Exercise 5.1: Creating Ternary Plot with R",
    "section": "",
    "text": "The read_csv() function of the readr package will be used to import espopagsex2000to2018_tidy.csv into R:\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#data-preparation",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#data-preparation",
    "title": "Hands-on Exercise 5.1: Creating Ternary Plot with R",
    "section": "",
    "text": "The mutate() function of the dplyr package is used to derive three new measures: young, active and old.\n\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#plotting-a-static-ternary-diagram",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#plotting-a-static-ternary-diagram",
    "title": "Hands-on Exercise 5.1: Creating Ternary Plot with R",
    "section": "2.1 Plotting a Static Ternary Diagram",
    "text": "2.1 Plotting a Static Ternary Diagram\nThe ggtern() function of the ggetern package is used to create a simple ternary plot:\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThe following code chunk adds the graph title “Population Structure, 2015” and theme_rgbw() to the ternary plot generated above:\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#plotting-an-interactive-ternary-diagram",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex051.html#plotting-an-interactive-ternary-diagram",
    "title": "Hands-on Exercise 5.1: Creating Ternary Plot with R",
    "section": "2.2 Plotting an Interactive Ternary Diagram",
    "text": "2.2 Plotting an Interactive Ternary Diagram\n\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "",
    "text": "The code chunk below installs and launches corrplot, ggpubr, plotly, and tidyverse in R:\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\n\nThe read_csv() function of the readr package will be used to import wine_quality.csv into R:\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "",
    "text": "The code chunk below installs and launches corrplot, ggpubr, plotly, and tidyverse in R:\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#importing-data",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "",
    "text": "The read_csv() function of the readr package will be used to import wine_quality.csv into R:\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#building-a-basic-correlation-matrix",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#building-a-basic-correlation-matrix",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "2.1 Building a Basic Correlation Matrix",
    "text": "2.1 Building a Basic Correlation Matrix\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#drawing-the-lower-corner",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#drawing-the-lower-corner",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "2.2 Drawing the Lower Corner",
    "text": "2.2 Drawing the Lower Corner\nTo show the lower half of the correlation matrix, the upper panel argument will be used as shown in the code chunk below:\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, we can use the lower.panel argument to show the upper half of the correlation matrix:\n\npairs(wine[,2:12], lower.panel = NULL)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#including-correlation-coefficients",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#including-correlation-coefficients",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "2.3 Including Correlation Coefficients",
    "text": "2.3 Including Correlation Coefficients\npanel.cor function will be used to show the correlation coefficient of each pair of variables:\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#the-basic-plot",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#the-basic-plot",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "3.1 The Basic Plot",
    "text": "3.1 The Basic Plot\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#getting-started-with-corrplot",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#getting-started-with-corrplot",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "5.1 Getting Started with corrplot",
    "text": "5.1 Getting Started with corrplot\nThe code chunk below uses cor() to compute the correlation matrix of the wine data frame:\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nThe code chunk below uses corrplot() to plot the corrgram based on default settings:\n\ncorrplot(wine.cor)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#working-with-visual-geometrics",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#working-with-visual-geometrics",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "5.2 Working with Visual Geometrics",
    "text": "5.2 Working with Visual Geometrics\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\n5.2.1 Trying Out Other Visual Geometrics\n\nSquareColorPieNumber\n\n\n\ncorrplot(wine.cor, \n         method = \"square\") \n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"color\") \n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"pie\") \n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"number\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#working-with-mixed-layout",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#working-with-mixed-layout",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "5.3 Working with Mixed Layout",
    "text": "5.3 Working with Mixed Layout\nThe code chunk below plots a corrgram with a mixed visual matrix with one half showing ellipses, and the other half showing numbers:\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#combining-corrgram-with-the-significant-test",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#combining-corrgram-with-the-significant-test",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "5.4 Combining Corrgram with the Significant Test",
    "text": "5.4 Combining Corrgram with the Significant Test\nWe are interested to know which pair of variables and their correlation coefficients are statistically significant in statistical analysis:\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#reordering-a-corrgram",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#reordering-a-corrgram",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "5.5 Reordering a Corrgram",
    "text": "5.5 Reordering a Corrgram\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#reordering-a-correlation-matrix-using-hclust",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex052.html#reordering-a-correlation-matrix-using-hclust",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "5.6 Reordering a Correlation Matrix using hclust",
    "text": "5.6 Reordering a Correlation Matrix using hclust\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)\n\n\n\n\n\n\n\n\n\n5.6.1 Trying Other Order Methods’\nAlphabet\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"square\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"alphabet\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nFPC\n\ncorrplot.mixed(wine.cor, \n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"FPC\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "Heatmaps are generally good at:\n\nShowing variances across multiple variables,\nRevealing patterns,\nDisplaying whether any variables are similar to each other, and\nDetecting if any correlations exist between them.\n\n\n\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\nThe code chunk below uses read_csv() of readr to import WHData-2018.csv into R:\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nThe code chunk below changes the rows by country name instead of row numbers:\n\nrow.names(wh) &lt;- wh$Country\n\n\n\n\nThe data needs to be transformed into a data matrix in order to create the heatmap:\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#importing-the-dataset",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#importing-the-dataset",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "The code chunk below uses read_csv() of readr to import WHData-2018.csv into R:\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#preparing-the-data",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#preparing-the-data",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "The code chunk below changes the rows by country name instead of row numbers:\n\nrow.names(wh) &lt;- wh$Country"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#transforming-the-data-frame-into-a-matrix",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#transforming-the-data-frame-into-a-matrix",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "The data needs to be transformed into a data matrix in order to create the heatmap:\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#heatmap-of-r-stats",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#heatmap-of-r-stats",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "2.1 heatmap() of R Stats",
    "text": "2.1 heatmap() of R Stats\nThe code chunk below uses heatmap() of base stats to plot a heatmap:\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nIndicating NA in the Rowv and Colv switches off the plotting the row and column dendrograms. The code chunk below removes the argument to show how the heatmap looks like with the dendrograms plotted:\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nThe Happiness Score variable has relatively higher values than the other variables (which are mostly below 1.0). Hence, there is a need to normalise the matrix via the scale argument. The margins argument is used to ensure that the x-axis labels are displayed completely while cexRow and cexCol are used to define the font size:\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#working-with-heatmaply",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#working-with-heatmaply",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3.1 Working with heatmaply",
    "text": "3.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk uses -c(1, 2, 3, 4, 5) to create a vector that lists the columns to be excluded from the wh_matrix data frame when plotting the heatmap:\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#data-transformation",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#data-transformation",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3.2 Data Transformation",
    "text": "3.2 Data Transformation\nIn multivariate data sets, variables in the data sets include variables that reflect different types of measurements, which have their own individual ranges.\nTo ensure that all variables have comparable values, data transformation is often used before clustering.\n\n3.2.1 Scaling Method\nIf all variables are assumed to be normally distributed, then scaling would bring them closer to the standard normal distribution. The scale column supports column and row scaling.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n3.2.2 Normalising Method\nWhen variables come from different (non-normal) distributions, use the normalise function to bring the data to 0 - 1 scale.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n3.2.3 Percentising Method\nSimilar to ranking the variables. However, instead of keeping the rank variables, they are divided by the maximal rank. Interpretation is generally clearer as each value is a percent of observation that has its value or less:\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#manual-approach",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#manual-approach",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.1 Manual Approach",
    "text": "4.1 Manual Approach\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#statistical-approach",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#statistical-approach",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.2 Statistical Approach",
    "text": "4.2 Statistical Approach\nTo determine the best clustering method and number of clusters, the dend_expend() and find_k() functions would be used.\ndend_expend():\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe average method should be used since it has the highest optimum value of 0.67.\nfind_k():\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nThe number of clusters = 3.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#seriation",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#seriation",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.3 Seriation",
    "text": "4.3 Seriation\nOptimal Leaf Ordering (OLO):\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nGruvaeus and Wainer:\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nMean\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nNone:\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#working-with-colour-palettes",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#working-with-colour-palettes",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.4 Working with Colour Palettes",
    "text": "4.4 Working with Colour Palettes\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#the-finishing-touch",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex053.html#the-finishing-touch",
    "title": "Hands-on Exercise 5.3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4.5 The Finishing Touch",
    "text": "4.5 The Finishing Touch\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "Parallel coordinates plot compares multiple variables together and seeing the relationships between. This visualisation technique is more often found in academic and scientific studies rather than business / consumer data visualisations.\nParallel coordinates is used to bring meaningful multivariate patterns and comparisons to light.\n\n\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nThe read_csv() function is used to import WHData-2018.csv into R:\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "pacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#importing-data",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "The read_csv() function is used to import WHData-2018.csv into R:\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#plotting-a-simple-parallel-coordinates-plot",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#plotting-a-simple-parallel-coordinates-plot",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.1 Plotting a Simple Parallel Coordinates Plot",
    "text": "2.1 Plotting a Simple Parallel Coordinates Plot\nThe code chunk below uses ggparcoord() to plot a basic static parallel coordinates plot:\n\nggparcoord(data = wh, \n           columns = c(7:12))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#plotting-a-parallel-coordinates-with-boxplot",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#plotting-a-parallel-coordinates-with-boxplot",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.2 Plotting a Parallel Coordinates with Boxplot",
    "text": "2.2 Plotting a Parallel Coordinates with Boxplot\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#parallel-coordinates-with-facet",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#parallel-coordinates-with-facet",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.3 Parallel Coordinates with Facet",
    "text": "2.3 Parallel Coordinates with Facet\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#rotating-x-axis-text-label",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#rotating-x-axis-text-label",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.4 Rotating X-Axis Text Label",
    "text": "2.4 Rotating X-Axis Text Label\nThe theme() function in ggplot2 is used to rotate the text labels:\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#adjusting-the-rotated-x-axis-text-label",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#adjusting-the-rotated-x-axis-text-label",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2.5 Adjusting the Rotated X-Axis Text Label",
    "text": "2.5 Adjusting the Rotated X-Axis Text Label\nhjust is used to prevent label overlap with the plot:\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#the-basic-plot",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#the-basic-plot",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "3.1 The Basic Plot",
    "text": "3.1 The Basic Plot\nThe code chunk uses parallelPlot() to plot an interactive parallel coordinates plot:\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#rotate-axis-label",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#rotate-axis-label",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "3.2 Rotate Axis Label",
    "text": "3.2 Rotate Axis Label\nThe axis label is rotated using the rotateTitle argument:\n\nparallelPlot(wh,\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#changing-the-colour-scheme",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#changing-the-colour-scheme",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "3.3 Changing the Colour Scheme",
    "text": "3.3 Changing the Colour Scheme\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\nThe code provided above did not change the colour scheme despite including the argument continuousCS. We would need to included the refColumnDim argument ensure that the continuousCS effect shows:\n(Ref: https://cran.r-project.org/web/packages/parallelPlot/vignettes/introduction-to-parallelplot.html)\n\nparallelPlot(wh,\n             refColumnDim = \"Happiness score\",\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#parallel-coordinates-plot-with-histogram",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex054.html#parallel-coordinates-plot-with-histogram",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "3.4 Parallel Coordinates Plot with Histogram",
    "text": "3.4 Parallel Coordinates Plot with Histogram\nThe histoVisibility argument is used to plot histogram along the axis of each variable:\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "",
    "text": "pacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\nThe read_csv() is used to import realis2018.csv into R:\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n\n\nAs realis2018 is in transaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap.\n\n\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#installing-and-launching-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "",
    "text": "pacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#importing-the-data",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#importing-the-data",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "",
    "text": "The read_csv() is used to import realis2018.csv into R:\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#data-wrangling-and-manipulation",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#data-wrangling-and-manipulation",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "",
    "text": "As realis2018 is in transaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap.\n\n\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#designing-a-static-treemap",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#designing-a-static-treemap",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.1 Designing a Static Treemap",
    "text": "2.1 Designing a Static Treemap\nThe treemap() function of the Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resole condominium by geographic hierarchy.\nThe following code selects records belonging to resale condominium:\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#using-basic-arguments",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#using-basic-arguments",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.2 Using Basic Arguments",
    "text": "2.2 Using Basic Arguments\nThe code chunk below creates a treemap using the following argument: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nNote:\n\nIndex: The index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nvSize: The column must not contain negative values."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#working-with-vcolor-and-type-arguments",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#working-with-vcolor-and-type-arguments",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.3 Working with vColor and type Arguments",
    "text": "2.3 Working with vColor and type Arguments\nThe type argument is defined as value in the code chunk below:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#the-value-type-treemap",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#the-value-type-treemap",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.4 The “Value” Type Treemap",
    "text": "2.4 The “Value” Type Treemap\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#the-manual-type-treemap",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#the-manual-type-treemap",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.5 The “Manual” Type Treemap",
    "text": "2.5 The “Manual” Type Treemap\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThe following code chunk uses a single colour palette instead of diverging colour palette. Single colour palette should be used in cases where the values are all positive or negative:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#working-with-the-algorithm-argument",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#working-with-the-algorithm-argument",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.6 Working with the algorithm Argument",
    "text": "2.6 Working with the algorithm Argument\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#using-sortid",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#using-sortid",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "2.7 Using sortID",
    "text": "2.7 Using sortID\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#designing-a-basic-treemap",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#designing-a-basic-treemap",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "3.1 Designing a Basic Treemap",
    "text": "3.1 Designing a Basic Treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#defining-hierarchy",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#defining-hierarchy",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "3.2 Defining Hierarchy",
    "text": "3.2 Defining Hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning R\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding Boundary Line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#installing-the-d3treer-package",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#installing-the-d3treer-package",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "4.1 Installing the d3treeR Package",
    "text": "4.1 Installing the d3treeR Package\n\nlibrary(d3treeR)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#designing-an-interactive-treemap",
    "href": "Hands-on Exercise/Hands-on_Ex05/Hands-on_Ex055.html#designing-an-interactive-treemap",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "4.2 Designing an Interactive Treemap",
    "text": "4.2 Designing an Interactive Treemap\nThe code uses treemap() to build a treemap by using selected variables in condominium data.frame.\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nd3tree() is then used to build an interactive treemap:\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex04/In-Class_Ex04.html",
    "href": "In-Class Exercise/In-Class_Ex04/In-Class_Ex04.html",
    "title": "In-class Exercise 4.0",
    "section": "",
    "text": "pacman::p_load(haven, SmartEDA, tidyverse, tidymodels, ggplot2)\n\n\n\n\nThe code chunk below uses read_csv( ) to import exam_data.csv into R and save it into a tibble data frame:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex04/In-Class_Ex04.html#installing-and-launching-the-r-packages",
    "href": "In-Class Exercise/In-Class_Ex04/In-Class_Ex04.html#installing-and-launching-the-r-packages",
    "title": "In-class Exercise 4.0",
    "section": "",
    "text": "pacman::p_load(haven, SmartEDA, tidyverse, tidymodels, ggplot2)"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex04/In-Class_Ex04.html#importing-data",
    "href": "In-Class Exercise/In-Class_Ex04/In-Class_Ex04.html#importing-data",
    "title": "In-class Exercise 4.0",
    "section": "",
    "text": "The code chunk below uses read_csv( ) to import exam_data.csv into R and save it into a tibble data frame:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#financial",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#financial",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.1 Financial",
    "text": "3.1 Financial\n\nObservation X: Tankers have the lowest median profit amongst all ship types while Bulk Carriers have a bimodal distribution of profits.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filtering out \"None\" values from the Ship_Type Column:\nfiltered_ship_data &lt;- ship_data %&gt;%   filter(Ship_Type != \"None\")\n\np1 &lt;- ggplot(data=filtered_ship_data,\n       aes(y=Profit_USD/1e6, x=Ship_Type, fill = Ship_Type)) +\n  geom_boxplot(notch=TRUE, show.legend = FALSE) +\n  scale_y_continuous(labels = scales::dollar_format(suffix = \"M\", prefix = \"\"), limits = c(-1.0,1.5)) + \n  labs(\n    x = \"Ship Type\", \n    y = \"Profit (in USD Million)\"  \n  ) +\n  coord_flip() +\n  theme_classic()\n\n\np2 &lt;- ggplot(data = filtered_ship_data, aes(x = Profit_USD / 1e6, y = Ship_Type)) +\n  geom_density_ridges(aes(group = Ship_Type, fill = Ship_Type), alpha = 0.8, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::dollar_format(suffix = \"M\", prefix = \"\"), limits = c(-1.0,1.5)) +\n  labs(\n    x = \"Profit (in USD Million)\",  # Custom x-axis title\n    y = \"Ship Type\"\n  ) +\n  theme_classic() +\n  theme(axis.text.y = element_text(angle = 0))\n\n\ncombined_plot &lt;- (p1 / p2) +\n  plot_layout(guides = \"collect\") + \n  plot_annotation(\n    title = \"Profitability by Ship Types\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\")\n    )\n  )\n\n\ncombined_plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nTankers have the lowest median profit amongst all ship types, as indicated by the boxplot and further supported by the peak of the ridgeline plot being closer to zero.\nAlthough the median profits for Fish Carriers, Container Ships and Bulk Carriers appear relatively similar (as indicated by the boxplot), the distribution of profits differ across all ship types.\na. Bulk Carriers display a bimodal profit distribution, strongly suggesting two distinct groups within this category. It implies that some Bulk Carriers are highly profitable while others struggle.\nb. Both Fish Carriers and Container Ships exhibit unimodal distributions. However, Container Ships appear to have a higher profit variability as indicated by the greater range and IQR in the boxplot."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#profitability-by-ship-types",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#profitability-by-ship-types",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.2 Profitability by Ship Types",
    "text": "3.2 Profitability by Ship Types\nIn this section, we will analyze the profit distribution across different ship types to gain insights into their profitability trends and variability.\nThe code chunk below utilizes the patchwork package to combine both boxplots and ridgeline plots, allowing for a comprehensive visualization of profit distributions across ship types.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filtering out \"None\" values from the Ship_Type Column:\nfiltered_ship_data1 &lt;- ship_data %&gt;%   filter(Ship_Type != \"None\")\n\nmedians &lt;- filtered_ship_data1 %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarize(Median_Profit = median(Profit_USD/1e6))\n\nfiltered_ship_data1 &lt;- filtered_ship_data1 %&gt;%\n  left_join(medians, by = \"Ship_Type\")\n\n\np1 &lt;- ggplot(data=filtered_ship_data1,\n       aes(y=Profit_USD/1e6, x=Ship_Type, fill = Ship_Type)) +\n  geom_boxplot(notch=TRUE, show.legend = FALSE) +\n  \n   geom_text(\n    data = medians,\n    aes(label = sprintf(\"%.2fM\", Median_Profit), y = Median_Profit),\n    nudge_y = 0.1,\n    size = 2.5\n  ) +\n  \n  scale_y_continuous(labels = scales::dollar_format(suffix = \"M\", prefix = \"\"), limits = c(-1.0,1.5)) + \n  labs(\n    x = \"Ship Type\", \n    y = \"Profit (in USD Million)\"  \n  ) +\n  coord_flip() +\n  theme_classic()\n\n\np2 &lt;- ggplot(data = filtered_ship_data1, aes(x = Profit_USD / 1e6, y = Ship_Type)) +\n  geom_density_ridges(aes(group = Ship_Type, fill = Ship_Type), alpha = 0.8, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::dollar_format(suffix = \"M\", prefix = \"\"), limits = c(-1.0,1.5)) +\n  labs(\n    x = \"Profit (in USD Million)\",  # Custom x-axis title\n    y = \"Ship Type\"\n  ) +\n  theme_classic() +\n  theme(axis.text.y = element_text(angle = 0))\n\n\ncombined_plot &lt;- (p1 / p2) +\n  plot_layout(guides = \"collect\") + \n  plot_annotation(\n    title = \"Profitability by Ship Types\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\")\n    )\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nTankers have the lowest median profit at US$0.23M amongst all ship types, as indicated by the boxplot and further supported by the peak of the ridgeline plot being closer to zero.\nAlthough the median profits for Fish Carriers, Container Ships and Bulk Carriers appear relatively similar (as indicated by the boxplot), the distribution of profits differ across all ship types.\n(a) Bulk Carriers display a bimodal profit distribution, strongly suggesting two distinct groups within this category. It implies that some Bulk Carriers are highly profitable while others struggle.\n(b) Both Fish Carriers and Container Ships exhibit unimodal distributions. However, Container Ships appear to have a higher profit variability as indicated by the greater range and IQR in the boxplot."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#section",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#section",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.2",
    "text": "3.2\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter out Ship_Type = \"None\" and Maintenance_Status = \"None\"\nfiltered_ship_data2 &lt;- ship_data %&gt;%\n  filter(Ship_Type != \"None\", Maintenance_Status != \"None\")\n\n# Create stacked bar chart with Brewer Palette\nggplot(filtered_ship_data2, aes(x = Ship_Type, fill = Maintenance_Status)) +\n  geom_bar(position = \"fill\", color=\"black\") +  # Stacked proportionally\n  scale_y_continuous(labels = scales::percent_format()) +  # Convert to percentage\n  scale_fill_brewer(palette = \"Pastel1\") +  # Change color palette\n  labs(\n    title = \"Maintenance Condition by Ship Type\",\n    x = \"Ship Type\",\n    y = \"Percentage\",\n    fill = \"Maintenance Status\"\n  ) +\n  theme_minimal() + \n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nTankers have the lowest median profit at US$0.23M amongst all ship types, as indicated by the boxplot and further supported by the peak of the ridgeline plot being closer to zero.\nAlthough the median profits for Fish Carriers, Container Ships and Bulk Carriers appear relatively similar (as indicated by the boxplot), the distribution of profits differ across all ship types.\n(a) Bulk Carriers display a bimodal profit distribution, strongly suggesting two distinct groups within this category. It implies that some Bulk Carriers are highly profitable while others struggle.\n(b) Both Fish Carriers and Container Ships exhibit unimodal distributions. However, Container Ships appear to have a higher profit variability as indicated by the greater range and IQR in the boxplot."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#profitability-by-route-types",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#profitability-by-route-types",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.2 Profitability by Route Types",
    "text": "3.2 Profitability by Route Types\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter out Route_Type = \"None\"\nfiltered_ship_data6 &lt;- ship_data %&gt;%\n  filter(Route_Type != \"None\")\n\n# Plot\nggplot(filtered_ship_data6, \n       aes(x = Profit_USD / 1e6,\n           y = Route_Type)) +\n  stat_halfeye(adjust=0.5, scale=0.6, justification=-0.2, show.legend = FALSE) +\n  geom_boxplot(width = .2, outlier.shape = NA, show.legend = FALSE) + \n  stat_dots(side = \"left\", scale=0.5, justification=1.2, show.legend = FALSE) +\n  \n  labs(\n    x = \"Profit (in USD Millions)\",\n    y = \"Route Type\",\n    title = \"Profit Distribution by Route Type\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nTankers have the lowest median profit at US$0.23M amongst all ship types, as indicated by the boxplot and further supported by the peak of the ridgeline plot being closer to zero.\nAlthough the median profits for Fish Carriers, Container Ships and Bulk Carriers appear relatively similar (as indicated by the boxplot), the distribution of profits differ across all ship types.\n(a) Bulk Carriers display a bimodal profit distribution, strongly suggesting two distinct groups within this category. It implies that some Bulk Carriers are highly profitable while others struggle.\n(b) Both Fish Carriers and Container Ships exhibit unimodal distributions. However, Container Ships appear to have a higher profit variability as indicated by the greater range and IQR in the boxplot."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#maintenance-status-by-ship-types",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#maintenance-status-by-ship-types",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.4 Maintenance Status by Ship Types",
    "text": "3.4 Maintenance Status by Ship Types\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter out Ship_Type = \"None\" and Maintenance_Status = \"None\"\nfiltered_ship_data2 &lt;- ship_data %&gt;%\n  filter(Ship_Type != \"None\", Maintenance_Status != \"None\")\n\n# Create stacked bar chart with Brewer Palette\nggplot(filtered_ship_data2, aes(x = Ship_Type, fill = Maintenance_Status)) +\n  geom_bar(position = \"fill\", color=\"black\") +  # Stacked proportionally\n  scale_y_continuous(labels = scales::percent_format()) +  # Convert to percentage\n  scale_fill_brewer(palette = \"Pastel1\") +  # Change color palette\n  labs(\n    title = \"Maintenance Status by Ship Type\",\n    x = \"Ship Type\",\n    y = \"Percentage\",\n    fill = \"Maintenance Status\"\n  ) +\n  theme_minimal() + \n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n[WRITE INSIGHTS HEREEEE]"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#sales-and-profit-by-route-types",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#sales-and-profit-by-route-types",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.3 Sales and Profit by Route Types",
    "text": "3.3 Sales and Profit by Route Types\nIn this section, we will analyse the sales and profitability by route types based on quarterly trends. However, as June 2023 represents an incomplete quarter, we will exclude it from our analysis to ensure consistency in our quarterly comparisons.\nThe analysis assumes that the fiscal year starts in July. Hence, we will define the quarters as follows:\n\nQ1 = July 2023 - September 2023\nQ2 = October 2023 - December 2023\nQ3 = January 2024 - March 2024\nQ4 = April 2024 - June 2024\n\nEach chart is divided into four quadrants:\n\nHigh Profit, High Sales (Top Right)\nHigh Profit, Low Sales(Top Left): This could indicate potential issues with cost management or pricing.\nLow Profit, High Sales (Bottom Right)\nLow Profit, Low Sales (Bottom Left): Potentially requires attention.\n\nThe code chunk below generates a facet gird consisting of bubble charts, with each panel representing a quarterly breakdown of sales and profitability by route type. The bubble size reflects total weekly voyages to further aid in understanding how different route types perform over time.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nroute_summary &lt;- ship_data %&gt;%\n  filter(Route_Type != \"None\") %&gt;%  # Exclude Route_Type = \"None\"\n  filter(!(year(Month) == 2023 & month(Month) == 6)) %&gt;%  # Exclude June 2023\n  mutate(Quarter = case_when(\n    month(Month) %in% 7:9  ~ \"Q1\",  # July - September\n    month(Month) %in% 10:12 ~ \"Q2\", # October - December\n    month(Month) %in% 1:3  ~ \"Q3\",  # January - March\n    month(Month) %in% 4:6  ~ \"Q4\"   # April - June\n  )) %&gt;%\n  filter(!is.na(Quarter)) %&gt;% \n  group_by(Quarter, Route_Type) %&gt;%\n  summarise(\n    Total_Sales = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Total_Profit = sum(Profit_USD, na.rm = TRUE),\n    Total_Weekly_Voyages = sum(Weekly_Voyage_Count, na.rm = TRUE) \n  ) %&gt;%\n  mutate(\n    Sales_Percentile = percent_rank(Total_Sales), \n    Profit_Percentile = percent_rank(Total_Profit)\n  )\n\n\nggplot(route_summary, aes(x = Sales_Percentile, y = Profit_Percentile, \n                          size = Total_Weekly_Voyages, color = Route_Type)) +\n  geom_point(alpha = 0.7) + \n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"black\") +  \n  scale_size(range = c(3, 15), name = \"Total Weekly Voyages\") + \n  scale_x_continuous(labels = scales::percent_format()) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    title = \"Sales and Profit by Route Types\",\n    x = \"Sales Percentile\",\n    y = \"Profit Percentile\",\n    color = \"Route Type\",\n    size = \"Total Weekly Voyages\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    legend.position = \"right\"\n  ) +\n  facet_wrap(~ Quarter, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nWith the exception of Q2, Long-Haul Routes predominantly occupy the top-right quadrant, indicating strong performance in both sales and profit across most quarters.\nCoastal Routes consistently rank above 50th percentile in profitability across all quarters, suggesting their high-margin nature. However, their sales performance fluctuates.\nTransoceanic Routes consistently rank below the 50th percentile in profitability across all quarters. In terms of sales, they exhibit the lowest sales in Q1 and Q2 but show improvements in Q3 and Q4. They ranked the lowest in terms of profitability and sales in Q1 and Q2.\nWith the exception of Q2, Short-Haul Routes exhibit both low profitability and sales in Q3 and Q4 (replacing Transoceanic Routes), thus positioning it as an under-performing route. In addition, they record the lowest number of voyages in Q3."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#overall-revenue-cost-and-cargo-weight-trend-by-month",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#overall-revenue-cost-and-cargo-weight-trend-by-month",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.1 Overall Revenue, Cost and Cargo Weight Trend by Month",
    "text": "3.1 Overall Revenue, Cost and Cargo Weight Trend by Month\nThis section provides a time-series analysis of revenue, cost, and cargo weight trends across the observed period to identify key patterns and insights.\nThe code chunk below plots a combination of bar and line charts. Cargo weight is represented by a bar chart while revenue and operational costs are illustrated as line plots.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonthly_summary &lt;- ship_data %&gt;%\n  group_by(Month) %&gt;%\n  summarise(\n    Total_Revenue = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Total_Cost = sum(Operational_Cost_USD, na.rm = TRUE),\n    Total_Cargo_Weight = sum(Cargo_Weight_tons, na.rm = TRUE)\n  )\n\nmonthly_summary$Month &lt;- as.Date(paste0(monthly_summary$Month, \"-01\"), format=\"%Y-%m-%d\")\n\nmax_revenue &lt;- max(monthly_summary$Total_Revenue/1e6, na.rm = TRUE)\nmax_cargo &lt;- max(monthly_summary$Total_Cargo_Weight/1e6, na.rm = TRUE)\nscaling_factor &lt;- max_revenue / max_cargo  \n\n\nggplot(monthly_summary, aes(x = Month)) +\n  geom_col(aes(y = Total_Cargo_Weight/1e6*scaling_factor, fill = \"Cargo Weight (Million Tons)\"), alpha = 0.6) + \n  geom_line(aes(y = Total_Revenue/1e6, color = \"Revenue (in USD Million)\"), size = 1.2) + \n  geom_line(aes(y = Total_Cost/1e6, color = \"Operational Cost (in USD Million)\"), size = 1.2, linetype = \"dashed\") +\n  scale_y_continuous(\n    name = \"Revenue & Cost (in USD Million)\", \n    labels = scales::dollar_format(suffix = \"M\", prefix = \"\"),\n    sec.axis = sec_axis(~ ./scaling_factor, name = \"Cargo Weight (Million Tons)\")  \n  ) +\n  scale_x_date(\n    date_labels = \"%b %Y\",\n    breaks = seq(min(monthly_summary$Month), max(monthly_summary$Month), by = \"1 month\")\n  ) +\n  labs(\n    title = \"Revenue, Cost, and Cargo Weight by Month\",\n    x = \"Month\",\n    fill = \"Metric\",\n    color = \"Metric\"\n  ) +\n  scale_fill_manual(values = c(\"Cargo Weight (Million Tons)\" = \"lightblue\")) +  \n  scale_color_manual(values = c(\n    \"Revenue (in USD Million)\" = \"black\",\n    \"Operational Cost (in USD Million)\" = \"darkred\"\n  )) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nRevenue consistently exceeds operational costs across all months, indicating that operations remain profitable throughout the observed period.\nRevenue, operational costs and cargo weight exhibit similar trends. In months where cargo weight increases, both revenue and costs rise accordingly, and vice versa. This suggests a positive correlation between all three variables.\nThere is no clear growth trend over the observed period, as fluctuations in cargo weight, revenue, and costs occur at different points. Further research could be undertaken to understand if these variations could be attributed to seasonal demand shifts or external factors such as global economic conditions affecting shipping volumes."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#shipping-volumes-by-route-types",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#shipping-volumes-by-route-types",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.5 Shipping Volumes by Route Types",
    "text": "3.5 Shipping Volumes by Route Types\n\nfiltered_data &lt;- ship_data %&gt;%\n  filter(Route_Type != \"None\") %&gt;%\n  filter(!(year(Month) == 2023 & month(Month) == 6)) %&gt;%  # Exclude June 2023\n  mutate(\n    Quarter = case_when(\n      month(Month) %in% 7:9  ~ \"Q1 (Jul-Sep)\",  # Q1: July - September\n      month(Month) %in% 10:12 ~ \"Q2 (Oct-Dec)\", # Q2: October - December\n      month(Month) %in% 1:3  ~ \"Q3 (Jan-Mar)\",  # Q3: January - March\n      month(Month) %in% 4:6  ~ \"Q4 (Apr-Jun)\"   # Q4: April - June\n    )\n  ) %&gt;%\n  filter(!is.na(Quarter))  # Ensure valid quarter data\n\n# Summarize Data: Total Weekly Voyages and Cargo Weight per Route Type per Quarter\nsummary_data &lt;- filtered_data %&gt;%\n  group_by(Quarter, Route_Type) %&gt;%\n  summarise(\n    Total_Voyages = sum(Weekly_Voyage_Count, na.rm = TRUE),\n    Total_Cargo_Weight = sum(Cargo_Weight_tons, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Define Scaling Factor for Secondary Axis\nscaling_factor &lt;- max(summary_data$Total_Voyages, na.rm = TRUE) / \n                  max(summary_data$Total_Cargo_Weight, na.rm = TRUE)\n\n# Plot: Bar Chart (Voyages) + Line Chart (Cargo Weight) with 2x2 Facet by Quarter\nggplot(summary_data, aes(x = Route_Type)) +\n  geom_col(aes(y = Total_Voyages, fill = \"Total Voyages\"), alpha = 0.7) +  # Bar chart\n  geom_line(aes(y = Total_Cargo_Weight * scaling_factor, group = 1, color = \"Total Cargo Weight\"), size = 1.2) +  # Line chart\n  geom_point(aes(y = Total_Cargo_Weight * scaling_factor, color = \"Total Cargo Weight\"), size = 3) +  # Points for line chart\n  scale_y_continuous(\n    name = \"Total Voyages\",\n    labels = scales::comma_format(),\n    sec.axis = sec_axis(~ . / scaling_factor, name = \"Total Cargo Weight (tons)\")\n  ) +\n  scale_fill_manual(values = c(\"Total Voyages\" = \"lightblue\")) +  # Bar color\n  scale_color_manual(values = c(\"Total Cargo Weight\" = \"black\")) +  # Line color\n  labs(\n    title = \"Total Voyages and Cargo Weight by Route Type (Faceted by Quarter)\",\n    x = \"Route Type\",\n    fill = \"Metric\",\n    color = \"Metric\"\n  ) +\n  facet_wrap(~ Quarter, ncol = 2) +  # Flip for better readability\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n::::"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#average-load-percentage-by-ship-type-and-route-types",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#average-load-percentage-by-ship-type-and-route-types",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.4 Average Load Percentage by Ship Type and Route Types",
    "text": "3.4 Average Load Percentage by Ship Type and Route Types\nThis section examines the distribution of average load percentage across different ship types and routes types. By visualising the density distribution of load percentage, this section aims to understand how efficiently different ship types utilise their cargo capacity on various routes.\nThe code chunk below plots the density distributions of average load percentage for different ship types across route types using geom_density. A reference line representing the median load percentage for each route type is added to provide a benchmark for further interpretation.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered_data2 &lt;- ship_data %&gt;%\n  filter(Ship_Type != \"None\", Route_Type != \"None\")\n\nmedian_values &lt;- filtered_data2 %&gt;%\n  group_by(Route_Type) %&gt;%\n  summarise(Median_Load = median(Average_Load_Percentage, na.rm = TRUE), .groups = \"drop\")\n\n\nggplot(filtered_data2, aes(x = Average_Load_Percentage, color = Ship_Type)) +\n  geom_density(alpha = 0.7) +  \n  geom_vline(data = median_values, aes(xintercept = Median_Load), \n             linetype = \"dashed\", size = 0.5, color = \"black\") +\n  geom_text(data = median_values, \n            aes(x = Median_Load, y = 0, \n                label = sprintf(\"Median: %.1f%%\", Median_Load)), \n            hjust = 1.1, vjust = -1.5, size = 2.5, color = \"black\") + \n  labs(\n    title = \"Average Load Percentage by Ship Types Across Routes\",\n    x = \"Average Load Percentage (%)\",\n    y = \"Density\",\n    color = \"Ship Type\"\n  ) +\n  facet_wrap(~ Route_Type, ncol = 2) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nCoastal Routes: Tankers exhibit a left-skewed distribution, with a distinct peak in the 90% - 95% range, indicating a higher frequency of tankers operating at high load capacities. In contrast, other ship types demonstrate a more uniform distribution.\nLong-Haul Routes: All ship types exhibit a relatively uniform distribution.\nShort-Haul Routes: Container Ships exhibit a right-skewed distribution, with a peak in the 60% - 65% range, indicating a higher frequency of container ships operating with lower load capacities. In contrast, both Bulk Carriers and Tankers exhibit a left-skew distribution, suggesting a tendency toward higher load capacities.\nTransoceanic Routes: Most ship types exhibit a relatively uniform distribution, except for Bulk Carriers, which display a distinct peak in the 80% - 85% range. This indicates a higher concentration of bulk carriers operating within this load percentage."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#financial-metrics",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#financial-metrics",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.1 Financial Metrics",
    "text": "3.1 Financial Metrics\n\n3.1.1 Overview of Revenue, Cost and Cargo Weight Trending by Month\nThis section provides a time-series analysis of revenue, cost, and cargo weight trends across the observed period to identify key patterns and insights.\nThe code chunk below plots a combination of bar and line charts. Cargo weight is represented by a bar chart while revenue and operational costs are illustrated as line plots.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonthly_summary &lt;- ship_data %&gt;%\n  group_by(Month) %&gt;%\n  summarise(\n    Total_Revenue = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Total_Cost = sum(Operational_Cost_USD, na.rm = TRUE),\n    Total_Cargo_Weight = sum(Cargo_Weight_tons, na.rm = TRUE)\n  )\n\nmonthly_summary$Month &lt;- as.Date(paste0(monthly_summary$Month, \"-01\"), format=\"%Y-%m-%d\")\n\nmax_revenue &lt;- max(monthly_summary$Total_Revenue/1e6, na.rm = TRUE)\nmax_cargo &lt;- max(monthly_summary$Total_Cargo_Weight/1e6, na.rm = TRUE)\nscaling_factor &lt;- max_revenue / max_cargo  \n\n\nggplot(monthly_summary, aes(x = Month)) +\n  geom_col(aes(y = Total_Cargo_Weight/1e6*scaling_factor, fill = \"Cargo Weight (Million Tons)\"), alpha = 0.6) + \n  geom_line(aes(y = Total_Revenue/1e6, color = \"Revenue (in USD Million)\"), size = 1) + \n  geom_line(aes(y = Total_Cost/1e6, color = \"Operational Cost (in USD Million)\"), size = 1, linetype = \"dashed\") +\n  scale_y_continuous(\n    name = \"Revenue & Cost (in USD Million)\", \n    labels = scales::dollar_format(suffix = \"M\", prefix = \"\"),\n    sec.axis = sec_axis(~ ./scaling_factor, name = \"Cargo Weight (Million Tons)\")  \n  ) +\n  scale_x_date(\n    date_labels = \"%b %Y\",\n    breaks = seq(min(monthly_summary$Month), max(monthly_summary$Month), by = \"1 month\")\n  ) +\n  labs(\n    title = \"Revenue, Cost, and Cargo Weight by Month\",\n    x = \"Month\",\n    fill = \"Metric\",\n    color = \"Metric\"\n  ) +\n  scale_fill_manual(values = c(\"Cargo Weight (Million Tons)\" = \"lightblue\")) +  \n  scale_color_manual(values = c(\n    \"Revenue (in USD Million)\" = \"black\",\n    \"Operational Cost (in USD Million)\" = \"darkred\"\n  )) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nRevenue consistently exceeds operational costs across all months, indicating that operations remain profitable throughout the observed period.\nRevenue, operational costs and cargo weight exhibit similar trends. In months where cargo weight increases, both revenue and costs rise accordingly, and vice versa. This suggests a positive correlation between all three variables.\nThere is no clear growth trend over the observed period, as fluctuations in cargo weight, revenue, and costs occur over time. Further research could be undertaken to understand if these variations could be attributed to seasonal demand shifts or external factors such as global economic conditions affecting shipping volumes.\n\n\n\n\n\n3.1.2 Profitability by Ship Types\nIn this section, we will analyze the profitability across different ship types to gain insights into their profitability trends and variability.\nThe code chunk below generates three plots to explore the profitability of different ship types. Firstly, the bar chart presents the total profit across ship types, ranking them from highest to lowest profit. Next, the boxplot provides insight into the distribution of profit, highlighting the variability and median values across ship types. Lastly, the ridgeline plot illustrates the profit distribution across ship types. The patchwork function is then used to combine these plots together.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered_ship_data1 &lt;- ship_data %&gt;% filter(Ship_Type != \"None\")\n\n\n\nmedians &lt;- filtered_ship_data1 %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarize(Median_Profit = median(Profit_USD/1e6, na.rm = TRUE))\n\nfiltered_ship_data1 &lt;- filtered_ship_data1 %&gt;%\n  left_join(medians, by = \"Ship_Type\")\n\n\n\np1 &lt;- ggplot(data=filtered_ship_data1, aes(y=Profit_USD/1e6, x=reorder(Ship_Type, Median_Profit), fill = Ship_Type)) +\n  geom_boxplot(notch=TRUE, show.legend = FALSE) +\n  geom_text(data = medians,\n            aes(label = sprintf(\"%.2fM\", Median_Profit), y = Median_Profit),\n            nudge_y = 0.1, size = 3.5) +\n  scale_y_continuous(labels = scales::dollar_format(suffix = \"M\", prefix = \"$\"), limits = c(-1.0,1.5)) + \n  labs(\n    title = \"Profit Distribution by Ship Type\",\n    x = NULL,  \n    y = \"Profit (in USD Million)\"\n  ) +\n  coord_flip() +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_blank(),\n    axis.text.y = element_text(size = 12)\n  )\n\n\n\np2 &lt;- ggplot(data = filtered_ship_data1, aes(x = Profit_USD / 1e6, y = reorder(Ship_Type, Median_Profit), fill = Ship_Type)) +\n  geom_density_ridges(aes(group = Ship_Type, fill = Ship_Type), alpha = 0.8, show.legend = FALSE) +\n  scale_x_continuous(labels = scales::dollar_format(suffix = \"M\", prefix = \"$\"), limits = c(-1.0,1.5)) +\n  labs(\n    x = \"Profit (in USD Million)\",\n    y = NULL\n  ) +\n  theme_classic() + \n  theme(\n    axis.text.y = element_text(size = 12)\n  )\n\n\n\nprofit_summary &lt;- ship_data %&gt;%\n  filter(Ship_Type != \"None\") %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(Total_Profit = sum(Profit_USD, na.rm = TRUE)) %&gt;%\n  arrange(desc(Total_Profit)) \n\n\n\np3 &lt;- ggplot(profit_summary, aes(x = reorder(Ship_Type, Total_Profit), y = Total_Profit, fill = Ship_Type)) +\n  geom_col(show.legend = FALSE) + \n  geom_text(aes(label = sprintf(\"%.2fM\", Total_Profit / 1e6)), \n            hjust = 1.5, size = 3.5) +\n  coord_flip() + \n  scale_y_continuous(labels = scales::dollar_format(prefix = \"$\", suffix = \"M\", scale = 1e-6)) +\n  labs(\n    title = \"Total Profit by Ship Type\",\n    x = NULL, \n    y = \"Profit (in USD Million)\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    plot.margin = margin(10, 40, 10, 10),\n    axis.text.y = element_text(size = 12))\n\n\ncombined_plot &lt;- (p3 | (p1 / p2)) + \n  plot_layout(widths = c(1, 2.5)) +\n  plot_annotation(\n    title = \"Profitability by Ship Types\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, size = 18, face = \"bold\")\n    )\n  )\n\ncombined_plot\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nFish Carriers generated the highest total profit while Tankers generated the lowest. This pattern is also reflected in median profits, with Tankers having the lowest median profit at US$0.23M. Furthermore, the notch of the boxplot for Tankers does not overlap with the notches of the other ship types, suggesting that the median profit for Tankers is significantly lower.\nAlthough the median profits for Fish Carriers, Container Ships and Bulk Carriers are similar (indicated by their overlapping boxplot notches), their profit distributions differ:\n(a) Bulk Carriers display a bimodal distribution, indicating two distinct groups - some Bulk Carriers are highly profitable while others operate at lower margins.\n(b) Fish Carriers and Container Ships exhibit unimodal distributions. However, Container Ships appear to have a higher profit variability as indicated by the greater range and IQR in the boxplot.\n\n\n\n\n\n3.1.3 Sales and Profitability by Route Types\nIn this section, we will analyse the sales and profitability trends by route types on a quarterly basis. Since June 2023 represents an incomplete quarter, it has been excluded to ensure consistency in our quarterly comparisons.\nThe analysis assumes that the fiscal year starts in July. Hence, we will define the quarters as follows:\n\nQ1 = July 2023 - September 2023\nQ2 = October 2023 - December 2023\nQ3 = January 2024 - March 2024\nQ4 = April 2024 - June 2024\n\nEach chart is divided into four quadrants to help interpret the relationship between sales and profit:\n\nHigh Profit, High Sales (Top Right)\nHigh Profit, Low Sales(Top Left)\nLow Profit, High Sales (Bottom Right): This could indicate potential issues with cost management or pricing.\nLow Profit, Low Sales (Bottom Left): Potentially requires attention.\n\nThe code chunk below generates a facet gird consisting of bubble charts, with each panel representing a quarterly breakdown of sales and profitability by route type. The bubble size corresponds to the profit margin percentage.\nThe code chunk also generates an interactive plot using plotly. It allows users to hover over each data point to view details such as route type, total sales, total profit and profit margin.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nroute_summary &lt;- ship_data %&gt;%\n  filter(Route_Type != \"None\") %&gt;%\n  filter(!(year(Month) == 2023 & month(Month) == 6)) %&gt;%\n  mutate(Quarter = case_when(\n    month(Month) %in% 7:9  ~ \"Q1\",  \n    month(Month) %in% 10:12 ~ \"Q2\", \n    month(Month) %in% 1:3  ~ \"Q3\",  \n    month(Month) %in% 4:6  ~ \"Q4\"   \n  )) %&gt;%\n  filter(!is.na(Quarter)) %&gt;% \n  group_by(Quarter, Route_Type) %&gt;%\n  summarise(\n    Total_Sales = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Total_Profit = sum(Profit_USD, na.rm = TRUE),\n    Profit_Margin = ifelse(Total_Sales &gt; 0, (Total_Profit / Total_Sales) * 100, NA)  \n  ) %&gt;%\n  mutate(\n    Sales_Percentile = percent_rank(Total_Sales), \n    Profit_Percentile = percent_rank(Total_Profit)\n  )\n\np &lt;- ggplot(route_summary, aes(x = Sales_Percentile, y = Profit_Percentile, \n                               size = Profit_Margin, color = Route_Type,\n                               text = paste(\"Route Type:\", Route_Type,\n                                            \"&lt;br&gt;Sales:\", scales::dollar(Total_Sales / 1e6, suffix = \"M\"),\n                                            \"&lt;br&gt;Profit:\", scales::dollar(Total_Profit / 1e6, suffix = \"M\"),\n                                            \"&lt;br&gt;Profit Margin:\", sprintf(\"%.1f%%\", Profit_Margin)))) +\n  geom_point(alpha = 0.7) + \n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"black\", size = 0.3) +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"black\", size = 0.3) +  \n  scale_size(range = c(3, 15), name = \"Profit Margin (%)\", guide = guide_legend(title = \"Profit Margin (%)\")) +\n  scale_x_continuous(labels = scales::percent_format()) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(\n    title = \"Sales and Profit by Route Types\",\n    x = \"Sales Percentile\",\n    y = \"Profit Percentile\",\n    color = \"Route Type\",\n    size = \"Profit Margin (%)\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    legend.position = \"right\",\n    panel.spacing = unit(1.5, \"lines\")  \n  ) +\n  facet_wrap(~ Quarter, ncol = 2)\n\n\np_interactive &lt;- ggplotly(p, tooltip = \"text\")\n\np_interactive\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nLong-Haul Routes predominantly occupy the top-right quadrant, indicating strong performance in both sales and profit across most quarters. However, in Q2, they fall into the low sales, low profit quadrant, suggesting weaker performance during this period. They also have the lowest profit margin in Q2.\nCoastal Routes consistently rank above the 50th percentile in profitability across all quarters, reinforcing their high-margin nature. However, sales performance fluctuates, with sales falling below the 50th percentile in three out of four quarters.\nTransoceanic Routes consistently rank below the 50th percentile in profitability across all quarters. Their sales performance is weakest in Q1 and Q2 but show improvement in Q3 and Q4. These routes exhibit the lowest profitability and sales in Q1 and Q2.\nShort-Haul Routes exhibit the lowest profitability and sales in Q3 and Q4, replacing Transoceanic Routes as the weakest performing category in those quarters."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#operational-metrics",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#operational-metrics",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "3.2 Operational Metrics",
    "text": "3.2 Operational Metrics\n\n3.2.1 Average Load Percentage by Ship Types Across Route Types\nThis section examines the distribution of average load percentage across different ship types and routes types. By visualising the density distribution of load percentage, this section aims to understand how efficiently different ship types utilise their cargo capacity on various routes.\nThe code chunk below plots the density distributions of average load percentage for different ship types across route types using geom_density. A reference line representing the median load percentage for each route type is added to provide a benchmark for further interpretation.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| fig-width: 12\n#| fig-height: 8\n\nfiltered_data2 &lt;- ship_data %&gt;%\n  filter(Ship_Type != \"None\", Route_Type != \"None\")\n\nmedian_values &lt;- filtered_data2 %&gt;%\n  group_by(Route_Type) %&gt;%\n  summarise(Median_Load = median(Average_Load_Percentage, na.rm = TRUE), .groups = \"drop\")\n\n\nggplot(filtered_data2, aes(x = Average_Load_Percentage, color = Ship_Type)) +\n  geom_density(alpha = 0.7) +  \n  geom_vline(data = median_values, aes(xintercept = Median_Load), \n             linetype = \"dashed\", size = 0.5, color = \"black\") +\n  geom_text(data = median_values, \n            aes(x = Median_Load, y = 0, \n                label = sprintf(\"Median: %.1f%%\", Median_Load)), \n            hjust = 1.1, vjust = -1.5, size = 2.5, color = \"black\") + \n  labs(\n    title = \"Average Load Percentage by Ship Types Across Routes\",\n    x = \"Average Load Percentage (%)\",\n    y = \"Density\",\n    color = \"Ship Type\"\n  ) +\n  facet_wrap(~ Route_Type, ncol = 2) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nCoastal Routes: Tankers exhibit a left-skewed distribution, with a distinct peak in the 90% - 95% range, indicating a higher frequency of tankers operating at high load capacities. In contrast, other ship types demonstrate a more uniform distribution.\nLong-Haul Routes: All ship types exhibit a relatively uniform distribution.\nShort-Haul Routes: Container Ships exhibit a right-skewed distribution, with a peak in the 60% - 65% range, indicating a higher frequency of container ships operating with lower load capacities. In contrast, both Bulk Carriers and Tankers exhibit a left-skew distribution, suggesting a tendency toward higher load capacities.\nTransoceanic Routes: Most ship types exhibit a relatively uniform distribution, except for Bulk Carriers, which display a distinct peak in the 80% - 85% range. This indicates a higher concentration of bulk carriers operating within this load percentage.\n\n\n\n\n\n3.2.2 Number of Voyages and Cargo Weight by Route Types\nThis section analyses the number of voyages and cargo weight across different route types over the observed period. By visualising this data, we can identify trends, such as which routes experience higher shipping volumes and whether voyage frequency aligns with cargo weight trends.\nThe code chunk below aggregates the total number of voyages and cargo weight (in tons) for each route type by quarter. A bar chart is used to represent the number of voyages, while a line chart overlays the total cargo weight to show the relationship between voyage frequency and cargo volume.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| fig-width: 12\n#| fig-height: 8\n\nlibrary(scales)\n\nfiltered_data3 &lt;- ship_data %&gt;%\n  filter(Route_Type != \"None\") %&gt;%\n  filter(!(year(Month) == 2023 & month(Month) == 6)) %&gt;%\n  mutate(\n    Quarter = case_when(\n      month(Month) %in% 7:9  ~ \"Q1\",  \n      month(Month) %in% 10:12 ~ \"Q2\", \n      month(Month) %in% 1:3  ~ \"Q3\",  \n      month(Month) %in% 4:6  ~ \"Q4\"\n    )\n  ) %&gt;%\n  filter(!is.na(Quarter)) \n\nsummary_data &lt;- filtered_data3 %&gt;%\n  group_by(Quarter, Route_Type) %&gt;%\n  summarise(\n    Total_Voyages = sum(Weekly_Voyage_Count, na.rm = TRUE),\n    Total_Cargo_Weight = sum(Cargo_Weight_tons, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nmax_voyages &lt;- max(summary_data$Total_Voyages, na.rm = TRUE)\nmax_cargo &lt;- max(summary_data$Total_Cargo_Weight, na.rm = TRUE)\nscaling_factor &lt;- max_voyages / max_cargo\n\n\nggplot(summary_data, aes(x = Route_Type)) +\n  \n  geom_col(aes(y = Total_Voyages, fill = Route_Type), position = \"dodge\", alpha = 0.7) +\n  \n  geom_line(aes(y = Total_Cargo_Weight * scaling_factor, group = 1, color = \"Total Cargo Weight (Tons)\"), size = 1.2) +\n  geom_point(aes(y = Total_Cargo_Weight * scaling_factor, color = \"Total Cargo Weight (Tons)\"), size = 2) +\n\n  scale_y_continuous(\n    name = \"Total Number of Voyages\",\n    labels = comma_format(),  \n    sec.axis = sec_axis(~ . / scaling_factor, name = \"Total Cargo Weight (Tons)\", labels = comma_format())\n  ) +\n  \n  scale_color_manual(name = \" \", values = c(\"Total Cargo Weight (Tons)\" = \"black\")) +  \n\n  labs(\n    title = \"Number of Voyages and Cargo Weight (Tons) by Route Type\",\n    x = NULL, \n    fill = \"Route Type\"\n  ) +\n  facet_wrap(~ Quarter, ncol = 2) + \n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = -0.2, size = 14, face = \"bold\"),\n    panel.spacing = unit(1, \"cm\"),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nShort-haul Routes recorded the highest number of voyages and cargo weight in Q2. However, it was followed by a significant decreased in Q3 and Q4, recording the lowest number of voyages and total cargo weight.\nTransoceanic Routes had the lowest number of voyages and total cargo weight in Q1 and Q2, but saw a significant increase in Q3 and Q4, making them the busiest route type in the second half of the year.\nLong-haul Routes maintained a relatively stable number of voyages and total cargo weight throughout the observed period.\nCoastal Routes experienced lower voyage activity in Q1 and Q4, with slightly higher voyage counts in Q2 and Q3.\nCargo weight generally followed the same trend as the number of voyages, with the exception of Q1."
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex05/In-Class_Ex05.html",
    "href": "In-Class Exercise/In-Class_Ex05/In-Class_Ex05.html",
    "title": "In-class Exercise 5.0",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, SmartEDA, easystats, gtsummary, ggstatsplot)\n\n\n\n\n\ncar_resale &lt;-\n  read_xls(\"data/ToyotaCorolla - Copy.xls\", \"data\")"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex05/In-Class_Ex05.html#installing-and-launching-the-r-packages",
    "href": "In-Class Exercise/In-Class_Ex05/In-Class_Ex05.html#installing-and-launching-the-r-packages",
    "title": "In-class Exercise 5.0",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, SmartEDA, easystats, gtsummary, ggstatsplot)"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex05/In-Class_Ex05.html#importing-data",
    "href": "In-Class Exercise/In-Class_Ex05/In-Class_Ex05.html#importing-data",
    "title": "In-class Exercise 5.0",
    "section": "",
    "text": "car_resale &lt;-\n  read_xls(\"data/ToyotaCorolla - Copy.xls\", \"data\")"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#financial-performance",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#financial-performance",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "4.1 Financial Performance",
    "text": "4.1 Financial Performance\nGenerally, shipping operations remained profitable throughout the observed period. Fluctuations in revenue and costs aligned with variations in total cargo weight, suggesting a positive correlation between shipping volume and financial performance.\nFish Carriers achieved the highest profitability while Tankers had the lowest profitability. Similarly, Long-haul Routes consistently outperformed other routes in both sales and profit, except in Q2. Transoceanic Routes had the weakest performance in Q1 and Q2 while Short-haul Routes recorded the weakest performance in Q3 and Q4."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#operational-performance",
    "href": "Take-Home Exercise/Take-Home_Ex01/Take-Home_Ex01b.html#operational-performance",
    "title": "Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default",
    "section": "4.2 Operational Performance",
    "text": "4.2 Operational Performance\nA higher proportion of tankers operate at higher load capacities on Coastal and Short-haul routes. However, a higher proportion of Container Ships operate at lower load capacities on Short-haul Routes.\nTotal cargo weight generally followed the same trend as the number of voyages, with Short-haul Routes recording the lowest number of voyages and cargo weight in Q3 and Q4."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#overall-exports-and-imports-of-services-2020---2024",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#overall-exports-and-imports-of-services-2020---2024",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "2.2 Overall Exports and Imports of Services, 2020 - 2024",
    "text": "2.2 Overall Exports and Imports of Services, 2020 - 2024\n\n2.2.1 Data Import\nThe data for Overall Exports and Imports of Services, 2020 - 2024 can be found here. The following code chunk uses the read_csv() function to import the servicestrade.csv\n\nservicetrade &lt;- read_csv(\"data/servicestrade.csv\")\n\n\n\n2.2.2 Understanding the Data\nAfter loading the data was loaded, the glimpse() function was then used to understand its structure and the type of data it contains.\n\nglimpse(servicetrade)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 84\nColumns: 26\n$ ...1  &lt;chr&gt; \"Theme: Trade & Investment\", \"Subject: Trade in Services (TIS)\",…\n$ ...2  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2024.0, 997749.8, 528568.3, …\n$ ...3  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2023.0, 919117.0, 481009.2, …\n$ ...4  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2022.0, 877252.5, 468190.5, …\n$ ...5  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2021.0, 715093.5, 382492.4, …\n$ ...6  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2020.0, 590035.1, 300004.6, …\n$ ...7  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2019.0, 592824.3, 307215.9, …\n$ ...8  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2018.0, 561271.0, 287141.4, …\n$ ...9  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2017.0, 493353.8, 241568.0, …\n$ ...10 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2016.0, 431109.3, 211835.8, …\n$ ...11 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2015.0, 432922.3, 210622.7, …\n$ ...12 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2014.0, 406020.8, 194843.2, …\n$ ...13 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2013.0, 365055.0, 177719.3, …\n$ ...14 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2012.0, 327866.3, 161769.2, …\n$ ...15 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2011.0, 298227.8, 150013.0, …\n$ ...16 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2010.0, 273929.7, 136872.3, …\n$ ...17 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2009.0, 238962.6, 117832.0, …\n$ ...18 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2008.0, 254282.0, 126155.0, …\n$ ...19 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2007.0, 223936.4, 110796.6, …\n$ ...20 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2006.0, 195966.0, 92674.8, 5…\n$ ...21 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2005.0, 167532.8, 75904.8, 3…\n$ ...22 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2004.0, 150911.1, 66795.8, 3…\n$ ...23 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2003.0, 122427.9, 52966.2, 3…\n$ ...24 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2002.0, 109710.5, 49936.3, 3…\n$ ...25 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 2001.0, 102892.5, 46286.1, 1…\n$ ...26 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, \"Million Dollars\", \"2000\", \"9645…\n\n\n\n\n\nThe output of the glimpse() function indicates that there are 84 rows and 26 columns. The first few rows appear to serve as a document header, with entries such as “Theme: Trade & Investment” and “Subject: Trade in Services (TIS)”, followed by several NA cells. The actual data beings in subsequent rows with each column representing a specific year and each row representing various trade-related variables.\n\n\n2.2.3 Data Wrangling\nRemoving Non-Relevant Rows\nGiven the structure of our dataset, particularly the presence of non-data rows at the beginning with a large number of NA values, we will use na.omit() to remove rows containing NA values.\n\ncleaned_servicetrade &lt;- na.omit(servicetrade)\n\nAfter removing the rows containing the NA entries, we used the glimpse() function once again to review the structure of the cleaned dataset.\n\nglimpse(cleaned_servicetrade)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 52\nColumns: 26\n$ ...1  &lt;chr&gt; \"Data Series\", \"Total Trade In Services\", \"Exports Of Services\",…\n$ ...2  &lt;dbl&gt; 2024.0, 997749.8, 528568.3, 471.0, 10820.1, 172971.1, 145993.3, …\n$ ...3  &lt;dbl&gt; 2023.0, 919117.0, 481009.2, 490.7, 10981.0, 149537.4, 124222.5, …\n$ ...4  &lt;dbl&gt; 2022.0, 877252.5, 468190.5, 685.5, 10117.9, 189649.0, 167209.2, …\n$ ...5  &lt;dbl&gt; 2021.0, 715093.5, 382492.4, 489.9, 8833.5, 144220.0, 130499.3, 1…\n$ ...6  &lt;dbl&gt; 2020.0, 590035.1, 300004.6, 236.8, 8172.9, 93560.0, 79857.9, 137…\n$ ...7  &lt;dbl&gt; 2019.0, 592824.3, 307215.9, 266.9, 9663.3, 94272.1, 76545.7, 177…\n$ ...8  &lt;dbl&gt; 2018.0, 561271.0, 287141.4, 370.3, 9410.0, 88888.8, 71746.4, 171…\n$ ...9  &lt;dbl&gt; 2017.0, 493353.8, 241568.0, 247.1, 7712.0, 69993.5, 54547.9, 154…\n$ ...10 &lt;dbl&gt; 2016.0, 431109.3, 211835.8, 284.8, 8418.5, 59213.4, 45873.0, 133…\n$ ...11 &lt;dbl&gt; 2015.0, 432922.3, 210622.7, 346.5, 9315.2, 64097.1, 50798.1, 132…\n$ ...12 &lt;dbl&gt; 2014.0, 406020.8, 194843.2, 424.4, 9853.1, 63918.8, 50917.2, 130…\n$ ...13 &lt;dbl&gt; 2013.0, 365055.0, 177719.3, 283.2, 10767.2, 57830.9, 45929.4, 11…\n$ ...14 &lt;dbl&gt; 2012.0, 327866.3, 161769.2, 249.6, 9053.1, 55586.3, 42864.3, 127…\n$ ...15 &lt;dbl&gt; 2011.0, 298227.8, 150013.0, 260.4, 9342.9, 53523.0, 41416.7, 121…\n$ ...16 &lt;dbl&gt; 2010.0, 273929.7, 136872.3, 289.5, 8648.4, 52606.6, 41214.6, 113…\n$ ...17 &lt;dbl&gt; 2009.0, 238962.6, 117832.0, 323.4, 9128.1, 43365.7, 33042.6, 103…\n$ ...18 &lt;dbl&gt; 2008.0, 254282.0, 126155.0, 452.1, 8354.6, 51108.8, 38561.9, 125…\n$ ...19 &lt;dbl&gt; 2007.0, 223936.4, 110796.6, 492.6, 6605.6, 43642.8, 31104.6, 125…\n$ ...20 &lt;dbl&gt; 2006.0, 195966.0, 92674.8, 534.7, 5701.0, 35877.1, 24748.0, 1112…\n$ ...21 &lt;dbl&gt; 2005.0, 167532.8, 75904.8, 315.0, 4797.7, 32435.1, 21286.1, 1114…\n$ ...22 &lt;dbl&gt; 2004.0, 150911.1, 66795.8, 353.2, 3450.5, 28630.3, 18702.3, 9928…\n$ ...23 &lt;dbl&gt; 2003.0, 122427.9, 52966.2, 303.1, 2883.1, 23343.2, 15022.2, 8321…\n$ ...24 &lt;dbl&gt; 2002.0, 109710.5, 49936.3, 369.5, 3071.8, 21539.3, 12656.8, 8882…\n$ ...25 &lt;dbl&gt; 2001.0, 102892.5, 46286.1, 195.0, 2099.5, 20497.9, 12079.2, 8418…\n$ ...26 &lt;chr&gt; \"2000\", \"96452.4\", \"44854.8\", \"202.4\", \"1755.3\", \"20379.3\", \"115…\n\n\n\n\n\nThe output shows that we have successfully excluded non-relevant rows and retained only the actual trade-related data.\nTransposing the Data\nNext, since our columns year data, we need to transpose the dataset to improve its usability for subsequent data visualisation or time-series analysis. The years will be consolidated into a single column, transforming them into row identifiers, while trade-related variables will now be represented as columns.\nThe code chunk uses the t() function for transposing and the as.data.frame() function to ensure that the transposed data remains in a dataframe format:\n\ntransposed_servicetrade &lt;- as.data.frame(t(cleaned_servicetrade))\n\n# Set the first row as column names\ncolnames(transposed_servicetrade) &lt;- as.character(transposed_servicetrade[1, ])\n\n# Remove the first row from the data frame\ntransposed_servicetrade &lt;- transposed_servicetrade[-1, ]\n\nAfter transposing, we examined the structure of the resulting data frame using the glimpse() function.\n\nglimpse(transposed_servicetrade)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 25\nColumns: 52\n$ `Data Series`                                               &lt;chr&gt; \"  2024.0\"…\n$ `Total Trade In Services`                                   &lt;chr&gt; \"997749.8\"…\n$ `Exports Of Services`                                       &lt;chr&gt; \"528568.3\"…\n$ `Manufacturing Services On Physical Inputs Owned By Others` &lt;chr&gt; \"   471.0\"…\n$ `Maintenance And Repair Services`                           &lt;chr&gt; \" 10820.1\"…\n$ Transport                                                   &lt;chr&gt; \"172971.1\"…\n$ Freight                                                     &lt;chr&gt; \"145993.3\"…\n$ Others                                                      &lt;chr&gt; \" 26977.8\"…\n$ Travel                                                      &lt;chr&gt; \" 31867.3\"…\n$ Insurance                                                   &lt;chr&gt; \" 12649.8\"…\n$ `Government Goods And Services`                             &lt;chr&gt; \"   477.3\"…\n$ Construction                                                &lt;chr&gt; \"  2100.8\"…\n$ Financial                                                   &lt;chr&gt; \" 71582.7\"…\n$ `Telecommunications, Computer & Information`                &lt;chr&gt; \" 41149.8\"…\n$ `Charges For The Use Of Intellectual Property`              &lt;chr&gt; \" 26255.8\"…\n$ `Personal, Cultural And Recreational`                       &lt;chr&gt; \"  4831.0\"…\n$ `Other Business Services`                                   &lt;chr&gt; \"153391.6\"…\n$ Accounting                                                  &lt;chr&gt; \"   828.1\"…\n$ `Advertising And Market Research`                           &lt;chr&gt; \" 67492.1\"…\n$ Architectural                                               &lt;chr&gt; \"   551.8\"…\n$ `Business Management`                                       &lt;chr&gt; \" 45864.5\"…\n$ `Engineering And Technical`                                 &lt;chr&gt; \" 12668.6\"…\n$ Legal                                                       &lt;chr&gt; \"  1743.4\"…\n$ `Research And Development`                                  &lt;chr&gt; \"  1712.3\"…\n$ `Operating Leasing`                                         &lt;chr&gt; \"  6722.5\"…\n$ `Trade-Related`                                             &lt;chr&gt; \" 13495.7\"…\n$ Others                                                      &lt;chr&gt; \"  2312.6\"…\n$ `Imports Of Services`                                       &lt;chr&gt; \"469181.5\"…\n$ `Manufacturing Services On Physical Inputs Owned By Others` &lt;chr&gt; \"  9865.1\"…\n$ `Maintenance And Repair Services`                           &lt;chr&gt; \"  1891.0\"…\n$ Transport                                                   &lt;chr&gt; \"162013.4\"…\n$ Freight                                                     &lt;chr&gt; \"116964.9\"…\n$ Others                                                      &lt;chr&gt; \" 45048.5\"…\n$ Travel                                                      &lt;chr&gt; \" 41790.5\"…\n$ Insurance                                                   &lt;chr&gt; \" 10605.2\"…\n$ `Government Goods And Services`                             &lt;chr&gt; \"   383.7\"…\n$ Construction                                                &lt;chr&gt; \"  1010.4\"…\n$ Financial                                                   &lt;chr&gt; \" 23225.3\"…\n$ `Telecommunications, Computer & Information`                &lt;chr&gt; \" 43523.1\"…\n$ `Charges For The Use Of Intellectual Property`              &lt;chr&gt; \" 24062.5\"…\n$ `Personal, Cultural And Recreational`                       &lt;chr&gt; \"  1819.6\"…\n$ `Other Business Services`                                   &lt;chr&gt; \"148991.7\"…\n$ Accounting                                                  &lt;chr&gt; \"  1180.6\"…\n$ `Advertising And Market Research`                           &lt;chr&gt; \" 30918.1\"…\n$ Architectural                                               &lt;chr&gt; \"    57.8\"…\n$ `Business Management`                                       &lt;chr&gt; \" 50386.2\"…\n$ `Engineering And Technical`                                 &lt;chr&gt; \"  7910.0\"…\n$ Legal                                                       &lt;chr&gt; \"  1009.5\"…\n$ `Research And Development`                                  &lt;chr&gt; \" 30345.1\"…\n$ `Operating Leasing`                                         &lt;chr&gt; \"  7291.2\"…\n$ `Trade-Related`                                             &lt;chr&gt; \" 19117.6\"…\n$ Others                                                      &lt;chr&gt; \"   775.6\"…\n\n\n\n\n\nFrom the output of glimpse(), the following issues were identified:\n\nThe column that has the dates is now labelled as “Data Series”. We will rename this to “Date”.\nAll data types are character strings (CHR). We will convert the “Date” column to date format and the remaining columns to numeric types for appropriate data handling.\n\nThe following code chunk renames the “Data Series” column to “Date”:\n\ncolnames(transposed_servicetrade)[1] &lt;- \"Date\"\n\nThe following code chunk converts the data types into date and numeric formats accordingly. It also filter out entries from Jan 2015 onwards.\n\n# Set the locale to English for consistent date parsing\nSys.setlocale(\"LC_TIME\", \"C\")\n\n[1] \"C\"\n\ntransposed_servicetrade$Date &lt;- as.Date(paste0(as.integer(transposed_servicetrade$Date), \"-01-01\"), format = \"%Y-%m-%d\")\n\n# Filter for dates from 2015 onwards\nfiltered_servicetrade &lt;- transposed_servicetrade[transposed_servicetrade$Date &gt;= as.Date(\"2015-01-01\"), ]\n\nFurther data preparation and wrangling will be performed in the respective sections to prepare the data for the specific visualisation / analysis."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#loading-the-required-libraries",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#loading-the-required-libraries",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "2.1 Loading the Required Libraries",
    "text": "2.1 Loading the Required Libraries\nThe code chunk below loads the relevant R libraries required for this exercise.\n\npacman::p_load(plotly, ggthemes, tsibble, feasts, fable, seasonal, patchwork, ggplot2, tidyverse, dplyr, lubridate)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#total-merchandise-trade-at-current-prices-2020---2024",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#total-merchandise-trade-at-current-prices-2020---2024",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "2.3 Total Merchandise Trade At Current Prices, 2020 - 2024",
    "text": "2.3 Total Merchandise Trade At Current Prices, 2020 - 2024\n\n2.3.1 Data Import\nThe data for Total Merchandise Trade At Current Prices, 2020 - 2024 can be found here. The follow code chunk uses the read_csv() function to import the merchandisetrade.csv file into R.\n\nmerchandisetrade &lt;- read_csv(\"data/merchandisetrade.csv\")\n\n\n\n2.3.2 Understanding the Data\nAfter loading the data was loaded, the glimpse() function was then used to understand its structure and the type of data it contains.\n\nglimpse(merchandisetrade)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 105\nColumns: 734\n$ ...1   &lt;chr&gt; \"Theme: Trade & Investment\", \"Subject: Merchandise Trade\", \"Top…\n$ ...2   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2025 Jan\", \"114153979.9\", …\n$ ...3   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Dec\", \"116278793.1\", …\n$ ...4   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Nov\", \"110132324.5\", …\n$ ...5   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Oct\", \"107525959.8\", …\n$ ...6   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Sep\", \"103512459.9\", …\n$ ...7   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Aug\", \"105709528.1\", …\n$ ...8   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Jul\", \"112193161.2\", …\n$ ...9   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Jun\", \"100854308.9\", …\n$ ...10  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 May\", \"109494399.7\", …\n$ ...11  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Apr\", \"108724422.7\", …\n$ ...12  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Mar\", \"108379073.7\", …\n$ ...13  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Feb\", \"96121143.1\", \"…\n$ ...14  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Jan\", \"106938892.7\", …\n$ ...15  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Dec\", \"97730166.2\", \"…\n$ ...16  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Nov\", \"104964764.1\", …\n$ ...17  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Oct\", \"109959513.4\", …\n$ ...18  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Sep\", \"103395782.6\", …\n$ ...19  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Aug\", \"102822761.5\", …\n$ ...20  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Jul\", \"98876159.7\", \"…\n$ ...21  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Jun\", \"99800672.3\", \"…\n$ ...22  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 May\", \"96292627\", \"17…\n$ ...23  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Apr\", \"94275864.7\", \"…\n$ ...24  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Mar\", \"110665037.4\", …\n$ ...25  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Feb\", \"93025120.2\", \"…\n$ ...26  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Jan\", \"93914081.9\", \"…\n$ ...27  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Dec\", \"104869854\", \"2…\n$ ...28  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Nov\", \"104816687.4\", …\n$ ...29  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Oct\", \"109759290.9\", …\n$ ...30  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Sep\", \"118306444\", \"2…\n$ ...31  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Aug\", \"121829757.2\", …\n$ ...32  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Jul\", \"125154364.8\", …\n$ ...33  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Jun\", \"123826212.3\", …\n$ ...34  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 May\", \"117451686.9\", …\n$ ...35  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Apr\", \"116353344.9\", …\n$ ...36  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Mar\", \"121212560.9\", …\n$ ...37  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Feb\", \"96949830.4\", \"…\n$ ...38  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Jan\", \"104872484.8\", …\n$ ...39  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Dec\", \"113563150.5\", …\n$ ...40  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Nov\", \"107395038.7\", …\n$ ...41  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Oct\", \"101584554.8\", …\n$ ...42  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Sep\", \"98014412.4\", \"…\n$ ...43  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Aug\", \"96753013\", \"15…\n$ ...44  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Jul\", \"95941798.1\", \"…\n$ ...45  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Jun\", \"94658839.2\", \"…\n$ ...46  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 May\", \"88914921.6\", \"…\n$ ...47  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Apr\", \"95761442.6\", \"…\n$ ...48  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Mar\", \"103112519.2\", …\n$ ...49  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Feb\", \"80245891.3\", \"…\n$ ...50  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Jan\", \"84017449.2\", \"…\n$ ...51  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Dec\", \"86401426\", \"11…\n$ ...52  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Nov\", \"81769816.3\", \"…\n$ ...53  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Oct\", \"82262179.1\", \"…\n$ ...54  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Sep\", \"82708848\", \"11…\n$ ...55  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Aug\", \"80805918.9\", \"…\n$ ...56  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Jul\", \"80736330.3\", \"…\n$ ...57  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Jun\", \"75761657.7\", \"…\n$ ...58  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 May\", \"67940497.1\", \"…\n$ ...59  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Apr\", \"75825423.9\", \"…\n$ ...60  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Mar\", \"86233047.8\", \"…\n$ ...61  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Feb\", \"82984957\", \"16…\n$ ...62  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Jan\", \"85681880.8\", \"…\n$ ...63  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Dec\", \"86644318.8\", \"…\n$ ...64  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Nov\", \"88248629.3\", \"…\n$ ...65  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Oct\", \"89111010.5\", \"…\n$ ...66  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Sep\", \"82944944.7\", \"…\n$ ...67  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Aug\", \"86156104.5\", \"…\n$ ...68  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Jul\", \"87420995.7\", \"…\n$ ...69  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Jun\", \"80403917.6\", \"…\n$ ...70  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 May\", \"89269126.2\", \"…\n$ ...71  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Apr\", \"85433686.5\", \"…\n$ ...72  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Mar\", \"84572200\", \"14…\n$ ...73  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Feb\", \"75937043.3\", \"…\n$ ...74  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Jan\", \"86084504.8\", \"…\n$ ...75  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Dec\", \"86058910.3\", \"…\n$ ...76  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Nov\", \"93814550.4\", \"…\n$ ...77  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Oct\", \"98783433.4\", \"…\n$ ...78  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Sep\", \"87289929.6\", \"…\n$ ...79  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Aug\", \"94250763.9\", \"…\n$ ...80  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Jul\", \"93279293.5\", \"…\n$ ...81  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Jun\", \"86748323.6\", \"…\n$ ...82  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 May\", \"91247498.4\", \"…\n$ ...83  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Apr\", \"82874846.6\", \"…\n$ ...84  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Mar\", \"85347638.7\", \"…\n$ ...85  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Feb\", \"73545913\", \"16…\n$ ...86  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Jan\", \"82618004.4\", \"…\n$ ...87  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Dec\", \"84697494.7\", \"…\n$ ...88  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Nov\", \"87363139.7\", \"…\n$ ...89  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Oct\", \"83086700.1\", \"…\n$ ...90  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Sep\", \"76911014.7\", \"…\n$ ...91  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Aug\", \"83167698.8\", \"…\n$ ...92  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Jul\", \"79504111.4\", \"…\n$ ...93  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Jun\", \"78740858.7\", \"…\n$ ...94  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 May\", \"83094746.9\", \"…\n$ ...95  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Apr\", \"74973091.6\", \"…\n$ ...96  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Mar\", \"86060240\", \"17…\n$ ...97  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Feb\", \"72372935.7\", \"…\n$ ...98  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Jan\", \"77130382.4\", \"…\n$ ...99  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Dec\", \"83794770.7\", \"…\n$ ...100 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Nov\", \"79372049.5\", \"…\n$ ...101 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Oct\", \"73575640.3\", \"…\n$ ...102 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Sep\", \"72450494.6\", \"…\n$ ...103 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Aug\", \"72155962\", \"11…\n$ ...104 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Jul\", \"70069579.1\", \"…\n$ ...105 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Jun\", \"73370914.2\", \"…\n$ ...106 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 May\", \"71830063.6\", \"…\n$ ...107 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Apr\", \"71014960.5\", \"…\n$ ...108 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Mar\", \"72481976.9\", \"…\n$ ...109 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Feb\", \"63342636.3\", \"…\n$ ...110 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Jan\", \"66757163.4\", \"…\n$ ...111 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Dec\", \"75472970.5\", \"…\n$ ...112 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Nov\", \"72782687.7\", \"…\n$ ...113 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Oct\", \"79471169.3\", \"…\n$ ...114 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Sep\", \"75845721.2\", \"…\n$ ...115 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Aug\", \"73760090.3\", \"…\n$ ...116 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Jul\", \"80314624.8\", \"…\n$ ...117 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Jun\", \"77939565.4\", \"…\n$ ...118 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 May\", \"72991940.3\", \"…\n$ ...119 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Apr\", \"79096446.2\", \"…\n$ ...120 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Mar\", \"85166186.1\", \"…\n$ ...121 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Feb\", \"64476544.2\", \"…\n$ ...122 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Jan\", \"77900845.3\", \"…\n$ ...123 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Dec\", \"80529402\", \"15…\n$ ...124 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Nov\", \"77414200.7\", \"…\n$ ...125 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Oct\", \"86236478.1\", \"…\n$ ...126 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Sep\", \"85831628.1\", \"…\n$ ...127 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Aug\", \"80280884.5\", \"…\n$ ...128 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Jul\", \"84410904.3\", \"…\n$ ...129 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Jun\", \"81821835.1\", \"…\n$ ...130 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 May\", \"85571038.1\", \"…\n$ ...131 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Apr\", \"89000350.8\", \"…\n$ ...132 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Mar\", \"89094505.9\", \"…\n$ ...133 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Feb\", \"78349170.8\", \"…\n$ ...134 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Jan\", \"86109609.4\", \"…\n$ ...135 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Dec\", \"81200008\", \"20…\n$ ...136 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Nov\", \"82011098.6\", \"…\n$ ...137 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Oct\", \"92787692\", \"24…\n$ ...138 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Sep\", \"86777870.7\", \"…\n$ ...139 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Aug\", \"84320793.5\", \"…\n$ ...140 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Jul\", \"90009610.8\", \"…\n$ ...141 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Jun\", \"82677399.9\", \"…\n$ ...142 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 May\", \"87712430.7\", \"…\n$ ...143 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Apr\", \"87749589.3\", \"…\n$ ...144 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Mar\", \"80374024.3\", \"…\n$ ...145 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Feb\", \"72915521\", \"22…\n$ ...146 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Jan\", \"82541864.9\", \"…\n$ ...147 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Dec\", \"77025317.8\", \"…\n$ ...148 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Nov\", \"82566343.6\", \"…\n$ ...149 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Oct\", \"85517037.3\", \"…\n$ ...150 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Sep\", \"79724773.8\", \"…\n$ ...151 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Aug\", \"80477594.7\", \"…\n$ ...152 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Jul\", \"81505716\", \"20…\n$ ...153 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Jun\", \"85050940.9\", \"…\n$ ...154 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 May\", \"87356484.1\", \"…\n$ ...155 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Apr\", \"84516566.8\", \"…\n$ ...156 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Mar\", \"89820321.3\", \"…\n$ ...157 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Feb\", \"85882277.9\", \"…\n$ ...158 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Jan\", \"82100595.1\", \"…\n$ ...159 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Dec\", \"83853527.9\", \"…\n$ ...160 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Nov\", \"85068675.9\", \"…\n$ ...161 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Oct\", \"84146679.4\", \"…\n$ ...162 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Sep\", \"84307189.4\", \"…\n$ ...163 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Aug\", \"87336076.5\", \"…\n$ ...164 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Jul\", \"79908645.1\", \"…\n$ ...165 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Jun\", \"83057330.8\", \"…\n$ ...166 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 May\", \"82396879.4\", \"…\n$ ...167 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Apr\", \"81282034.2\", \"…\n$ ...168 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Mar\", \"89761340.1\", \"…\n$ ...169 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Feb\", \"69089869\", \"19…\n$ ...170 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Jan\", \"81350559.3\", \"…\n$ ...171 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Dec\", \"77966152.5\", \"…\n$ ...172 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Nov\", \"75568476.6\", \"…\n$ ...173 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Oct\", \"78325836\", \"17…\n$ ...174 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Sep\", \"77178033\", \"18…\n$ ...175 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Aug\", \"79150240.7\", \"…\n$ ...176 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Jul\", \"79676629.1\", \"…\n$ ...177 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Jun\", \"78694903.3\", \"…\n$ ...178 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 May\", \"72205358.8\", \"…\n$ ...179 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Apr\", \"77364598.8\", \"…\n$ ...180 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Mar\", \"77368439.8\", \"…\n$ ...181 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Feb\", \"63856067.1\", \"…\n$ ...182 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Jan\", \"69681291.3\", \"…\n$ ...183 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Dec\", \"71029541.6\", \"…\n$ ...184 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Nov\", \"67108157.6\", \"…\n$ ...185 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Oct\", \"68414179.7\", \"…\n$ ...186 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Sep\", \"68456728.5\", \"…\n$ ...187 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Aug\", \"64307849.4\", \"…\n$ ...188 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Jul\", \"66963504.1\", \"…\n$ ...189 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Jun\", \"61952063.4\", \"…\n$ ...190 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 May\", \"57938152.1\", \"…\n$ ...191 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Apr\", \"59246226.4\", \"…\n$ ...192 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Mar\", \"59528603.3\", \"…\n$ ...193 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Feb\", \"54165921.4\", \"…\n$ ...194 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Jan\", \"52189843.3\", \"…\n$ ...195 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Dec\", \"59211487.9\", \"…\n$ ...196 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Nov\", \"67148353\", \"14…\n$ ...197 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Oct\", \"78459916.4\", \"…\n$ ...198 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Sep\", \"85240482.8\", \"…\n$ ...199 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Aug\", \"81399600.3\", \"…\n$ ...200 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Jul\", \"88744688.6\", \"…\n$ ...201 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Jun\", \"83194163.9\", \"…\n$ ...202 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 May\", \"79559914.9\", \"…\n$ ...203 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Apr\", \"83071447.7\", \"…\n$ ...204 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Mar\", \"79079467\", \"18…\n$ ...205 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Feb\", \"69842221.4\", \"…\n$ ...206 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Jan\", \"81363940.9\", \"…\n$ ...207 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Dec\", \"72788487.2\", \"…\n$ ...208 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Nov\", \"75063525.9\", \"…\n$ ...209 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Oct\", \"78189401.5\", \"…\n$ ...210 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Sep\", \"71929205.2\", \"…\n$ ...211 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Aug\", \"72833825.3\", \"…\n$ ...212 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Jul\", \"73669127.1\", \"…\n$ ...213 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Jun\", \"72476997.6\", \"…\n$ ...214 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 May\", \"68746903.3\", \"…\n$ ...215 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Apr\", \"68387572.3\", \"…\n$ ...216 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Mar\", \"71254516.6\", \"…\n$ ...217 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Feb\", \"58789691.4\", \"…\n$ ...218 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Jan\", \"68361570.6\", \"…\n$ ...219 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Dec\", \"68954969.8\", \"…\n$ ...220 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Nov\", \"69294697.5\", \"…\n$ ...221 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Oct\", \"68077663.5\", \"…\n$ ...222 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Sep\", \"71451021.8\", \"…\n$ ...223 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Aug\", \"72219142.2\", \"…\n$ ...224 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Jul\", \"69368770.5\", \"…\n$ ...225 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Jun\", \"71752930\", \"14…\n$ ...226 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 May\", \"68624261.8\", \"…\n$ ...227 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Apr\", \"62986337.8\", \"…\n$ ...228 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Mar\", \"69234700.5\", \"…\n$ ...229 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Feb\", \"62940701.9\", \"…\n$ ...230 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Jan\", \"59993900.3\", \"…\n$ ...231 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Dec\", \"67847663.9\", \"…\n$ ...232 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Nov\", \"63761309.4\", \"…\n$ ...233 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Oct\", \"67877583.9\", \"…\n$ ...234 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Sep\", \"63386556\", \"10…\n$ ...235 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Aug\", \"63943439.9\", \"…\n$ ...236 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Jul\", \"59649731\", \"96…\n$ ...237 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Jun\", \"59158726.2\", \"…\n$ ...238 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 May\", \"56773896.3\", \"…\n$ ...239 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Apr\", \"56558394.8\", \"…\n$ ...240 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Mar\", \"59642108.4\", \"…\n$ ...241 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Feb\", \"46908115\", \"65…\n$ ...242 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Jan\", \"52489280.4\", \"…\n$ ...243 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Dec\", \"55568760.6\", \"…\n$ ...244 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Nov\", \"53278515.2\", \"…\n$ ...245 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Oct\", \"56763878.5\", \"…\n$ ...246 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Sep\", \"56673275.2\", \"…\n$ ...247 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Aug\", \"54551785\", \"73…\n$ ...248 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Jul\", \"55788184.1\", \"…\n$ ...249 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Jun\", \"53492814.7\", \"…\n$ ...250 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 May\", \"51759425.7\", \"…\n$ ...251 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Apr\", \"50906345.4\", \"…\n$ ...252 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Mar\", \"53069273\", \"67…\n$ ...253 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Feb\", \"44463508.5\", \"…\n$ ...254 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Jan\", \"44638368.7\", \"…\n$ ...255 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Dec\", \"48554997.7\", \"…\n$ ...256 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Nov\", \"43802442.5\", \"…\n$ ...257 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Oct\", \"48229423.3\", \"…\n$ ...258 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Sep\", \"45816601.9\", \"…\n$ ...259 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Aug\", \"42299447.4\", \"…\n$ ...260 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Jul\", \"43360466.4\", \"…\n$ ...261 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Jun\", \"42077944.4\", \"…\n$ ...262 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 May\", \"40162535.8\", \"…\n$ ...263 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Apr\", \"42072883.2\", \"…\n$ ...264 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Mar\", \"43860167.9\", \"…\n$ ...265 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Feb\", \"36993870.9\", \"…\n$ ...266 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Jan\", \"41986698.9\", \"…\n$ ...267 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Dec\", \"35684824.8\", \"…\n$ ...268 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Nov\", \"38120539.9\", \"…\n$ ...269 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Oct\", \"39326285.3\", \"…\n$ ...270 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Sep\", \"35904949.8\", \"…\n$ ...271 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Aug\", \"37787583\", \"43…\n$ ...272 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Jul\", \"38629707.1\", \"…\n$ ...273 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Jun\", \"36890597.7\", \"…\n$ ...274 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 May\", \"36244503\", \"39…\n$ ...275 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Apr\", \"37718249\", \"44…\n$ ...276 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Mar\", \"35995455.7\", \"…\n$ ...277 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Feb\", \"29527038.2\", \"…\n$ ...278 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2002 Jan\", \"33818023.3\", \"…\n$ ...279 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Dec\", \"32253624.2\", \"…\n$ ...280 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Nov\", \"34625528.7\", \"…\n$ ...281 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Oct\", \"37008944.9\", \"…\n$ ...282 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Sep\", \"32827412.9\", \"…\n$ ...283 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Aug\", \"34943647.4\", \"…\n$ ...284 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Jul\", \"34880396.6\", \"…\n$ ...285 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Jun\", \"35971403.7\", \"…\n$ ...286 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 May\", \"35826204.1\", \"…\n$ ...287 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Apr\", \"35548433.9\", \"…\n$ ...288 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Mar\", \"39548517.5\", \"…\n$ ...289 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Feb\", \"36045003.3\", \"…\n$ ...290 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2001 Jan\", \"36239283.3\", \"…\n$ ...291 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Dec\", \"41782301.1\", \"…\n$ ...292 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Nov\", \"43003500.4\", \"…\n$ ...293 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Oct\", \"44263702.1\", \"…\n$ ...294 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Sep\", \"42916026.1\", \"…\n$ ...295 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Aug\", \"42880027.8\", \"…\n$ ...296 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Jul\", \"40186659.3\", \"…\n$ ...297 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Jun\", \"39739278.5\", \"…\n$ ...298 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 May\", \"38407734.5\", \"…\n$ ...299 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Apr\", \"35025776.7\", \"…\n$ ...300 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Mar\", \"38546733.9\", \"…\n$ ...301 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Feb\", \"31757734.3\", \"…\n$ ...302 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2000 Jan\", \"31491949\", \"37…\n$ ...303 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Dec\", \"36936214.6\", \"…\n$ ...304 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Nov\", \"35331910.5\", \"…\n$ ...305 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Oct\", \"34742341.1\", \"…\n$ ...306 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Sep\", \"34069719.6\", \"…\n$ ...307 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Aug\", \"32465146.8\", \"…\n$ ...308 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Jul\", \"32852660.8\", \"…\n$ ...309 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Jun\", \"32105547.7\", \"…\n$ ...310 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 May\", \"30475820.5\", \"…\n$ ...311 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Apr\", \"31163897\", \"28…\n$ ...312 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Mar\", \"31485379.3\", \"…\n$ ...313 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Feb\", \"24494581.9\", \"…\n$ ...314 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1999 Jan\", \"26307956.1\", \"…\n$ ...315 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Dec\", \"29379108\", \"21…\n$ ...316 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Nov\", \"27602867\", \"23…\n$ ...317 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Oct\", \"28935515\", \"20…\n$ ...318 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Sep\", \"30403223\", \"21…\n$ ...319 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Aug\", \"29295320\", \"21…\n$ ...320 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Jul\", \"30368195\", \"24…\n$ ...321 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Jun\", \"30387660\", \"23…\n$ ...322 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 May\", \"27269816\", \"21…\n$ ...323 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Apr\", \"29115338\", \"24…\n$ ...324 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Mar\", \"33013823\", \"22…\n$ ...325 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Feb\", \"29530419\", \"24…\n$ ...326 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1998 Jan\", \"28325521\", \"24…\n$ ...327 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Dec\", \"34284272\", \"29…\n$ ...328 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Nov\", \"32817829\", \"27…\n$ ...329 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Oct\", \"34523630\", \"29…\n$ ...330 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Sep\", \"34349004\", \"27…\n$ ...331 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Aug\", \"31479244\", \"25…\n$ ...332 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Jul\", \"33460102\", \"27…\n$ ...333 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Jun\", \"30998743\", \"31…\n$ ...334 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 May\", \"31678874\", \"34…\n$ ...335 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Apr\", \"31353836\", \"27…\n$ ...336 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Mar\", \"32204410\", \"28…\n$ ...337 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Feb\", \"24217362\", \"25…\n$ ...338 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1997 Jan\", \"30850383\", \"34…\n$ ...339 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Dec\", \"31043702\", \"30…\n$ ...340 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Nov\", \"30692970\", \"29…\n$ ...341 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Oct\", \"32025621\", \"29…\n$ ...342 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Sep\", \"29425608\", \"28…\n$ ...343 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Aug\", \"28635705\", \"22…\n$ ...344 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Jul\", \"30826321\", \"28…\n$ ...345 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Jun\", \"29152742\", \"27…\n$ ...346 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 May\", \"30061642\", \"30…\n$ ...347 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Apr\", \"30108289\", \"28…\n$ ...348 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Mar\", \"32076758\", \"30…\n$ ...349 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Feb\", \"26562292\", \"25…\n$ ...350 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1996 Jan\", \"30843672\", \"28…\n$ ...351 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Dec\", \"30189911\", \"24…\n$ ...352 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Nov\", \"31194891\", \"22…\n$ ...353 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Oct\", \"31039678\", \"23…\n$ ...354 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Sep\", \"29665051\", \"21…\n$ ...355 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Aug\", \"30652877\", \"24…\n$ ...356 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Jul\", \"29625194\", \"24…\n$ ...357 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Jun\", \"29092975\", \"24…\n$ ...358 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 May\", \"28700250\", \"25…\n$ ...359 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Apr\", \"26384942\", \"21…\n$ ...360 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Mar\", \"28768453\", \"24…\n$ ...361 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Feb\", \"23957862\", \"22…\n$ ...362 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1995 Jan\", \"24556086\", \"22…\n$ ...363 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Dec\", \"27307893\", \"22…\n$ ...364 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Nov\", \"26727765\", \"22…\n$ ...365 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Oct\", \"26893921\", \"22…\n$ ...366 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Sep\", \"27321176\", \"22…\n$ ...367 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Aug\", \"27022867\", \"30…\n$ ...368 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Jul\", \"26053223\", \"24…\n$ ...369 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Jun\", \"26321588\", \"23…\n$ ...370 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 May\", \"25342975\", \"26…\n$ ...371 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Apr\", \"25820372\", \"23…\n$ ...372 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Mar\", \"23984139\", \"21…\n$ ...373 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Feb\", \"18827899\", \"18…\n$ ...374 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1994 Jan\", \"22099165\", \"21…\n$ ...375 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Dec\", \"23293955\", \"23…\n$ ...376 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Nov\", \"21972021\", \"23…\n$ ...377 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Oct\", \"21878085\", \"23…\n$ ...378 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Sep\", \"23359027\", \"25…\n$ ...379 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Aug\", \"21050175\", \"24…\n$ ...380 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Jul\", \"22276134\", \"24…\n$ ...381 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Jun\", \"21695902\", \"25…\n$ ...382 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 May\", \"21076420\", \"24…\n$ ...383 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Apr\", \"21870039\", \"28…\n$ ...384 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Mar\", \"22019533\", \"26…\n$ ...385 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Feb\", \"18987631\", \"23…\n$ ...386 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1993 Jan\", \"17597466\", \"22…\n$ ...387 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Dec\", \"21928057\", \"24…\n$ ...388 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Nov\", \"19764917\", \"27…\n$ ...389 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Oct\", \"19530943\", \"23…\n$ ...390 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Sep\", \"18832282\", \"23…\n$ ...391 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Aug\", \"17682603\", \"21…\n$ ...392 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Jul\", \"19303469\", \"24…\n$ ...393 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Jun\", \"19061391\", \"24…\n$ ...394 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 May\", \"16834013\", \"21…\n$ ...395 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Apr\", \"17190434\", \"22…\n$ ...396 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Mar\", \"18472025\", \"22…\n$ ...397 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Feb\", \"15087414\", \"21…\n$ ...398 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1992 Jan\", \"17193165\", \"24…\n$ ...399 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Dec\", \"16971151\", \"22…\n$ ...400 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Nov\", \"17569101\", \"27…\n$ ...401 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Oct\", \"17874179\", \"23…\n$ ...402 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Sep\", \"17375152\", \"24…\n$ ...403 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Aug\", \"17997204\", \"28…\n$ ...404 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Jul\", \"19520375\", \"28…\n$ ...405 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Jun\", \"18670555\", \"26…\n$ ...406 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 May\", \"18095221\", \"25…\n$ ...407 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Apr\", \"17513364\", \"27…\n$ ...408 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Mar\", \"18523113\", \"28…\n$ ...409 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Feb\", \"16552644\", \"32…\n$ ...410 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1991 Jan\", \"19412377\", \"40…\n$ ...411 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Dec\", \"18804435\", \"35…\n$ ...412 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Nov\", \"18976108\", \"36…\n$ ...413 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Oct\", \"19484208\", \"42…\n$ ...414 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Sep\", \"16682825\", \"29…\n$ ...415 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Aug\", \"17113546\", \"27…\n$ ...416 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Jul\", \"16464565\", \"24…\n$ ...417 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Jun\", \"16573325\", \"22…\n$ ...418 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 May\", \"16569564\", \"24…\n$ ...419 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Apr\", \"15579206\", \"26…\n$ ...420 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Mar\", \"17835810\", \"27…\n$ ...421 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Feb\", \"14979340\", \"23…\n$ ...422 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1990 Jan\", \"15948701\", \"26…\n$ ...423 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Dec\", \"16406934\", \"23…\n$ ...424 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Nov\", \"16670958\", \"26…\n$ ...425 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Oct\", \"16409717\", \"23…\n$ ...426 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Sep\", \"16222652\", \"21…\n$ ...427 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Aug\", \"16466064\", \"24…\n$ ...428 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Jul\", \"14632640\", \"20…\n$ ...429 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Jun\", \"15432765\", \"22…\n$ ...430 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 May\", \"15031724\", \"23…\n$ ...431 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Apr\", \"15562849\", \"22…\n$ ...432 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Mar\", \"15913503\", \"22…\n$ ...433 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Feb\", \"12584527\", \"17…\n$ ...434 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1989 Jan\", \"12645836\", \"19…\n$ ...435 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Dec\", \"15866441\", \"17…\n$ ...436 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Nov\", \"14613743\", \"17…\n$ ...437 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Oct\", \"15726208\", \"18…\n$ ...438 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Sep\", \"14249424\", \"20…\n$ ...439 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Aug\", \"14995639\", \"22…\n$ ...440 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Jul\", \"14385386\", \"21…\n$ ...441 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Jun\", \"14976565\", \"26…\n$ ...442 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 May\", \"13173838\", \"20…\n$ ...443 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Apr\", \"13036559\", \"19…\n$ ...444 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Mar\", \"11763728\", \"19…\n$ ...445 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Feb\", \"12253885\", \"20…\n$ ...446 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1988 Jan\", \"12236559\", \"22…\n$ ...447 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Dec\", \"12552949\", \"22…\n$ ...448 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Nov\", \"12440399\", \"24…\n$ ...449 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Oct\", \"11663744\", \"22…\n$ ...450 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Sep\", \"12097303\", \"26…\n$ ...451 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Aug\", \"10591657\", \"20…\n$ ...452 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Jul\", \"11378341\", \"21…\n$ ...453 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Jun\", \"10448346\", \"19…\n$ ...454 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 May\", \"9875454\", \"177…\n$ ...455 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Apr\", \"10616755\", \"19…\n$ ...456 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Mar\", \"9012296\", \"167…\n$ ...457 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Feb\", \"8969979\", \"194…\n$ ...458 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1987 Jan\", \"9033736\", \"164…\n$ ...459 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Dec\", \"9542443\", \"170…\n$ ...460 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Nov\", \"9118847\", \"175…\n$ ...461 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Oct\", \"9113454\", \"175…\n$ ...462 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Sep\", \"8701368\", \"179…\n$ ...463 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Aug\", \"9032949\", \"169…\n$ ...464 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Jul\", \"8481929\", \"181…\n$ ...465 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Jun\", \"8617548\", \"197…\n$ ...466 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 May\", \"8107353\", \"171…\n$ ...467 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Apr\", \"8988669\", \"217…\n$ ...468 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Mar\", \"8428895\", \"237…\n$ ...469 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Feb\", \"8204219\", \"228…\n$ ...470 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1986 Jan\", \"8193201\", \"231…\n$ ...471 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Dec\", \"8360460\", \"234…\n$ ...472 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Nov\", \"8757073\", \"276…\n$ ...473 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Oct\", \"9071069\", \"311…\n$ ...474 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Sep\", \"8581385\", \"258…\n$ ...475 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Aug\", \"8941592\", \"258…\n$ ...476 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Jul\", \"8349893\", \"255…\n$ ...477 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Jun\", \"8865169\", \"288…\n$ ...478 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 May\", \"8902682\", \"294…\n$ ...479 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Apr\", \"9812541\", \"263…\n$ ...480 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Mar\", \"9097469\", \"315…\n$ ...481 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Feb\", \"8981734\", \"256…\n$ ...482 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1985 Jan\", \"10275331\", \"33…\n$ ...483 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Dec\", \"8479924\", \"197…\n$ ...484 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Nov\", \"10305601\", \"27…\n$ ...485 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Oct\", \"9709161\", \"266…\n$ ...486 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Sep\", \"8740987\", \"249…\n$ ...487 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Aug\", \"9277161\", \"258…\n$ ...488 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Jul\", \"10279572\", \"33…\n$ ...489 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Jun\", \"9288434\", \"281…\n$ ...490 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 May\", \"10136467\", \"30…\n$ ...491 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Apr\", \"8568871\", \"230…\n$ ...492 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Mar\", \"9454289\", \"293…\n$ ...493 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Feb\", \"8075635\", \"273…\n$ ...494 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1984 Jan\", \"10157540\", \"34…\n$ ...495 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Dec\", \"9029214\", \"260…\n$ ...496 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Nov\", \"8992828\", \"297…\n$ ...497 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Oct\", \"8833662\", \"291…\n$ ...498 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Sep\", \"8842977\", \"268…\n$ ...499 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Aug\", \"9255958\", \"291…\n$ ...500 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Jul\", \"8667411\", \"281…\n$ ...501 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Jun\", \"9331520\", \"302…\n$ ...502 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 May\", \"8489857\", \"262…\n$ ...503 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Apr\", \"9339807\", \"301…\n$ ...504 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Mar\", \"8775155\", \"305…\n$ ...505 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Feb\", \"7533919\", \"283…\n$ ...506 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1983 Jan\", \"8566793\", \"315…\n$ ...507 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Dec\", \"8622975\", \"302…\n$ ...508 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Nov\", \"8256747\", \"281…\n$ ...509 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Oct\", \"9175781\", \"384…\n$ ...510 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Sep\", \"8430238\", \"286…\n$ ...511 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Aug\", \"8342091\", \"302…\n$ ...512 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Jul\", \"9077975\", \"323…\n$ ...513 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Jun\", \"8418490\", \"285…\n$ ...514 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 May\", \"9174856\", \"354…\n$ ...515 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Apr\", \"9123512\", \"353…\n$ ...516 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Mar\", \"9377611\", \"340…\n$ ...517 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Feb\", \"8294753\", \"319…\n$ ...518 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1982 Jan\", \"8422338\", \"307…\n$ ...519 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Dec\", \"8742796\", \"311…\n$ ...520 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Nov\", \"7954451\", \"265…\n$ ...521 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Oct\", \"8895568\", \"324…\n$ ...522 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Sep\", \"8535093\", \"291…\n$ ...523 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Aug\", \"8587580\", \"334…\n$ ...524 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Jul\", \"9318592\", \"360…\n$ ...525 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Jun\", \"8210811\", \"261…\n$ ...526 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 May\", \"8560171\", \"303…\n$ ...527 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Apr\", \"8944270\", \"319…\n$ ...528 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Mar\", \"8643079\", \"321…\n$ ...529 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Feb\", \"6825379\", \"247…\n$ ...530 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1981 Jan\", \"9320982\", \"351…\n$ ...531 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Dec\", \"7694598\", \"222…\n$ ...532 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Nov\", \"8018408\", \"263…\n$ ...533 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Oct\", \"8360759\", \"251…\n$ ...534 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Sep\", \"7999543\", \"239…\n$ ...535 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Aug\", \"7691056\", \"267…\n$ ...536 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Jul\", \"8316149\", \"278…\n$ ...537 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Jun\", \"7568582\", \"233…\n$ ...538 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 May\", \"7743877\", \"251…\n$ ...539 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Apr\", \"7681468\", \"244…\n$ ...540 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Mar\", \"7647141\", \"272…\n$ ...541 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Feb\", \"6628180\", \"203…\n$ ...542 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1980 Jan\", \"7447353\", \"215…\n$ ...543 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Dec\", \"6818578\", \"214…\n$ ...544 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Nov\", \"6790714\", \"194…\n$ ...545 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Oct\", \"6139854\", \"167…\n$ ...546 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Sep\", \"6247485\", \"179…\n$ ...547 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Aug\", \"6612035\", \"186…\n$ ...548 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Jul\", \"5962679\", \"160…\n$ ...549 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Jun\", \"5525664\", \"131…\n$ ...550 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 May\", \"5447369\", \"136…\n$ ...551 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Apr\", \"5339240\", \"135…\n$ ...552 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Mar\", \"5116645\", \"123…\n$ ...553 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Feb\", \"4596062\", \"126…\n$ ...554 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1979 Jan\", \"4678197\", \"128…\n$ ...555 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Dec\", \"4661898\", \"107…\n$ ...556 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Nov\", \"4904315\", \"113…\n$ ...557 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Oct\", \"4794022\", \"131…\n$ ...558 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Sep\", \"4581372\", \"131…\n$ ...559 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Aug\", \"4527776\", \"104…\n$ ...560 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Jul\", \"4491517\", \"114…\n$ ...561 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Jun\", \"4382352\", \"116…\n$ ...562 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 May\", \"3977730\", \"101…\n$ ...563 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Apr\", \"4312686\", \"122…\n$ ...564 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Mar\", \"4327432\", \"109…\n$ ...565 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Feb\", \"3411896\", \"874…\n$ ...566 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1978 Jan\", \"4213726\", \"119…\n$ ...567 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Dec\", \"4020278\", \"999…\n$ ...568 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Nov\", \"4015654\", \"113…\n$ ...569 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Oct\", \"3994065\", \"108…\n$ ...570 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Sep\", \"4012879\", \"105…\n$ ...571 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Aug\", \"4075178\", \"114…\n$ ...572 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Jul\", \"3926665\", \"120…\n$ ...573 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Jun\", \"3786276\", \"117…\n$ ...574 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 May\", \"3473583\", \"968…\n$ ...575 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Apr\", \"3823531\", \"102…\n$ ...576 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Mar\", \"3729916\", \"109…\n$ ...577 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Feb\", \"3067312\", \"852…\n$ ...578 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1977 Jan\", \"3686934\", \"838…\n$ ...579 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Dec\", \"3560030\", \"103…\n$ ...580 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Nov\", \"3495886\", \"986…\n$ ...581 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Oct\", \"3516256\", \"103…\n$ ...582 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Sep\", \"3374302\", \"990…\n$ ...583 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Aug\", \"3347979\", \"952…\n$ ...584 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Jul\", \"3547263\", \"107…\n$ ...585 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Jun\", \"2942772\", \"756…\n$ ...586 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 May\", \"2707964\", \"704…\n$ ...587 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Apr\", \"3245711\", \"956…\n$ ...588 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Mar\", \"3042929\", \"757…\n$ ...589 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Feb\", \"2815720\", \"799…\n$ ...590 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1976 Jan\", \"3073525\", \"932…\n$ ...591 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Dec\", \"2854600\", \"746…\n$ ...592 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Nov\", \"2787700\", \"914…\n$ ...593 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Oct\", \"2883300\", \"781…\n$ ...594 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Sep\", \"2752600\", \"693…\n$ ...595 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Aug\", \"2636600\", \"760…\n$ ...596 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Jul\", \"2652500\", \"774…\n$ ...597 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Jun\", \"2438000\", \"513…\n$ ...598 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 May\", \"2635800\", \"718…\n$ ...599 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Apr\", \"2660500\", \"819…\n$ ...600 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Mar\", \"2546700\", \"708…\n$ ...601 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Feb\", \"2483900\", \"838…\n$ ...602 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1975 Jan\", \"2696000\", \"756…\n$ ...603 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Dec\", \"2543100\", \"639…\n$ ...604 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Nov\", \"2783300\", \"770…\n$ ...605 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Oct\", \"2874900\", \"817…\n$ ...606 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Sep\", \"2842800\", \"777…\n$ ...607 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Aug\", \"3145900\", \"819…\n$ ...608 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Jul\", \"2975700\", \"865…\n$ ...609 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Jun\", \"3018700\", \"803…\n$ ...610 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 May\", \"3382000\", \"100…\n$ ...611 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Apr\", \"2888400\", \"818…\n$ ...612 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Mar\", \"3110500\", \"959…\n$ ...613 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Feb\", \"2533200\", \"650…\n$ ...614 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1974 Jan\", \"2460900\", \"515…\n$ ...615 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Dec\", \"2134200\", \"336…\n$ ...616 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Nov\", \"2164800\", \"362…\n$ ...617 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Oct\", \"1922300\", \"281…\n$ ...618 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Sep\", \"1996000\", \"259…\n$ ...619 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Aug\", \"1859700\", \"303…\n$ ...620 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Jul\", \"1787100\", \"303…\n$ ...621 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Jun\", \"1693900\", \"264…\n$ ...622 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 May\", \"1704800\", \"272…\n$ ...623 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Apr\", \"1520300\", \"210…\n$ ...624 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Mar\", \"1649900\", \"276…\n$ ...625 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Feb\", \"1330700\", \"232…\n$ ...626 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1973 Jan\", \"1655900\", \"283…\n$ ...627 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Dec\", \"1451400\", \"223…\n$ ...628 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Nov\", \"1424700\", \"263…\n$ ...629 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Oct\", \"1398800\", \"239…\n$ ...630 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Sep\", \"1383500\", \"288…\n$ ...631 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Aug\", \"1447000\", \"266…\n$ ...632 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Jul\", \"1294700\", \"218…\n$ ...633 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Jun\", \"1225900\", \"221…\n$ ...634 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 May\", \"1328700\", \"245…\n$ ...635 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Apr\", \"1200200\", \"221…\n$ ...636 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Mar\", \"1279200\", \"271…\n$ ...637 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Feb\", \"1079400\", \"215…\n$ ...638 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1972 Jan\", \"1173800\", \"221…\n$ ...639 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Dec\", \"1183500\", \"207…\n$ ...640 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Nov\", \"1159000\", \"205…\n$ ...641 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Oct\", \"1171800\", \"185…\n$ ...642 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Sep\", \"1167100\", \"205…\n$ ...643 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Aug\", \"1178900\", \"227…\n$ ...644 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Jul\", \"1270300\", \"263…\n$ ...645 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Jun\", \"1221000\", \"213…\n$ ...646 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 May\", \"1167900\", \"242…\n$ ...647 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Apr\", \"1188100\", \"229…\n$ ...648 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Mar\", \"1278800\", \"251…\n$ ...649 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Feb\", \"1016800\", \"194…\n$ ...650 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1971 Jan\", \"1023000\", \"194…\n$ ...651 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Dec\", \"1166500\", \"213…\n$ ...652 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Nov\", \"1046600\", \"184…\n$ ...653 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Oct\", \"1062200\", \"179…\n$ ...654 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Sep\", \"1014200\", \"170…\n$ ...655 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Aug\", \"1053300\", \"175…\n$ ...656 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Jul\", \"1056400\", \"185…\n$ ...657 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Jun\", \"1020100\", \"176…\n$ ...658 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 May\", \"1000900\", \"197…\n$ ...659 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Apr\", \"964000\", \"1491…\n$ ...660 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Mar\", \"1002000\", \"175…\n$ ...661 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Feb\", \"842100\", \"1449…\n$ ...662 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1970 Jan\", \"1061300\", \"164…\n$ ...663 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Dec\", \"1007000\", \"208…\n$ ...664 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Nov\", \"969200\", \"1717…\n$ ...665 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Oct\", \"1056800\", \"206…\n$ ...666 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Sep\", \"1004400\", \"175…\n$ ...667 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Aug\", \"910200\", \"1529…\n$ ...668 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Jul\", \"952800\", \"1920…\n$ ...669 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Jun\", \"878500\", \"1570…\n$ ...670 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 May\", \"866200\", \"1795…\n$ ...671 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Apr\", \"864600\", \"1653…\n$ ...672 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Mar\", \"864400\", \"1911…\n$ ...673 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Feb\", \"730000\", \"1720…\n$ ...674 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1969 Jan\", \"880200\", \"1694…\n$ ...675 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Dec\", \"768600\", \"1540…\n$ ...676 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Nov\", \"781000\", \"1585…\n$ ...677 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Oct\", \"793000\", \"1659…\n$ ...678 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Sep\", \"772400\", \"1704…\n$ ...679 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Aug\", \"754900\", \"1667…\n$ ...680 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Jul\", \"789300\", \"1643…\n$ ...681 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Jun\", \"751300\", \"1648…\n$ ...682 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 May\", \"809800\", \"1808…\n$ ...683 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Apr\", \"695700\", \"1296…\n$ ...684 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Mar\", \"733000\", \"1647…\n$ ...685 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Feb\", \"694700\", \"1688…\n$ ...686 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1968 Jan\", \"631000\", \"1500…\n$ ...687 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Dec\", \"668200\", \"1451…\n$ ...688 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Nov\", \"666900\", \"1388…\n$ ...689 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Oct\", \"690900\", \"1483…\n$ ...690 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Sep\", \"668900\", \"1345…\n$ ...691 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Aug\", \"698400\", \"1495…\n$ ...692 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Jul\", \"629400\", \"1265…\n$ ...693 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Jun\", \"665500\", \"1395…\n$ ...694 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 May\", \"689500\", \"1542…\n$ ...695 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Apr\", \"645700\", \"1234…\n$ ...696 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Mar\", \"655600\", \"1236…\n$ ...697 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Feb\", \"607200\", \"1409…\n$ ...698 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1967 Jan\", \"610700\", \"1121…\n$ ...699 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Dec\", \"671800\", \"1313…\n$ ...700 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Nov\", \"629200\", \"1283…\n$ ...701 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Oct\", \"624900\", \"1168…\n$ ...702 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Sep\", \"638900\", \"1266…\n$ ...703 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Aug\", \"645800\", \"1254…\n$ ...704 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Jul\", \"622100\", \"1072…\n$ ...705 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Jun\", \"561200\", \"1079…\n$ ...706 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 May\", \"648500\", \"1218…\n$ ...707 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Apr\", \"575200\", \"1074…\n$ ...708 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Mar\", \"642500\", \"1122…\n$ ...709 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Feb\", \"610000\", \"1152…\n$ ...710 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1966 Jan\", \"569100\", \"9060…\n$ ...711 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Dec\", \"605600\", \"8800…\n$ ...712 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Nov\", \"599700\", \"1075…\n$ ...713 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Oct\", \"565400\", \"9090…\n$ ...714 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Sep\", \"573900\", \"9600…\n$ ...715 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Aug\", \"582500\", \"9380…\n$ ...716 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Jul\", \"554000\", \"7770…\n$ ...717 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Jun\", \"530200\", \"9320…\n$ ...718 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 May\", \"575000\", \"9930…\n$ ...719 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Apr\", \"535700\", \"8900…\n$ ...720 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Mar\", \"611500\", \"9370…\n$ ...721 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Feb\", \"493200\", \"8370…\n$ ...722 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1965 Jan\", \"584600\", \"8870…\n$ ...723 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Dec\", \"542200\", \"7320…\n$ ...724 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Nov\", \"498400\", \"6920…\n$ ...725 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Oct\", \"575000\", \"7940…\n$ ...726 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Sep\", \"542300\", \"8890…\n$ ...727 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Aug\", \"552300\", \"9970…\n$ ...728 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Jul\", \"466000\", \"5710…\n$ ...729 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Jun\", \"532800\", \"8430…\n$ ...730 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 May\", \"513100\", \"9000…\n$ ...731 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Apr\", \"501800\", \"7610…\n$ ...732 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Mar\", \"499800\", \"9160…\n$ ...733 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"1964 Feb\", \"466900\", \"6900…\n$ ...734 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, \"Thousand Dollars\", \"1964 Jan\",…\n\n\n\n\n\nThe output of the glimpse() function indicates that there are 105 rows and 734 columns. The first few rows appear to serve as a document header, with entries such as “Theme: Trade & Investment” and “Subject: Merchandise Trade”, followed by numerous NA cells. The actual trade data likely begins in subsequent rows, with each column representing a specific month and year, and each row representing various trade-related variables.\n\n\n2.3.3 Data Wrangling\nRemoving Non-Relevant Rows\nGiven the structure of our dataset, particularly the presence of non-data rows at the beginning with a large number of NA values, we will use na.omit() to remove rows containing NA values.\n\ncleaned_merchandisetrade &lt;- na.omit(merchandisetrade)\n\nAfter removing the rows containing the NA entries, we used the glimpse() function once again to review the structure of the cleaned dataset.\n\nglimpse(cleaned_merchandisetrade)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 69\nColumns: 734\n$ ...1   &lt;chr&gt; \"Data Series\", \"Total Merchandise Trade, (At Current Prices)\", …\n$ ...2   &lt;chr&gt; \"2025 Jan\", \"114153979.9\", \"19490289.9\", \"16418934.4\", \"3071355…\n$ ...3   &lt;chr&gt; \"2024 Dec\", \"116278793.1\", \"18488973.7\", \"15564654.3\", \"2924319…\n$ ...4   &lt;chr&gt; \"2024 Nov\", \"110132324.5\", \"18061885.1\", \"14910685.5\", \"3151199…\n$ ...5   &lt;chr&gt; \"2024 Oct\", \"107525959.8\", \"17510049.7\", \"14804333.5\", \"2705716…\n$ ...6   &lt;chr&gt; \"2024 Sep\", \"103512459.9\", \"15686653.5\", \"12611958.1\", \"3074695…\n$ ...7   &lt;chr&gt; \"2024 Aug\", \"105709528.1\", \"18423053.5\", \"14910944.4\", \"3512109…\n$ ...8   &lt;chr&gt; \"2024 Jul\", \"112193161.2\", \"21247218.9\", \"17952997.6\", \"3294221…\n$ ...9   &lt;chr&gt; \"2024 Jun\", \"100854308.9\", \"18757682.3\", \"15157705.6\", \"3599976…\n$ ...10  &lt;chr&gt; \"2024 May\", \"109494399.7\", \"22411806.3\", \"19049737.7\", \"3362068…\n$ ...11  &lt;chr&gt; \"2024 Apr\", \"108724422.7\", \"21869533.9\", \"18351817.9\", \"3517716…\n$ ...12  &lt;chr&gt; \"2024 Mar\", \"108379073.7\", \"19893545.9\", \"16361101.8\", \"3532444…\n$ ...13  &lt;chr&gt; \"2024 Feb\", \"96121143.1\", \"21274121.4\", \"17430488.8\", \"3843632.…\n$ ...14  &lt;chr&gt; \"2024 Jan\", \"106938892.7\", \"20018014.6\", \"16984779.4\", \"3033235…\n$ ...15  &lt;chr&gt; \"2023 Dec\", \"97730166.2\", \"17465047.9\", \"14510265.1\", \"2954782.…\n$ ...16  &lt;chr&gt; \"2023 Nov\", \"104964764.1\", \"22309647.9\", \"19044310.7\", \"3265337…\n$ ...17  &lt;chr&gt; \"2023 Oct\", \"109959513.4\", \"22863122.2\", \"19507099.7\", \"3356022…\n$ ...18  &lt;chr&gt; \"2023 Sep\", \"103395782.6\", \"20253469.6\", \"17021949.1\", \"3231520…\n$ ...19  &lt;chr&gt; \"2023 Aug\", \"102822761.5\", \"19934169.9\", \"17031877.2\", \"2902292…\n$ ...20  &lt;chr&gt; \"2023 Jul\", \"98876159.7\", \"17997017.6\", \"15448306.1\", \"2548711.…\n$ ...21  &lt;chr&gt; \"2023 Jun\", \"99800672.3\", \"18269910\", \"15362407.5\", \"2907502.5\"…\n$ ...22  &lt;chr&gt; \"2023 May\", \"96292627\", \"17961001\", \"15052136.1\", \"2908864.9\", …\n$ ...23  &lt;chr&gt; \"2023 Apr\", \"94275864.7\", \"17712039.7\", \"14810718.4\", \"2901321.…\n$ ...24  &lt;chr&gt; \"2023 Mar\", \"110665037.4\", \"20344067.6\", \"17574483.5\", \"2769584…\n$ ...25  &lt;chr&gt; \"2023 Feb\", \"93025120.2\", \"19482789.9\", \"16311184.9\", \"3171605\"…\n$ ...26  &lt;chr&gt; \"2023 Jan\", \"93914081.9\", \"19333981.8\", \"16315749.1\", \"3018232.…\n$ ...27  &lt;chr&gt; \"2022 Dec\", \"104869854\", \"21517221.5\", \"18004300\", \"3512921.6\",…\n$ ...28  &lt;chr&gt; \"2022 Nov\", \"104816687.4\", \"22188941.8\", \"18397118.3\", \"3791823…\n$ ...29  &lt;chr&gt; \"2022 Oct\", \"109759290.9\", \"21070382.7\", \"17450430\", \"3619952.7…\n$ ...30  &lt;chr&gt; \"2022 Sep\", \"118306444\", \"23781790.9\", \"19956640.8\", \"3825150.1…\n$ ...31  &lt;chr&gt; \"2022 Aug\", \"121829757.2\", \"26145313.9\", \"21722917.3\", \"4422396…\n$ ...32  &lt;chr&gt; \"2022 Jul\", \"125154364.8\", \"27729063.9\", \"24001869.3\", \"3727194…\n$ ...33  &lt;chr&gt; \"2022 Jun\", \"123826212.3\", \"26733617.4\", \"22696475.2\", \"4037142…\n$ ...34  &lt;chr&gt; \"2022 May\", \"117451686.9\", \"26630948.8\", \"23096663.4\", \"3534285…\n$ ...35  &lt;chr&gt; \"2022 Apr\", \"116353344.9\", \"24656078.7\", \"21119852.3\", \"3536226…\n$ ...36  &lt;chr&gt; \"2022 Mar\", \"121212560.9\", \"24261438.9\", \"21635340.4\", \"2626098…\n$ ...37  &lt;chr&gt; \"2022 Feb\", \"96949830.4\", \"18208184.6\", \"15424525.4\", \"2783659.…\n$ ...38  &lt;chr&gt; \"2022 Jan\", \"104872484.8\", \"16559716.6\", \"13975438.3\", \"2584278…\n$ ...39  &lt;chr&gt; \"2021 Dec\", \"113563150.5\", \"18812564.9\", \"16112181\", \"2700383.9…\n$ ...40  &lt;chr&gt; \"2021 Nov\", \"107395038.7\", \"20775061.4\", \"18004586\", \"2770475.4…\n$ ...41  &lt;chr&gt; \"2021 Oct\", \"101584554.8\", \"17170762.2\", \"14866171.2\", \"2304591…\n$ ...42  &lt;chr&gt; \"2021 Sep\", \"98014412.4\", \"15532089.1\", \"13311451.7\", \"2220637.…\n$ ...43  &lt;chr&gt; \"2021 Aug\", \"96753013\", \"15924680.7\", \"13590838\", \"2333842.7\", …\n$ ...44  &lt;chr&gt; \"2021 Jul\", \"95941798.1\", \"15372329.8\", \"13116832.7\", \"2255497.…\n$ ...45  &lt;chr&gt; \"2021 Jun\", \"94658839.2\", \"16347755.6\", \"14264552.9\", \"2083202.…\n$ ...46  &lt;chr&gt; \"2021 May\", \"88914921.6\", \"13858660.1\", \"11739474.9\", \"2119185.…\n$ ...47  &lt;chr&gt; \"2021 Apr\", \"95761442.6\", \"15833732.9\", \"13689196.2\", \"2144536.…\n$ ...48  &lt;chr&gt; \"2021 Mar\", \"103112519.2\", \"16162869.9\", \"14088970.3\", \"2073899…\n$ ...49  &lt;chr&gt; \"2021 Feb\", \"80245891.3\", \"12118518.6\", \"10245453.8\", \"1873064.…\n$ ...50  &lt;chr&gt; \"2021 Jan\", \"84017449.2\", \"11541352.4\", \"9850271.3\", \"1691081.1…\n$ ...51  &lt;chr&gt; \"2020 Dec\", \"86401426\", \"11294241.8\", \"9574970.4\", \"1719271.5\",…\n$ ...52  &lt;chr&gt; \"2020 Nov\", \"81769816.3\", \"9425387.2\", \"7844979.8\", \"1580407.4\"…\n$ ...53  &lt;chr&gt; \"2020 Oct\", \"82262179.1\", \"9775647.6\", \"8175370\", \"1600277.6\", …\n$ ...54  &lt;chr&gt; \"2020 Sep\", \"82708848\", \"11795516.8\", \"10130560.6\", \"1664956.2\"…\n$ ...55  &lt;chr&gt; \"2020 Aug\", \"80805918.9\", \"9863398.6\", \"8199347.3\", \"1664051.2\"…\n$ ...56  &lt;chr&gt; \"2020 Jul\", \"80736330.3\", \"9551425.1\", \"8071575.1\", \"1479850\", …\n$ ...57  &lt;chr&gt; \"2020 Jun\", \"75761657.7\", \"8325120.3\", \"7127286.6\", \"1197833.7\"…\n$ ...58  &lt;chr&gt; \"2020 May\", \"67940497.1\", \"5987433.1\", \"4791520.4\", \"1195912.7\"…\n$ ...59  &lt;chr&gt; \"2020 Apr\", \"75825423.9\", \"8883317.1\", \"7166272.9\", \"1717044.2\"…\n$ ...60  &lt;chr&gt; \"2020 Mar\", \"86233047.8\", \"13341738.9\", \"11001386.7\", \"2340352.…\n$ ...61  &lt;chr&gt; \"2020 Feb\", \"82984957\", \"16260785.2\", \"13036890.2\", \"3223895\", …\n$ ...62  &lt;chr&gt; \"2020 Jan\", \"85681880.8\", \"17445557.3\", \"14323092.7\", \"3122464.…\n$ ...63  &lt;chr&gt; \"2019 Dec\", \"86644318.8\", \"14664548\", \"13707755.6\", \"956792.4\",…\n$ ...64  &lt;chr&gt; \"2019 Nov\", \"88248629.3\", \"16136904.6\", \"14741908.1\", \"1394996.…\n$ ...65  &lt;chr&gt; \"2019 Oct\", \"89111010.5\", \"15984781.7\", \"14047900.7\", \"1936881\"…\n$ ...66  &lt;chr&gt; \"2019 Sep\", \"82944944.7\", \"13991364.8\", \"12180066.4\", \"1811298.…\n$ ...67  &lt;chr&gt; \"2019 Aug\", \"86156104.5\", \"14787043.7\", \"12640653.1\", \"2146390.…\n$ ...68  &lt;chr&gt; \"2019 Jul\", \"87420995.7\", \"16351956.2\", \"14392381.6\", \"1959574.…\n$ ...69  &lt;chr&gt; \"2019 Jun\", \"80403917.6\", \"15861794.8\", \"13612250.8\", \"2249544\"…\n$ ...70  &lt;chr&gt; \"2019 May\", \"89269126.2\", \"18960544.9\", \"16854126.8\", \"2106418.…\n$ ...71  &lt;chr&gt; \"2019 Apr\", \"85433686.5\", \"16897538\", \"14629535.9\", \"2268002.1\"…\n$ ...72  &lt;chr&gt; \"2019 Mar\", \"84572200\", \"14968211.2\", \"12977303.1\", \"1990908.1\"…\n$ ...73  &lt;chr&gt; \"2019 Feb\", \"75937043.3\", \"15320497\", \"13160592.9\", \"2159904.2\"…\n$ ...74  &lt;chr&gt; \"2019 Jan\", \"86084504.8\", \"17288329.7\", \"15075508\", \"2212821.7\"…\n$ ...75  &lt;chr&gt; \"2018 Dec\", \"86058910.3\", \"16760637.4\", \"14405808\", \"2354829.4\"…\n$ ...76  &lt;chr&gt; \"2018 Nov\", \"93814550.4\", \"20767906\", \"17775719.7\", \"2992186.3\"…\n$ ...77  &lt;chr&gt; \"2018 Oct\", \"98783433.4\", \"21609973.2\", \"18787432.8\", \"2822540.…\n$ ...78  &lt;chr&gt; \"2018 Sep\", \"87289929.6\", \"17597086.6\", \"14981366.5\", \"2615720.…\n$ ...79  &lt;chr&gt; \"2018 Aug\", \"94250763.9\", \"19251444.8\", \"16644162.5\", \"2607282.…\n$ ...80  &lt;chr&gt; \"2018 Jul\", \"93279293.5\", \"18893126\", \"16392290.9\", \"2500835.1\"…\n$ ...81  &lt;chr&gt; \"2018 Jun\", \"86748323.6\", \"18879193.7\", \"16120211.2\", \"2758982.…\n$ ...82  &lt;chr&gt; \"2018 May\", \"91247498.4\", \"20296586.8\", \"17936923\", \"2359663.8\"…\n$ ...83  &lt;chr&gt; \"2018 Apr\", \"82874846.6\", \"16807418.2\", \"14593953.3\", \"2213464.…\n$ ...84  &lt;chr&gt; \"2018 Mar\", \"85347638.7\", \"16678485.6\", \"14424928.2\", \"2253557.…\n$ ...85  &lt;chr&gt; \"2018 Feb\", \"73545913\", \"16752585.3\", \"14141265.5\", \"2611319.7\"…\n$ ...86  &lt;chr&gt; \"2018 Jan\", \"82618004.4\", \"17680184.4\", \"15427290.3\", \"2252894.…\n$ ...87  &lt;chr&gt; \"2017 Dec\", \"84697494.7\", \"18180142.4\", \"15858526.5\", \"2321615.…\n$ ...88  &lt;chr&gt; \"2017 Nov\", \"87363139.7\", \"17785697.9\", \"15761435.6\", \"2024262.…\n$ ...89  &lt;chr&gt; \"2017 Oct\", \"83086700.1\", \"16448753.4\", \"14282502.1\", \"2166251.…\n$ ...90  &lt;chr&gt; \"2017 Sep\", \"76911014.7\", \"14702593.2\", \"12712741.9\", \"1989851.…\n$ ...91  &lt;chr&gt; \"2017 Aug\", \"83167698.8\", \"15671111.8\", \"13717866.6\", \"1953245.…\n$ ...92  &lt;chr&gt; \"2017 Jul\", \"79504111.4\", \"13121493.5\", \"11439872.6\", \"1681621\"…\n$ ...93  &lt;chr&gt; \"2017 Jun\", \"78740858.7\", \"14145115.4\", \"12184523.8\", \"1960591.…\n$ ...94  &lt;chr&gt; \"2017 May\", \"83094746.9\", \"15998903.4\", \"13930524.9\", \"2068378.…\n$ ...95  &lt;chr&gt; \"2017 Apr\", \"74973091.6\", \"15339409.9\", \"13311724.7\", \"2027685.…\n$ ...96  &lt;chr&gt; \"2017 Mar\", \"86060240\", \"17297617.6\", \"15381590\", \"1916027.7\", …\n$ ...97  &lt;chr&gt; \"2017 Feb\", \"72372935.7\", \"15674843.2\", \"13437011\", \"2237832.1\"…\n$ ...98  &lt;chr&gt; \"2017 Jan\", \"77130382.4\", \"15677846.3\", \"13805309.8\", \"1872536.…\n$ ...99  &lt;chr&gt; \"2016 Dec\", \"83794770.7\", \"14683953.3\", \"12915825.8\", \"1768127.…\n$ ...100 &lt;chr&gt; \"2016 Nov\", \"79372049.5\", \"14015073.6\", \"12229460.4\", \"1785613.…\n$ ...101 &lt;chr&gt; \"2016 Oct\", \"73575640.3\", \"12360951.7\", \"10924035.3\", \"1436916.…\n$ ...102 &lt;chr&gt; \"2016 Sep\", \"72450494.6\", \"12060787.3\", \"10478084\", \"1582703.3\"…\n$ ...103 &lt;chr&gt; \"2016 Aug\", \"72155962\", \"11626696\", \"10044142.6\", \"1582553.4\", …\n$ ...104 &lt;chr&gt; \"2016 Jul\", \"70069579.1\", \"11936414.9\", \"10299450.4\", \"1636964.…\n$ ...105 &lt;chr&gt; \"2016 Jun\", \"73370914.2\", \"13023095.1\", \"11353104.3\", \"1669990.…\n$ ...106 &lt;chr&gt; \"2016 May\", \"71830063.6\", \"11741370.8\", \"10407172\", \"1334198.9\"…\n$ ...107 &lt;chr&gt; \"2016 Apr\", \"71014960.5\", \"10852220.7\", \"9523416.8\", \"1328803.8…\n$ ...108 &lt;chr&gt; \"2016 Mar\", \"72481976.9\", \"9198013.1\", \"8226346.6\", \"971666.5\",…\n$ ...109 &lt;chr&gt; \"2016 Feb\", \"63342636.3\", \"9026808.4\", \"7939860.6\", \"1086947.7\"…\n$ ...110 &lt;chr&gt; \"2016 Jan\", \"66757163.4\", \"9243300.5\", \"7889249.7\", \"1354050.8\"…\n$ ...111 &lt;chr&gt; \"2015 Dec\", \"75472970.5\", \"11276812.7\", \"9588124.5\", \"1688688.1…\n$ ...112 &lt;chr&gt; \"2015 Nov\", \"72782687.7\", \"11236158.7\", \"9649229.8\", \"1586928.8…\n$ ...113 &lt;chr&gt; \"2015 Oct\", \"79471169.3\", \"13060112.1\", \"11382207.7\", \"1677904.…\n$ ...114 &lt;chr&gt; \"2015 Sep\", \"75845721.2\", \"12749190.8\", \"10934942.8\", \"1814248.…\n$ ...115 &lt;chr&gt; \"2015 Aug\", \"73760090.3\", \"13596685\", \"11772621.8\", \"1824063.2\"…\n$ ...116 &lt;chr&gt; \"2015 Jul\", \"80314624.8\", \"18321240\", \"16382325.3\", \"1938914.8\"…\n$ ...117 &lt;chr&gt; \"2015 Jun\", \"77939565.4\", \"16549876.8\", \"14439571.3\", \"2110305.…\n$ ...118 &lt;chr&gt; \"2015 May\", \"72991940.3\", \"14706436.9\", \"12747143.1\", \"1959293.…\n$ ...119 &lt;chr&gt; \"2015 Apr\", \"79096446.2\", \"16200273.7\", \"14310434.3\", \"1889839.…\n$ ...120 &lt;chr&gt; \"2015 Mar\", \"85166186.1\", \"16308462.7\", \"14541035.8\", \"1767426.…\n$ ...121 &lt;chr&gt; \"2015 Feb\", \"64476544.2\", \"11957716.2\", \"10296090\", \"1661626.2\"…\n$ ...122 &lt;chr&gt; \"2015 Jan\", \"77900845.3\", \"14641037.2\", \"12694098.8\", \"1946938.…\n$ ...123 &lt;chr&gt; \"2014 Dec\", \"80529402\", \"15906839.2\", \"13524983.7\", \"2381855.4\"…\n$ ...124 &lt;chr&gt; \"2014 Nov\", \"77414200.7\", \"17304670.7\", \"14781877.3\", \"2522793.…\n$ ...125 &lt;chr&gt; \"2014 Oct\", \"86236478.1\", \"21768797.4\", \"19019932.3\", \"2748865.…\n$ ...126 &lt;chr&gt; \"2014 Sep\", \"85831628.1\", \"22541451.4\", \"19578112\", \"2963339.4\"…\n$ ...127 &lt;chr&gt; \"2014 Aug\", \"80280884.5\", \"21015926.8\", \"18040907.8\", \"2975019\"…\n$ ...128 &lt;chr&gt; \"2014 Jul\", \"84410904.3\", \"23832107.8\", \"21031358.4\", \"2800749.…\n$ ...129 &lt;chr&gt; \"2014 Jun\", \"81821835.1\", \"22661219.4\", \"19592372.3\", \"3068847.…\n$ ...130 &lt;chr&gt; \"2014 May\", \"85571038.1\", \"25604036.7\", \"22365139.5\", \"3238897.…\n$ ...131 &lt;chr&gt; \"2014 Apr\", \"89000350.8\", \"24038107.9\", \"20575823.7\", \"3462284.…\n$ ...132 &lt;chr&gt; \"2014 Mar\", \"89094505.9\", \"23927801.7\", \"21129942.8\", \"2797858.…\n$ ...133 &lt;chr&gt; \"2014 Feb\", \"78349170.8\", \"24207741.3\", \"20563444.5\", \"3644296.…\n$ ...134 &lt;chr&gt; \"2014 Jan\", \"86109609.4\", \"23796568.2\", \"20515332\", \"3281236.2\"…\n$ ...135 &lt;chr&gt; \"2013 Dec\", \"81200008\", \"20354823.8\", \"17479059.8\", \"2875763.9\"…\n$ ...136 &lt;chr&gt; \"2013 Nov\", \"82011098.6\", \"22844752.3\", \"19597042.3\", \"3247710\"…\n$ ...137 &lt;chr&gt; \"2013 Oct\", \"92787692\", \"24582564.5\", \"21475845.6\", \"3106718.9\"…\n$ ...138 &lt;chr&gt; \"2013 Sep\", \"86777870.7\", \"24501228.3\", \"21427877\", \"3073351.3\"…\n$ ...139 &lt;chr&gt; \"2013 Aug\", \"84320793.5\", \"23184720.2\", \"19922875\", \"3261845.3\"…\n$ ...140 &lt;chr&gt; \"2013 Jul\", \"90009610.8\", \"23601117.1\", \"20665675.7\", \"2935441.…\n$ ...141 &lt;chr&gt; \"2013 Jun\", \"82677399.9\", \"21453469.2\", \"18580171.9\", \"2873297.…\n$ ...142 &lt;chr&gt; \"2013 May\", \"87712430.7\", \"22430760.7\", \"19488769.2\", \"2941991.…\n$ ...143 &lt;chr&gt; \"2013 Apr\", \"87749589.3\", \"22970657.8\", \"20085815.4\", \"2884842.…\n$ ...144 &lt;chr&gt; \"2013 Mar\", \"80374024.3\", \"19883302.8\", \"17028812.3\", \"2854490.…\n$ ...145 &lt;chr&gt; \"2013 Feb\", \"72915521\", \"22081388.2\", \"19157621.1\", \"2923767\", …\n$ ...146 &lt;chr&gt; \"2013 Jan\", \"82541864.9\", \"23353598.8\", \"20698102.1\", \"2655496.…\n$ ...147 &lt;chr&gt; \"2012 Dec\", \"77025317.8\", \"19830647.8\", \"17372601.3\", \"2458046.…\n$ ...148 &lt;chr&gt; \"2012 Nov\", \"82566343.6\", \"23971288.8\", \"21113361.8\", \"2857927\"…\n$ ...149 &lt;chr&gt; \"2012 Oct\", \"85517037.3\", \"24756207.7\", \"21936613.7\", \"2819594\"…\n$ ...150 &lt;chr&gt; \"2012 Sep\", \"79724773.8\", \"21639823.2\", \"18890709.3\", \"2749113.…\n$ ...151 &lt;chr&gt; \"2012 Aug\", \"80477594.7\", \"22032112.9\", \"19153209.3\", \"2878903.…\n$ ...152 &lt;chr&gt; \"2012 Jul\", \"81505716\", \"20597693.6\", \"17687875.8\", \"2909817.7\"…\n$ ...153 &lt;chr&gt; \"2012 Jun\", \"85050940.9\", \"23612673.2\", \"20283344.7\", \"3329328.…\n$ ...154 &lt;chr&gt; \"2012 May\", \"87356484.1\", \"26305273.7\", \"22752240.9\", \"3553032.…\n$ ...155 &lt;chr&gt; \"2012 Apr\", \"84516566.8\", \"25070981\", \"21714581.3\", \"3356399.7\"…\n$ ...156 &lt;chr&gt; \"2012 Mar\", \"89820321.3\", \"26112476.2\", \"23245416.2\", \"2867060\"…\n$ ...157 &lt;chr&gt; \"2012 Feb\", \"85882277.9\", \"26319147.4\", \"22942942.4\", \"3376205\"…\n$ ...158 &lt;chr&gt; \"2012 Jan\", \"82100595.1\", \"25456568.2\", \"22142302.6\", \"3314265.…\n$ ...159 &lt;chr&gt; \"2011 Dec\", \"83853527.9\", \"21599058.2\", \"18308854.2\", \"3290204\"…\n$ ...160 &lt;chr&gt; \"2011 Nov\", \"85068675.9\", \"24422953.6\", \"21402037.6\", \"3020916\"…\n$ ...161 &lt;chr&gt; \"2011 Oct\", \"84146679.4\", \"23981605.1\", \"21040471.6\", \"2941133.…\n$ ...162 &lt;chr&gt; \"2011 Sep\", \"84307189.4\", \"23516450.5\", \"20439076.2\", \"3077374.…\n$ ...163 &lt;chr&gt; \"2011 Aug\", \"87336076.5\", \"27585547.5\", \"24579637.9\", \"3005909.…\n$ ...164 &lt;chr&gt; \"2011 Jul\", \"79908645.1\", \"22405775.1\", \"19204362.1\", \"3201413\"…\n$ ...165 &lt;chr&gt; \"2011 Jun\", \"83057330.8\", \"24400223.9\", \"21450229.6\", \"2949994.…\n$ ...166 &lt;chr&gt; \"2011 May\", \"82396879.4\", \"24735503\", \"21685702.5\", \"3049800.4\"…\n$ ...167 &lt;chr&gt; \"2011 Apr\", \"81282034.2\", \"24750248.6\", \"21820510.3\", \"2929738.…\n$ ...168 &lt;chr&gt; \"2011 Mar\", \"89761340.1\", \"27272671.4\", \"24684350.5\", \"2588320.…\n$ ...169 &lt;chr&gt; \"2011 Feb\", \"69089869\", \"19270569.5\", \"16707007.9\", \"2563561.6\"…\n$ ...170 &lt;chr&gt; \"2011 Jan\", \"81350559.3\", \"22779346.8\", \"20413464.8\", \"2365882\"…\n$ ...171 &lt;chr&gt; \"2010 Dec\", \"77966152.5\", \"18125906.3\", \"15934940.2\", \"2190966.…\n$ ...172 &lt;chr&gt; \"2010 Nov\", \"75568476.6\", \"17982746\", \"15748741.1\", \"2234004.9\"…\n$ ...173 &lt;chr&gt; \"2010 Oct\", \"78325836\", \"17533324.9\", \"15411702.7\", \"2121622.3\"…\n$ ...174 &lt;chr&gt; \"2010 Sep\", \"77178033\", \"18331520.2\", \"16221580.4\", \"2109939.8\"…\n$ ...175 &lt;chr&gt; \"2010 Aug\", \"79150240.7\", \"17896785.2\", \"15668852.6\", \"2227932.…\n$ ...176 &lt;chr&gt; \"2010 Jul\", \"79676629.1\", \"18361889.8\", \"16131743.7\", \"2230146\"…\n$ ...177 &lt;chr&gt; \"2010 Jun\", \"78694903.3\", \"19990187.6\", \"17675947.6\", \"2314240\"…\n$ ...178 &lt;chr&gt; \"2010 May\", \"72205358.8\", \"17052300.5\", \"14568447.4\", \"2483853.…\n$ ...179 &lt;chr&gt; \"2010 Apr\", \"77364598.8\", \"20398367.2\", \"18313258.2\", \"2085109.…\n$ ...180 &lt;chr&gt; \"2010 Mar\", \"77368439.8\", \"18222472.9\", \"16201663.7\", \"2020809.…\n$ ...181 &lt;chr&gt; \"2010 Feb\", \"63856067.1\", \"16998218.4\", \"14801642.4\", \"2196576\"…\n$ ...182 &lt;chr&gt; \"2010 Jan\", \"69681291.3\", \"18209559.4\", \"16121110\", \"2088449.5\"…\n$ ...183 &lt;chr&gt; \"2009 Dec\", \"71029541.6\", \"16382511.4\", \"14484555.8\", \"1897955.…\n$ ...184 &lt;chr&gt; \"2009 Nov\", \"67108157.6\", \"15379432.8\", \"13428363.8\", \"1951069.…\n$ ...185 &lt;chr&gt; \"2009 Oct\", \"68414179.7\", \"15990400.1\", \"14039884.6\", \"1950515.…\n$ ...186 &lt;chr&gt; \"2009 Sep\", \"68456728.5\", \"16123628.9\", \"14173678.4\", \"1949950.…\n$ ...187 &lt;chr&gt; \"2009 Aug\", \"64307849.4\", \"15099034.2\", \"13251166.9\", \"1847867.…\n$ ...188 &lt;chr&gt; \"2009 Jul\", \"66963504.1\", \"15694221.9\", \"13914139.2\", \"1780082.…\n$ ...189 &lt;chr&gt; \"2009 Jun\", \"61952063.4\", \"13627041.7\", \"11966043.7\", \"1660998\"…\n$ ...190 &lt;chr&gt; \"2009 May\", \"57938152.1\", \"12611026.5\", \"11327914.6\", \"1283112\"…\n$ ...191 &lt;chr&gt; \"2009 Apr\", \"59246226.4\", \"12743043.1\", \"11531716.6\", \"1211326.…\n$ ...192 &lt;chr&gt; \"2009 Mar\", \"59528603.3\", \"11604858.6\", \"10532022.5\", \"1072836\"…\n$ ...193 &lt;chr&gt; \"2009 Feb\", \"54165921.4\", \"11515819.7\", \"10299285.4\", \"1216534.…\n$ ...194 &lt;chr&gt; \"2009 Jan\", \"52189843.3\", \"10628019.9\", \"9668224.2\", \"959795.6\"…\n$ ...195 &lt;chr&gt; \"2008 Dec\", \"59211487.9\", \"11313331.3\", \"10190058.5\", \"1123272.…\n$ ...196 &lt;chr&gt; \"2008 Nov\", \"67148353\", \"14776793.7\", \"12969128.3\", \"1807665.4\"…\n$ ...197 &lt;chr&gt; \"2008 Oct\", \"78459916.4\", \"19489503\", \"17002720\", \"2486783\", \"5…\n$ ...198 &lt;chr&gt; \"2008 Sep\", \"85240482.8\", \"22794675.5\", \"19745227.4\", \"3049448.…\n$ ...199 &lt;chr&gt; \"2008 Aug\", \"81399600.3\", \"22638765.2\", \"19479715.7\", \"3159049.…\n$ ...200 &lt;chr&gt; \"2008 Jul\", \"88744688.6\", \"28075083.7\", \"25376572.3\", \"2698511.…\n$ ...201 &lt;chr&gt; \"2008 Jun\", \"83194163.9\", \"24574301.5\", \"22007131.2\", \"2567170.…\n$ ...202 &lt;chr&gt; \"2008 May\", \"79559914.9\", \"23307631.6\", \"20977706.9\", \"2329924.…\n$ ...203 &lt;chr&gt; \"2008 Apr\", \"83071447.7\", \"22331630.2\", \"20013163.1\", \"2318467.…\n$ ...204 &lt;chr&gt; \"2008 Mar\", \"79079467\", \"18466201.8\", \"16633527.5\", \"1832674.2\"…\n$ ...205 &lt;chr&gt; \"2008 Feb\", \"69842221.4\", \"16961961.3\", \"14933445.7\", \"2028515.…\n$ ...206 &lt;chr&gt; \"2008 Jan\", \"81363940.9\", \"19541598.5\", \"17549715.3\", \"1991883.…\n$ ...207 &lt;chr&gt; \"2007 Dec\", \"72788487.2\", \"16262818.9\", \"14337223.7\", \"1925595.…\n$ ...208 &lt;chr&gt; \"2007 Nov\", \"75063525.9\", \"15281165.6\", \"13525323.8\", \"1755841.…\n$ ...209 &lt;chr&gt; \"2007 Oct\", \"78189401.5\", \"16139208.5\", \"14456956.2\", \"1682252.…\n$ ...210 &lt;chr&gt; \"2007 Sep\", \"71929205.2\", \"13633343.1\", \"11928209.1\", \"1705134\"…\n$ ...211 &lt;chr&gt; \"2007 Aug\", \"72833825.3\", \"12898284.1\", \"11451292.5\", \"1446991.…\n$ ...212 &lt;chr&gt; \"2007 Jul\", \"73669127.1\", \"14020060.4\", \"12501376.4\", \"1518684\"…\n$ ...213 &lt;chr&gt; \"2007 Jun\", \"72476997.6\", \"13821155\", \"12473840.9\", \"1347314.1\"…\n$ ...214 &lt;chr&gt; \"2007 May\", \"68746903.3\", \"13808854.8\", \"12405815.1\", \"1403039.…\n$ ...215 &lt;chr&gt; \"2007 Apr\", \"68387572.3\", \"14448539.2\", \"13182652\", \"1265887.2\"…\n$ ...216 &lt;chr&gt; \"2007 Mar\", \"71254516.6\", \"11594014.5\", \"10359103.3\", \"1234911.…\n$ ...217 &lt;chr&gt; \"2007 Feb\", \"58789691.4\", \"9565701.7\", \"8537245.1\", \"1028456.6\"…\n$ ...218 &lt;chr&gt; \"2007 Jan\", \"68361570.6\", \"11618856\", \"10495604.8\", \"1123251.2\"…\n$ ...219 &lt;chr&gt; \"2006 Dec\", \"68954969.8\", \"9701670.2\", \"8684881\", \"1016789.2\", …\n$ ...220 &lt;chr&gt; \"2006 Nov\", \"69294697.5\", \"10953823.7\", \"9828164.5\", \"1125659.1…\n$ ...221 &lt;chr&gt; \"2006 Oct\", \"68077663.5\", \"10485046.2\", \"9322896.1\", \"1162150.1…\n$ ...222 &lt;chr&gt; \"2006 Sep\", \"71451021.8\", \"13288760.2\", \"11989524.5\", \"1299235.…\n$ ...223 &lt;chr&gt; \"2006 Aug\", \"72219142.2\", \"15289194.8\", \"14064924.3\", \"1224270.…\n$ ...224 &lt;chr&gt; \"2006 Jul\", \"69368770.5\", \"13899748.4\", \"12750468.6\", \"1149279.…\n$ ...225 &lt;chr&gt; \"2006 Jun\", \"71752930\", \"14031087\", \"12704238\", \"1326849\", \"577…\n$ ...226 &lt;chr&gt; \"2006 May\", \"68624261.8\", \"14130212\", \"12940845.2\", \"1189366.8\"…\n$ ...227 &lt;chr&gt; \"2006 Apr\", \"62986337.8\", \"10163346.9\", \"8954455\", \"1208891.9\",…\n$ ...228 &lt;chr&gt; \"2006 Mar\", \"69234700.5\", \"11095211.2\", \"9965680\", \"1129531.2\",…\n$ ...229 &lt;chr&gt; \"2006 Feb\", \"62940701.9\", \"12225263.8\", \"11137039.8\", \"1088224\"…\n$ ...230 &lt;chr&gt; \"2006 Jan\", \"59993900.3\", \"9934204.6\", \"8917059.9\", \"1017144.7\"…\n$ ...231 &lt;chr&gt; \"2005 Dec\", \"67847663.9\", \"9992096.9\", \"8963324.3\", \"1028772.5\"…\n$ ...232 &lt;chr&gt; \"2005 Nov\", \"63761309.4\", \"10343283.3\", \"9178999\", \"1164284.3\",…\n$ ...233 &lt;chr&gt; \"2005 Oct\", \"67877583.9\", \"11489291.5\", \"10382282.7\", \"1107008.…\n$ ...234 &lt;chr&gt; \"2005 Sep\", \"63386556\", \"10798079.1\", \"9733053\", \"1065026.1\", \"…\n$ ...235 &lt;chr&gt; \"2005 Aug\", \"63943439.9\", \"10859668.3\", \"9861496.3\", \"998172\", …\n$ ...236 &lt;chr&gt; \"2005 Jul\", \"59649731\", \"9646590\", \"8733751.4\", \"912838.6\", \"50…\n$ ...237 &lt;chr&gt; \"2005 Jun\", \"59158726.2\", \"10210984.9\", \"9329210.7\", \"881774.1\"…\n$ ...238 &lt;chr&gt; \"2005 May\", \"56773896.3\", \"10203050.5\", \"9316419.9\", \"886630.6\"…\n$ ...239 &lt;chr&gt; \"2005 Apr\", \"56558394.8\", \"8316267.2\", \"7528409.5\", \"787857.6\",…\n$ ...240 &lt;chr&gt; \"2005 Mar\", \"59642108.4\", \"9524110.5\", \"8927231.5\", \"596879\", \"…\n$ ...241 &lt;chr&gt; \"2005 Feb\", \"46908115\", \"6538231\", \"5868670.3\", \"669560.7\", \"40…\n$ ...242 &lt;chr&gt; \"2005 Jan\", \"52489280.4\", \"8638507.8\", \"7986147.1\", \"652360.7\",…\n$ ...243 &lt;chr&gt; \"2004 Dec\", \"55568760.6\", \"7567216.5\", \"6882069.2\", \"685147.3\",…\n$ ...244 &lt;chr&gt; \"2004 Nov\", \"53278515.2\", \"8144407.1\", \"7412834\", \"731573.1\", \"…\n$ ...245 &lt;chr&gt; \"2004 Oct\", \"56763878.5\", \"8878313.5\", \"8181210.4\", \"697103\", \"…\n$ ...246 &lt;chr&gt; \"2004 Sep\", \"56673275.2\", \"7486267.5\", \"6792439\", \"693828.5\", \"…\n$ ...247 &lt;chr&gt; \"2004 Aug\", \"54551785\", \"7306962\", \"6612508.1\", \"694453.9\", \"47…\n$ ...248 &lt;chr&gt; \"2004 Jul\", \"55788184.1\", \"7372821.3\", \"6690195.3\", \"682626\", \"…\n$ ...249 &lt;chr&gt; \"2004 Jun\", \"53492814.7\", \"7104522.4\", \"6413559.7\", \"690962.7\",…\n$ ...250 &lt;chr&gt; \"2004 May\", \"51759425.7\", \"7034846.8\", \"6390799.2\", \"644047.6\",…\n$ ...251 &lt;chr&gt; \"2004 Apr\", \"50906345.4\", \"6467133.8\", \"5866811.8\", \"600322\", \"…\n$ ...252 &lt;chr&gt; \"2004 Mar\", \"53069273\", \"6789821.5\", \"6218370.3\", \"571451.3\", \"…\n$ ...253 &lt;chr&gt; \"2004 Feb\", \"44463508.5\", \"5466190.9\", \"4891109.2\", \"575081.7\",…\n$ ...254 &lt;chr&gt; \"2004 Jan\", \"44638368.7\", \"5436715.6\", \"4848614.7\", \"588100.9\",…\n$ ...255 &lt;chr&gt; \"2003 Dec\", \"48554997.7\", \"5855766.7\", \"5261722.3\", \"594044.4\",…\n$ ...256 &lt;chr&gt; \"2003 Nov\", \"43802442.5\", \"4764784\", \"4194532.4\", \"570251.6\", \"…\n$ ...257 &lt;chr&gt; \"2003 Oct\", \"48229423.3\", \"5212705\", \"4665676.4\", \"547028.6\", \"…\n$ ...258 &lt;chr&gt; \"2003 Sep\", \"45816601.9\", \"5068183.8\", \"4510263.5\", \"557920.3\",…\n$ ...259 &lt;chr&gt; \"2003 Aug\", \"42299447.4\", \"4504589.8\", \"3970214.4\", \"534375.4\",…\n$ ...260 &lt;chr&gt; \"2003 Jul\", \"43360466.4\", \"4602888.2\", \"4080105.9\", \"522782.3\",…\n$ ...261 &lt;chr&gt; \"2003 Jun\", \"42077944.4\", \"5841399.9\", \"5309935.6\", \"531464.3\",…\n$ ...262 &lt;chr&gt; \"2003 May\", \"40162535.8\", \"4566896.9\", \"4027203.7\", \"539693.2\",…\n$ ...263 &lt;chr&gt; \"2003 Apr\", \"42072883.2\", \"5074830.7\", \"4434745\", \"640085.8\", \"…\n$ ...264 &lt;chr&gt; \"2003 Mar\", \"43860167.9\", \"5769540.8\", \"5178858.6\", \"590682.2\",…\n$ ...265 &lt;chr&gt; \"2003 Feb\", \"36993870.9\", \"5163465\", \"4558407.7\", \"605057.3\", \"…\n$ ...266 &lt;chr&gt; \"2003 Jan\", \"41986698.9\", \"5873312\", \"5304700.7\", \"568611.3\", \"…\n$ ...267 &lt;chr&gt; \"2002 Dec\", \"35684824.8\", \"4433595.8\", \"3858804.3\", \"574791.5\",…\n$ ...268 &lt;chr&gt; \"2002 Nov\", \"38120539.9\", \"4606226\", \"4043353.8\", \"562872.2\", \"…\n$ ...269 &lt;chr&gt; \"2002 Oct\", \"39326285.3\", \"4727324.3\", \"4167110.6\", \"560213.7\",…\n$ ...270 &lt;chr&gt; \"2002 Sep\", \"35904949.8\", \"4288348.7\", \"3775717.9\", \"512630.8\",…\n$ ...271 &lt;chr&gt; \"2002 Aug\", \"37787583\", \"4313984\", \"3832056.1\", \"481927.9\", \"33…\n$ ...272 &lt;chr&gt; \"2002 Jul\", \"38629707.1\", \"4692393.7\", \"4198946\", \"493447.6\", \"…\n$ ...273 &lt;chr&gt; \"2002 Jun\", \"36890597.7\", \"4551838.6\", \"4040958.8\", \"510879.8\",…\n$ ...274 &lt;chr&gt; \"2002 May\", \"36244503\", \"3924054\", \"3431479.2\", \"492574.8\", \"32…\n$ ...275 &lt;chr&gt; \"2002 Apr\", \"37718249\", \"4459134.2\", \"3997207\", \"461927.2\", \"33…\n$ ...276 &lt;chr&gt; \"2002 Mar\", \"35995455.7\", \"3628005.8\", \"3250607.4\", \"377398.4\",…\n$ ...277 &lt;chr&gt; \"2002 Feb\", \"29527038.2\", \"3221493.2\", \"2842247.5\", \"379245.8\",…\n$ ...278 &lt;chr&gt; \"2002 Jan\", \"33818023.3\", \"3629231.8\", \"3216447.8\", \"412784\", \"…\n$ ...279 &lt;chr&gt; \"2001 Dec\", \"32253624.2\", \"2977608.2\", \"2549288.1\", \"428320.1\",…\n$ ...280 &lt;chr&gt; \"2001 Nov\", \"34625528.7\", \"3852382.1\", \"3296571.6\", \"555810.5\",…\n$ ...281 &lt;chr&gt; \"2001 Oct\", \"37008944.9\", \"4136820.5\", \"3654992.7\", \"481827.8\",…\n$ ...282 &lt;chr&gt; \"2001 Sep\", \"32827412.9\", \"3585683.9\", \"3088584.8\", \"497099.1\",…\n$ ...283 &lt;chr&gt; \"2001 Aug\", \"34943647.4\", \"4689498.1\", \"4157387.8\", \"532110.4\",…\n$ ...284 &lt;chr&gt; \"2001 Jul\", \"34880396.6\", \"4501539.1\", \"3989310.5\", \"512228.6\",…\n$ ...285 &lt;chr&gt; \"2001 Jun\", \"35971403.7\", \"4216013.3\", \"3709650.1\", \"506363.2\",…\n$ ...286 &lt;chr&gt; \"2001 May\", \"35826204.1\", \"4000942.9\", \"3499183.9\", \"501759\", \"…\n$ ...287 &lt;chr&gt; \"2001 Apr\", \"35548433.9\", \"4034831.8\", \"3572147.8\", \"462683.9\",…\n$ ...288 &lt;chr&gt; \"2001 Mar\", \"39548517.5\", \"3988442.2\", \"3562652.9\", \"425789.3\",…\n$ ...289 &lt;chr&gt; \"2001 Feb\", \"36045003.3\", \"4478825.3\", \"3986525.9\", \"492299.4\",…\n$ ...290 &lt;chr&gt; \"2001 Jan\", \"36239283.3\", \"4155262.5\", \"3593569.8\", \"561692.6\",…\n$ ...291 &lt;chr&gt; \"2000 Dec\", \"41782301.1\", \"5156029.8\", \"4622418.3\", \"533611.5\",…\n$ ...292 &lt;chr&gt; \"2000 Nov\", \"43003500.4\", \"4849158.8\", \"4285215\", \"563943.8\", \"…\n$ ...293 &lt;chr&gt; \"2000 Oct\", \"44263702.1\", \"5285172.4\", \"4750310.3\", \"534862.1\",…\n$ ...294 &lt;chr&gt; \"2000 Sep\", \"42916026.1\", \"4503101.1\", \"3949586.6\", \"553514.4\",…\n$ ...295 &lt;chr&gt; \"2000 Aug\", \"42880027.8\", \"4328228.6\", \"3792824.8\", \"535403.8\",…\n$ ...296 &lt;chr&gt; \"2000 Jul\", \"40186659.3\", \"3640664\", \"3146931.1\", \"493732.9\", \"…\n$ ...297 &lt;chr&gt; \"2000 Jun\", \"39739278.5\", \"4606471.7\", \"4238642.5\", \"367829.2\",…\n$ ...298 &lt;chr&gt; \"2000 May\", \"38407734.5\", \"4381770.1\", \"3970693.9\", \"411076.2\",…\n$ ...299 &lt;chr&gt; \"2000 Apr\", \"35025776.7\", \"3706572.5\", \"3231901.7\", \"474670.8\",…\n$ ...300 &lt;chr&gt; \"2000 Mar\", \"38546733.9\", \"3428235.7\", \"3072588.5\", \"355647.2\",…\n$ ...301 &lt;chr&gt; \"2000 Feb\", \"31757734.3\", \"3421626.1\", \"3075959.8\", \"345666.4\",…\n$ ...302 &lt;chr&gt; \"2000 Jan\", \"31491949\", \"3744773.7\", \"3356142\", \"388631.8\", \"27…\n$ ...303 &lt;chr&gt; \"1999 Dec\", \"36936214.6\", \"3331601.8\", \"3012155.4\", \"319446.5\",…\n$ ...304 &lt;chr&gt; \"1999 Nov\", \"35331910.5\", \"3628213.7\", \"3265500.5\", \"362713.2\",…\n$ ...305 &lt;chr&gt; \"1999 Oct\", \"34742341.1\", \"3160770\", \"2738413.9\", \"422356\", \"31…\n$ ...306 &lt;chr&gt; \"1999 Sep\", \"34069719.6\", \"3079151.9\", \"2739281.5\", \"339870.5\",…\n$ ...307 &lt;chr&gt; \"1999 Aug\", \"32465146.8\", \"2518699.2\", \"2242170.3\", \"276528.9\",…\n$ ...308 &lt;chr&gt; \"1999 Jul\", \"32852660.8\", \"2630461.4\", \"2354160.5\", \"276300.9\",…\n$ ...309 &lt;chr&gt; \"1999 Jun\", \"32105547.7\", \"2433302.7\", \"2070495\", \"362807.7\", \"…\n$ ...310 &lt;chr&gt; \"1999 May\", \"30475820.5\", \"2523756.1\", \"2285922.7\", \"237833.4\",…\n$ ...311 &lt;chr&gt; \"1999 Apr\", \"31163897\", \"2860155.8\", \"2655775.7\", \"204380.1\", \"…\n$ ...312 &lt;chr&gt; \"1999 Mar\", \"31485379.3\", \"2403621.3\", \"2196248\", \"207373.2\", \"…\n$ ...313 &lt;chr&gt; \"1999 Feb\", \"24494581.9\", \"1874059.1\", \"1673169.8\", \"200889.3\",…\n$ ...314 &lt;chr&gt; \"1999 Jan\", \"26307956.1\", \"1968457.7\", \"1790563\", \"177894.7\", \"…\n$ ...315 &lt;chr&gt; \"1998 Dec\", \"29379108\", \"2149029\", \"1909307\", \"239722\", \"272300…\n$ ...316 &lt;chr&gt; \"1998 Nov\", \"27602867\", \"2359311\", \"2105763\", \"253548\", \"252435…\n$ ...317 &lt;chr&gt; \"1998 Oct\", \"28935515\", \"2065683\", \"1810147\", \"255536\", \"268698…\n$ ...318 &lt;chr&gt; \"1998 Sep\", \"30403223\", \"2125191\", \"1902599\", \"222592\", \"282780…\n$ ...319 &lt;chr&gt; \"1998 Aug\", \"29295320\", \"2128730\", \"1876621\", \"252109\", \"271665…\n$ ...320 &lt;chr&gt; \"1998 Jul\", \"30368195\", \"2410891\", \"2169682\", \"241209\", \"279573…\n$ ...321 &lt;chr&gt; \"1998 Jun\", \"30387660\", \"2314718\", \"2070536\", \"244182\", \"280729…\n$ ...322 &lt;chr&gt; \"1998 May\", \"27269816\", \"2183849\", \"1986200\", \"197649\", \"250859…\n$ ...323 &lt;chr&gt; \"1998 Apr\", \"29115338\", \"2413105\", \"2158845\", \"254260\", \"267022…\n$ ...324 &lt;chr&gt; \"1998 Mar\", \"33013823\", \"2256747\", \"2037044\", \"219703\", \"307570…\n$ ...325 &lt;chr&gt; \"1998 Feb\", \"29530419\", \"2411138\", \"2138316\", \"272822\", \"271192…\n$ ...326 &lt;chr&gt; \"1998 Jan\", \"28325521\", \"2467473\", \"2209023\", \"258450\", \"258580…\n$ ...327 &lt;chr&gt; \"1997 Dec\", \"34284272\", \"2976628\", \"2720225\", \"256403\", \"313076…\n$ ...328 &lt;chr&gt; \"1997 Nov\", \"32817829\", \"2705572\", \"2408184\", \"297388\", \"301122…\n$ ...329 &lt;chr&gt; \"1997 Oct\", \"34523630\", \"2908922\", \"2638685\", \"270237\", \"316147…\n$ ...330 &lt;chr&gt; \"1997 Sep\", \"34349004\", \"2780488\", \"2539938\", \"240550\", \"315685…\n$ ...331 &lt;chr&gt; \"1997 Aug\", \"31479244\", \"2559771\", \"2293606\", \"266165\", \"289194…\n$ ...332 &lt;chr&gt; \"1997 Jul\", \"33460102\", \"2790589\", \"2545695\", \"244894\", \"306695…\n$ ...333 &lt;chr&gt; \"1997 Jun\", \"30998743\", \"3132740\", \"2897050\", \"235690\", \"278660…\n$ ...334 &lt;chr&gt; \"1997 May\", \"31678874\", \"3426257\", \"3149575\", \"276682\", \"282526…\n$ ...335 &lt;chr&gt; \"1997 Apr\", \"31353836\", \"2757793\", \"2483174\", \"274619\", \"285960…\n$ ...336 &lt;chr&gt; \"1997 Mar\", \"32204410\", \"2899046\", \"2631520\", \"267526\", \"293053…\n$ ...337 &lt;chr&gt; \"1997 Feb\", \"24217362\", \"2506692\", \"2260527\", \"246165\", \"217106…\n$ ...338 &lt;chr&gt; \"1997 Jan\", \"30850383\", \"3409541\", \"3107865\", \"301676\", \"274408…\n$ ...339 &lt;chr&gt; \"1996 Dec\", \"31043702\", \"3004967\", \"2795595\", \"209372\", \"280387…\n$ ...340 &lt;chr&gt; \"1996 Nov\", \"30692970\", \"2901305\", \"2650028\", \"251277\", \"277916…\n$ ...341 &lt;chr&gt; \"1996 Oct\", \"32025621\", \"2946231\", \"2741856\", \"204375\", \"290793…\n$ ...342 &lt;chr&gt; \"1996 Sep\", \"29425608\", \"2894523\", \"2598257\", \"296266\", \"265310…\n$ ...343 &lt;chr&gt; \"1996 Aug\", \"28635705\", \"2292157\", \"2091526\", \"200631\", \"263435…\n$ ...344 &lt;chr&gt; \"1996 Jul\", \"30826321\", \"2857771\", \"2618979\", \"238792\", \"279685…\n$ ...345 &lt;chr&gt; \"1996 Jun\", \"29152742\", \"2701982\", \"2442621\", \"259361\", \"264507…\n$ ...346 &lt;chr&gt; \"1996 May\", \"30061642\", \"3005159\", \"2754954\", \"250205\", \"270564…\n$ ...347 &lt;chr&gt; \"1996 Apr\", \"30108289\", \"2891047\", \"2634972\", \"256075\", \"272172…\n$ ...348 &lt;chr&gt; \"1996 Mar\", \"32076758\", \"3070287\", \"2822433\", \"247854\", \"290064…\n$ ...349 &lt;chr&gt; \"1996 Feb\", \"26562292\", \"2586145\", \"2337101\", \"249044\", \"239761…\n$ ...350 &lt;chr&gt; \"1996 Jan\", \"30843672\", \"2889836\", \"2675105\", \"214731\", \"279538…\n$ ...351 &lt;chr&gt; \"1995 Dec\", \"30189911\", \"2447560\", \"2277446\", \"170114\", \"277423…\n$ ...352 &lt;chr&gt; \"1995 Nov\", \"31194891\", \"2213093\", \"2027364\", \"185729\", \"289817…\n$ ...353 &lt;chr&gt; \"1995 Oct\", \"31039678\", \"2300170\", \"2087062\", \"213108\", \"287395…\n$ ...354 &lt;chr&gt; \"1995 Sep\", \"29665051\", \"2103282\", \"1931282\", \"172000\", \"275617…\n$ ...355 &lt;chr&gt; \"1995 Aug\", \"30652877\", \"2443105\", \"2250598\", \"192507\", \"282097…\n$ ...356 &lt;chr&gt; \"1995 Jul\", \"29625194\", \"2447418\", \"2223478\", \"223940\", \"271777…\n$ ...357 &lt;chr&gt; \"1995 Jun\", \"29092975\", \"2408224\", \"2180520\", \"227704\", \"266847…\n$ ...358 &lt;chr&gt; \"1995 May\", \"28700250\", \"2576487\", \"2373415\", \"203072\", \"261237…\n$ ...359 &lt;chr&gt; \"1995 Apr\", \"26384942\", \"2155526\", \"1951124\", \"204402\", \"242294…\n$ ...360 &lt;chr&gt; \"1995 Mar\", \"28768453\", \"2419191\", \"2238607\", \"180584\", \"263492…\n$ ...361 &lt;chr&gt; \"1995 Feb\", \"23957862\", \"2293217\", \"2073876\", \"219341\", \"216646…\n$ ...362 &lt;chr&gt; \"1995 Jan\", \"24556086\", \"2254538\", \"2054562\", \"199976\", \"223015…\n$ ...363 &lt;chr&gt; \"1994 Dec\", \"27307893\", \"2262936\", \"2069827\", \"193109\", \"250449…\n$ ...364 &lt;chr&gt; \"1994 Nov\", \"26727765\", \"2268352\", \"2052925\", \"215427\", \"244594…\n$ ...365 &lt;chr&gt; \"1994 Oct\", \"26893921\", \"2206670\", \"1945012\", \"261658\", \"246872…\n$ ...366 &lt;chr&gt; \"1994 Sep\", \"27321176\", \"2230225\", \"2011739\", \"218486\", \"250909…\n$ ...367 &lt;chr&gt; \"1994 Aug\", \"27022867\", \"3015996\", \"2777701\", \"238295\", \"240068…\n$ ...368 &lt;chr&gt; \"1994 Jul\", \"26053223\", \"2433751\", \"2232598\", \"201153\", \"236194…\n$ ...369 &lt;chr&gt; \"1994 Jun\", \"26321588\", \"2309236\", \"2106601\", \"202635\", \"240123…\n$ ...370 &lt;chr&gt; \"1994 May\", \"25342975\", \"2631909\", \"2403705\", \"228204\", \"227110…\n$ ...371 &lt;chr&gt; \"1994 Apr\", \"25820372\", \"2355154\", \"2185562\", \"169592\", \"234652…\n$ ...372 &lt;chr&gt; \"1994 Mar\", \"23984139\", \"2156922\", \"1981789\", \"175133\", \"218272…\n$ ...373 &lt;chr&gt; \"1994 Feb\", \"18827899\", \"1877207\", \"1724563\", \"152644\", \"169506…\n$ ...374 &lt;chr&gt; \"1994 Jan\", \"22099165\", \"2114214\", \"1923898\", \"190316\", \"199849…\n$ ...375 &lt;chr&gt; \"1993 Dec\", \"23293955\", \"2306275\", \"2116667\", \"189608\", \"209876…\n$ ...376 &lt;chr&gt; \"1993 Nov\", \"21972021\", \"2392762\", \"2188310\", \"204452\", \"195792…\n$ ...377 &lt;chr&gt; \"1993 Oct\", \"21878085\", \"2357839\", \"2111175\", \"246664\", \"195202…\n$ ...378 &lt;chr&gt; \"1993 Sep\", \"23359027\", \"2509174\", \"2288378\", \"220796\", \"208498…\n$ ...379 &lt;chr&gt; \"1993 Aug\", \"21050175\", \"2420966\", \"2168721\", \"252245\", \"186292…\n$ ...380 &lt;chr&gt; \"1993 Jul\", \"22276134\", \"2453283\", \"2243455\", \"209828\", \"198228…\n$ ...381 &lt;chr&gt; \"1993 Jun\", \"21695902\", \"2525391\", \"2310092\", \"215299\", \"191705…\n$ ...382 &lt;chr&gt; \"1993 May\", \"21076420\", \"2407819\", \"2208722\", \"199097\", \"186686…\n$ ...383 &lt;chr&gt; \"1993 Apr\", \"21870039\", \"2870577\", \"2675927\", \"194650\", \"189994…\n$ ...384 &lt;chr&gt; \"1993 Mar\", \"22019533\", \"2685142\", \"2506330\", \"178812\", \"193343…\n$ ...385 &lt;chr&gt; \"1993 Feb\", \"18987631\", \"2361660\", \"2154261\", \"207399\", \"166259…\n$ ...386 &lt;chr&gt; \"1993 Jan\", \"17597466\", \"2232599\", \"2007712\", \"224887\", \"153648…\n$ ...387 &lt;chr&gt; \"1992 Dec\", \"21928057\", \"2494329\", \"2237686\", \"256643\", \"194337…\n$ ...388 &lt;chr&gt; \"1992 Nov\", \"19764917\", \"2797892\", \"2599615\", \"198277\", \"169670…\n$ ...389 &lt;chr&gt; \"1992 Oct\", \"19530943\", \"2378750\", \"2198916\", \"179834\", \"171521…\n$ ...390 &lt;chr&gt; \"1992 Sep\", \"18832282\", \"2357900\", \"2162301\", \"195599\", \"164743…\n$ ...391 &lt;chr&gt; \"1992 Aug\", \"17682603\", \"2182337\", \"1977921\", \"204416\", \"155002…\n$ ...392 &lt;chr&gt; \"1992 Jul\", \"19303469\", \"2480309\", \"2296856\", \"183453\", \"168231…\n$ ...393 &lt;chr&gt; \"1992 Jun\", \"19061391\", \"2427894\", \"2266091\", \"161803\", \"166334…\n$ ...394 &lt;chr&gt; \"1992 May\", \"16834013\", \"2187422\", \"2019863\", \"167559\", \"146465…\n$ ...395 &lt;chr&gt; \"1992 Apr\", \"17190434\", \"2245232\", \"2091365\", \"153867\", \"149452…\n$ ...396 &lt;chr&gt; \"1992 Mar\", \"18472025\", \"2293934\", \"2107870\", \"186064\", \"161780…\n$ ...397 &lt;chr&gt; \"1992 Feb\", \"15087414\", \"2181543\", \"1995834\", \"185709\", \"129058…\n$ ...398 &lt;chr&gt; \"1992 Jan\", \"17193165\", \"2469553\", \"2279368\", \"190185\", \"147236…\n$ ...399 &lt;chr&gt; \"1991 Dec\", \"16971151\", \"2244063\", \"2049709\", \"194354\", \"147270…\n$ ...400 &lt;chr&gt; \"1991 Nov\", \"17569101\", \"2747377\", \"2566463\", \"180914\", \"148217…\n$ ...401 &lt;chr&gt; \"1991 Oct\", \"17874179\", \"2383734\", \"2199585\", \"184149\", \"154904…\n$ ...402 &lt;chr&gt; \"1991 Sep\", \"17375152\", \"2436008\", \"2259605\", \"176403\", \"149391…\n$ ...403 &lt;chr&gt; \"1991 Aug\", \"17997204\", \"2821506\", \"2613479\", \"208027\", \"151756…\n$ ...404 &lt;chr&gt; \"1991 Jul\", \"19520375\", \"2828159\", \"2617016\", \"211143\", \"166922…\n$ ...405 &lt;chr&gt; \"1991 Jun\", \"18670555\", \"2632891\", \"2385225\", \"247666\", \"160376…\n$ ...406 &lt;chr&gt; \"1991 May\", \"18095221\", \"2523157\", \"2291276\", \"231881\", \"155720…\n$ ...407 &lt;chr&gt; \"1991 Apr\", \"17513364\", \"2702398\", \"2339255\", \"363143\", \"148109…\n$ ...408 &lt;chr&gt; \"1991 Mar\", \"18523113\", \"2800915\", \"2455955\", \"344960\", \"157221…\n$ ...409 &lt;chr&gt; \"1991 Feb\", \"16552644\", \"3263296\", \"2972105\", \"291191\", \"132893…\n$ ...410 &lt;chr&gt; \"1991 Jan\", \"19412377\", \"4037646\", \"3659581\", \"378065\", \"153747…\n$ ...411 &lt;chr&gt; \"1990 Dec\", \"18804435\", \"3507128\", \"3186483\", \"320645\", \"152973…\n$ ...412 &lt;chr&gt; \"1990 Nov\", \"18976108\", \"3675845\", \"3369057\", \"306788\", \"153002…\n$ ...413 &lt;chr&gt; \"1990 Oct\", \"19484208\", \"4224732\", \"3927130\", \"297602\", \"152594…\n$ ...414 &lt;chr&gt; \"1990 Sep\", \"16682825\", \"2996701\", \"2731819\", \"264882\", \"136861…\n$ ...415 &lt;chr&gt; \"1990 Aug\", \"17113546\", \"2782633\", \"2578638\", \"203995\", \"143309…\n$ ...416 &lt;chr&gt; \"1990 Jul\", \"16464565\", \"2434671\", \"2209797\", \"224874\", \"140298…\n$ ...417 &lt;chr&gt; \"1990 Jun\", \"16573325\", \"2244736\", \"2101849\", \"142887\", \"143285…\n$ ...418 &lt;chr&gt; \"1990 May\", \"16569564\", \"2456177\", \"2277064\", \"179113\", \"141133…\n$ ...419 &lt;chr&gt; \"1990 Apr\", \"15579206\", \"2679965\", \"2464485\", \"215480\", \"128992…\n$ ...420 &lt;chr&gt; \"1990 Mar\", \"17835810\", \"2707716\", \"2538831\", \"168885\", \"151280…\n$ ...421 &lt;chr&gt; \"1990 Feb\", \"14979340\", \"2352931\", \"2131447\", \"221484\", \"126264…\n$ ...422 &lt;chr&gt; \"1990 Jan\", \"15948701\", \"2630986\", \"2392386\", \"238600\", \"133177…\n$ ...423 &lt;chr&gt; \"1989 Dec\", \"16406934\", \"2379741\", \"2145152\", \"234589\", \"140271…\n$ ...424 &lt;chr&gt; \"1989 Nov\", \"16670958\", \"2658194\", \"2456453\", \"201741\", \"140127…\n$ ...425 &lt;chr&gt; \"1989 Oct\", \"16409717\", \"2300415\", \"2111498\", \"188917\", \"141093…\n$ ...426 &lt;chr&gt; \"1989 Sep\", \"16222652\", \"2186659\", \"1950925\", \"235734\", \"140359…\n$ ...427 &lt;chr&gt; \"1989 Aug\", \"16466064\", \"2433929\", \"2225621\", \"208308\", \"140321…\n$ ...428 &lt;chr&gt; \"1989 Jul\", \"14632640\", \"2004816\", \"1804067\", \"200749\", \"126278…\n$ ...429 &lt;chr&gt; \"1989 Jun\", \"15432765\", \"2209890\", \"2025197\", \"184693\", \"132228…\n$ ...430 &lt;chr&gt; \"1989 May\", \"15031724\", \"2393743\", \"2182701\", \"211042\", \"126379…\n$ ...431 &lt;chr&gt; \"1989 Apr\", \"15562849\", \"2293753\", \"2118776\", \"174977\", \"132690…\n$ ...432 &lt;chr&gt; \"1989 Mar\", \"15913503\", \"2253861\", \"2109135\", \"144726\", \"136596…\n$ ...433 &lt;chr&gt; \"1989 Feb\", \"12584527\", \"1778484\", \"1626937\", \"151547\", \"108060…\n$ ...434 &lt;chr&gt; \"1989 Jan\", \"12645836\", \"1957007\", \"1787684\", \"169323\", \"106888…\n$ ...435 &lt;chr&gt; \"1988 Dec\", \"15866441\", \"1776818\", \"1619613\", \"157205\", \"140896…\n$ ...436 &lt;chr&gt; \"1988 Nov\", \"14613743\", \"1767082\", \"1583020\", \"184062\", \"128466…\n$ ...437 &lt;chr&gt; \"1988 Oct\", \"15726208\", \"1866958\", \"1683397\", \"183561\", \"138592…\n$ ...438 &lt;chr&gt; \"1988 Sep\", \"14249424\", \"2085933\", \"1909050\", \"176883\", \"121634…\n$ ...439 &lt;chr&gt; \"1988 Aug\", \"14995639\", \"2297673\", \"2088408\", \"209265\", \"126979…\n$ ...440 &lt;chr&gt; \"1988 Jul\", \"14385386\", \"2148568\", \"1973937\", \"174631\", \"122368…\n$ ...441 &lt;chr&gt; \"1988 Jun\", \"14976565\", \"2623873\", \"2447889\", \"175984\", \"123526…\n$ ...442 &lt;chr&gt; \"1988 May\", \"13173838\", \"2000338\", \"1816853\", \"183485\", \"111735…\n$ ...443 &lt;chr&gt; \"1988 Apr\", \"13036559\", \"1983283\", \"1806735\", \"176548\", \"110532…\n$ ...444 &lt;chr&gt; \"1988 Mar\", \"11763728\", \"1959178\", \"1782732\", \"176446\", \"980455…\n$ ...445 &lt;chr&gt; \"1988 Feb\", \"12253885\", \"2062872\", \"1860942\", \"201930\", \"101910…\n$ ...446 &lt;chr&gt; \"1988 Jan\", \"12236559\", \"2202405\", \"1996523\", \"205882\", \"100341…\n$ ...447 &lt;chr&gt; \"1987 Dec\", \"12552949\", \"2229377\", \"2012799\", \"216578\", \"103235…\n$ ...448 &lt;chr&gt; \"1987 Nov\", \"12440399\", \"2476120\", \"2249041\", \"227079\", \"996427…\n$ ...449 &lt;chr&gt; \"1987 Oct\", \"11663744\", \"2258067\", \"2040855\", \"217212\", \"940567…\n$ ...450 &lt;chr&gt; \"1987 Sep\", \"12097303\", \"2613765\", \"2399943\", \"213822\", \"948353…\n$ ...451 &lt;chr&gt; \"1987 Aug\", \"10591657\", \"2081498\", \"1879548\", \"201950\", \"851015…\n$ ...452 &lt;chr&gt; \"1987 Jul\", \"11378341\", \"2161700\", \"1951127\", \"210573\", \"921664…\n$ ...453 &lt;chr&gt; \"1987 Jun\", \"10448346\", \"1956207\", \"1740394\", \"215813\", \"849213…\n$ ...454 &lt;chr&gt; \"1987 May\", \"9875454\", \"1779549\", \"1581271\", \"198278\", \"8095905…\n$ ...455 &lt;chr&gt; \"1987 Apr\", \"10616755\", \"1904186\", \"1689791\", \"214395\", \"871256…\n$ ...456 &lt;chr&gt; \"1987 Mar\", \"9012296\", \"1674461\", \"1510807\", \"163654\", \"7337835…\n$ ...457 &lt;chr&gt; \"1987 Feb\", \"8969979\", \"1941591\", \"1758593\", \"182998\", \"7028388…\n$ ...458 &lt;chr&gt; \"1987 Jan\", \"9033736\", \"1647127\", \"1458182\", \"188945\", \"7386609…\n$ ...459 &lt;chr&gt; \"1986 Dec\", \"9542443\", \"1709037\", \"1538855\", \"170182\", \"7833406…\n$ ...460 &lt;chr&gt; \"1986 Nov\", \"9118847\", \"1753989\", \"1591257\", \"162732\", \"7364858…\n$ ...461 &lt;chr&gt; \"1986 Oct\", \"9113454\", \"1758148\", \"1613529\", \"144619\", \"7355306…\n$ ...462 &lt;chr&gt; \"1986 Sep\", \"8701368\", \"1790555\", \"1633450\", \"157105\", \"6910813…\n$ ...463 &lt;chr&gt; \"1986 Aug\", \"9032949\", \"1692606\", \"1536354\", \"156252\", \"7340343…\n$ ...464 &lt;chr&gt; \"1986 Jul\", \"8481929\", \"1816097\", \"1663620\", \"152477\", \"6665832…\n$ ...465 &lt;chr&gt; \"1986 Jun\", \"8617548\", \"1972854\", \"1783392\", \"189462\", \"6644694…\n$ ...466 &lt;chr&gt; \"1986 May\", \"8107353\", \"1712468\", \"1549253\", \"163215\", \"6394885…\n$ ...467 &lt;chr&gt; \"1986 Apr\", \"8988669\", \"2170719\", \"1934719\", \"236000\", \"6817950…\n$ ...468 &lt;chr&gt; \"1986 Mar\", \"8428895\", \"2375325\", \"2143087\", \"232238\", \"6053570…\n$ ...469 &lt;chr&gt; \"1986 Feb\", \"8204219\", \"2288051\", \"2068090\", \"219961\", \"5916168…\n$ ...470 &lt;chr&gt; \"1986 Jan\", \"8193201\", \"2315909\", \"2086006\", \"229903\", \"5877292…\n$ ...471 &lt;chr&gt; \"1985 Dec\", \"8360460\", \"2341394\", \"2102952\", \"238442\", \"6019066…\n$ ...472 &lt;chr&gt; \"1985 Nov\", \"8757073\", \"2768471\", \"2526911\", \"241560\", \"5988602…\n$ ...473 &lt;chr&gt; \"1985 Oct\", \"9071069\", \"3118033\", \"2909544\", \"208489\", \"5953036…\n$ ...474 &lt;chr&gt; \"1985 Sep\", \"8581385\", \"2587889\", \"2408926\", \"178963\", \"5993496…\n$ ...475 &lt;chr&gt; \"1985 Aug\", \"8941592\", \"2589638\", \"2331141\", \"258497\", \"6351954…\n$ ...476 &lt;chr&gt; \"1985 Jul\", \"8349893\", \"2559628\", \"2358270\", \"201358\", \"5790265…\n$ ...477 &lt;chr&gt; \"1985 Jun\", \"8865169\", \"2881059\", \"2646899\", \"234160\", \"5984110…\n$ ...478 &lt;chr&gt; \"1985 May\", \"8902682\", \"2944188\", \"2679656\", \"264532\", \"5958494…\n$ ...479 &lt;chr&gt; \"1985 Apr\", \"9812541\", \"2632759\", \"2370165\", \"262594\", \"7179782…\n$ ...480 &lt;chr&gt; \"1985 Mar\", \"9097469\", \"3155808\", \"2917331\", \"238477\", \"5941661…\n$ ...481 &lt;chr&gt; \"1985 Feb\", \"8981734\", \"2567039\", \"2322281\", \"244758\", \"6414695…\n$ ...482 &lt;chr&gt; \"1985 Jan\", \"10275331\", \"3337340\", \"3051192\", \"286148\", \"693799…\n$ ...483 &lt;chr&gt; \"1984 Dec\", \"8479924\", \"1970328\", \"1715336\", \"254992\", \"6509596…\n$ ...484 &lt;chr&gt; \"1984 Nov\", \"10305601\", \"2757711\", \"2516921\", \"240790\", \"754789…\n$ ...485 &lt;chr&gt; \"1984 Oct\", \"9709161\", \"2661354\", \"2447981\", \"213373\", \"7047807…\n$ ...486 &lt;chr&gt; \"1984 Sep\", \"8740987\", \"2495455\", \"2226794\", \"268661\", \"6245532…\n$ ...487 &lt;chr&gt; \"1984 Aug\", \"9277161\", \"2583478\", \"2358996\", \"224482\", \"6693683…\n$ ...488 &lt;chr&gt; \"1984 Jul\", \"10279572\", \"3387849\", \"3089627\", \"298222\", \"689172…\n$ ...489 &lt;chr&gt; \"1984 Jun\", \"9288434\", \"2816091\", \"2601431\", \"214660\", \"6472343…\n$ ...490 &lt;chr&gt; \"1984 May\", \"10136467\", \"3016712\", \"2786659\", \"230053\", \"711975…\n$ ...491 &lt;chr&gt; \"1984 Apr\", \"8568871\", \"2300824\", \"2088395\", \"212429\", \"6268047…\n$ ...492 &lt;chr&gt; \"1984 Mar\", \"9454289\", \"2937114\", \"2627134\", \"309980\", \"6517175…\n$ ...493 &lt;chr&gt; \"1984 Feb\", \"8075635\", \"2737946\", \"2442740\", \"295206\", \"5337689…\n$ ...494 &lt;chr&gt; \"1984 Jan\", \"10157540\", \"3475771\", \"3244354\", \"231417\", \"668176…\n$ ...495 &lt;chr&gt; \"1983 Dec\", \"9029214\", \"2604228\", \"2380018\", \"224210\", \"6424986…\n$ ...496 &lt;chr&gt; \"1983 Nov\", \"8992828\", \"2971986\", \"2760747\", \"211239\", \"6020842…\n$ ...497 &lt;chr&gt; \"1983 Oct\", \"8833662\", \"2911291\", \"2662725\", \"248566\", \"5922371…\n$ ...498 &lt;chr&gt; \"1983 Sep\", \"8842977\", \"2681687\", \"2440120\", \"241567\", \"6161290…\n$ ...499 &lt;chr&gt; \"1983 Aug\", \"9255958\", \"2919116\", \"2692420\", \"226696\", \"6336842…\n$ ...500 &lt;chr&gt; \"1983 Jul\", \"8667411\", \"2817161\", \"2583911\", \"233250\", \"5850250…\n$ ...501 &lt;chr&gt; \"1983 Jun\", \"9331520\", \"3024680\", \"2780784\", \"243896\", \"6306840…\n$ ...502 &lt;chr&gt; \"1983 May\", \"8489857\", \"2623799\", \"2344975\", \"278824\", \"5866058…\n$ ...503 &lt;chr&gt; \"1983 Apr\", \"9339807\", \"3018745\", \"2744968\", \"273777\", \"6321062…\n$ ...504 &lt;chr&gt; \"1983 Mar\", \"8775155\", \"3058378\", \"2753642\", \"304736\", \"5716777…\n$ ...505 &lt;chr&gt; \"1983 Feb\", \"7533919\", \"2833713\", \"2565985\", \"267728\", \"4700206…\n$ ...506 &lt;chr&gt; \"1983 Jan\", \"8566793\", \"3157297\", \"2870884\", \"286413\", \"5409496…\n$ ...507 &lt;chr&gt; \"1982 Dec\", \"8622975\", \"3025512\", \"2765983\", \"259529\", \"5597463…\n$ ...508 &lt;chr&gt; \"1982 Nov\", \"8256747\", \"2819243\", \"2572521\", \"246722\", \"5437504…\n$ ...509 &lt;chr&gt; \"1982 Oct\", \"9175781\", \"3847198\", \"3565698\", \"281500\", \"5328583…\n$ ...510 &lt;chr&gt; \"1982 Sep\", \"8430238\", \"2863001\", \"2539011\", \"323990\", \"5567237…\n$ ...511 &lt;chr&gt; \"1982 Aug\", \"8342091\", \"3022446\", \"2717975\", \"304471\", \"5319645…\n$ ...512 &lt;chr&gt; \"1982 Jul\", \"9077975\", \"3232951\", \"2942401\", \"290550\", \"5845024…\n$ ...513 &lt;chr&gt; \"1982 Jun\", \"8418490\", \"2850034\", \"2578161\", \"271873\", \"5568456…\n$ ...514 &lt;chr&gt; \"1982 May\", \"9174856\", \"3544847\", \"3238335\", \"306512\", \"5630009…\n$ ...515 &lt;chr&gt; \"1982 Apr\", \"9123512\", \"3537137\", \"3281399\", \"255738\", \"5586375…\n$ ...516 &lt;chr&gt; \"1982 Mar\", \"9377611\", \"3400373\", \"3157077\", \"243296\", \"5977238…\n$ ...517 &lt;chr&gt; \"1982 Feb\", \"8294753\", \"3195943\", \"2934607\", \"261336\", \"5098810…\n$ ...518 &lt;chr&gt; \"1982 Jan\", \"8422338\", \"3072208\", \"2802991\", \"269217\", \"5350130…\n$ ...519 &lt;chr&gt; \"1981 Dec\", \"8742796\", \"3116992\", \"2801571\", \"315421\", \"5625804…\n$ ...520 &lt;chr&gt; \"1981 Nov\", \"7954451\", \"2659934\", \"2387175\", \"272759\", \"5294517…\n$ ...521 &lt;chr&gt; \"1981 Oct\", \"8895568\", \"3243918\", \"2951760\", \"292158\", \"5651650…\n$ ...522 &lt;chr&gt; \"1981 Sep\", \"8535093\", \"2917895\", \"2679462\", \"238433\", \"5617198…\n$ ...523 &lt;chr&gt; \"1981 Aug\", \"8587580\", \"3344342\", \"3071479\", \"272863\", \"5243238…\n$ ...524 &lt;chr&gt; \"1981 Jul\", \"9318592\", \"3605769\", \"3371656\", \"234113\", \"5712823…\n$ ...525 &lt;chr&gt; \"1981 Jun\", \"8210811\", \"2613763\", \"2395582\", \"218181\", \"5597048…\n$ ...526 &lt;chr&gt; \"1981 May\", \"8560171\", \"3036117\", \"2765457\", \"270660\", \"5524054…\n$ ...527 &lt;chr&gt; \"1981 Apr\", \"8944270\", \"3199662\", \"2984201\", \"215461\", \"5744608…\n$ ...528 &lt;chr&gt; \"1981 Mar\", \"8643079\", \"3217335\", \"2987712\", \"229623\", \"5425744…\n$ ...529 &lt;chr&gt; \"1981 Feb\", \"6825379\", \"2479590\", \"2285172\", \"194418\", \"4345789…\n$ ...530 &lt;chr&gt; \"1981 Jan\", \"9320982\", \"3519741\", \"3325467\", \"194274\", \"5801241…\n$ ...531 &lt;chr&gt; \"1980 Dec\", \"7694598\", \"2224418\", \"1981176\", \"243242\", \"5470180…\n$ ...532 &lt;chr&gt; \"1980 Nov\", \"8018408\", \"2633317\", \"2426605\", \"206712\", \"5385091…\n$ ...533 &lt;chr&gt; \"1980 Oct\", \"8360759\", \"2513933\", \"2304250\", \"209683\", \"5846826…\n$ ...534 &lt;chr&gt; \"1980 Sep\", \"7999543\", \"2390773\", \"2180867\", \"209906\", \"5608770…\n$ ...535 &lt;chr&gt; \"1980 Aug\", \"7691056\", \"2676786\", \"2451085\", \"225701\", \"5014270…\n$ ...536 &lt;chr&gt; \"1980 Jul\", \"8316149\", \"2783551\", \"2605812\", \"177739\", \"5532598…\n$ ...537 &lt;chr&gt; \"1980 Jun\", \"7568582\", \"2330134\", \"2108637\", \"221497\", \"5238448…\n$ ...538 &lt;chr&gt; \"1980 May\", \"7743877\", \"2518390\", \"2283891\", \"234499\", \"5225487…\n$ ...539 &lt;chr&gt; \"1980 Apr\", \"7681468\", \"2447218\", \"2244563\", \"202655\", \"5234250…\n$ ...540 &lt;chr&gt; \"1980 Mar\", \"7647141\", \"2720472\", \"2507174\", \"213298\", \"4926669…\n$ ...541 &lt;chr&gt; \"1980 Feb\", \"6628180\", \"2032683\", \"1829210\", \"203473\", \"4595497…\n$ ...542 &lt;chr&gt; \"1980 Jan\", \"7447353\", \"2151302\", \"1931682\", \"219620\", \"5296051…\n$ ...543 &lt;chr&gt; \"1979 Dec\", \"6818578\", \"2149023\", \"1957794\", \"191229\", \"4669555…\n$ ...544 &lt;chr&gt; \"1979 Nov\", \"6790714\", \"1947934\", \"1781864\", \"166070\", \"4842780…\n$ ...545 &lt;chr&gt; \"1979 Oct\", \"6139854\", \"1678523\", \"1515286\", \"163237\", \"4461331…\n$ ...546 &lt;chr&gt; \"1979 Sep\", \"6247485\", \"1799157\", \"1659252\", \"139905\", \"4448328…\n$ ...547 &lt;chr&gt; \"1979 Aug\", \"6612035\", \"1861340\", \"1672003\", \"189337\", \"4750695…\n$ ...548 &lt;chr&gt; \"1979 Jul\", \"5962679\", \"1601951\", \"1450878\", \"151073\", \"4360728…\n$ ...549 &lt;chr&gt; \"1979 Jun\", \"5525664\", \"1315067\", \"1163066\", \"152001\", \"4210597…\n$ ...550 &lt;chr&gt; \"1979 May\", \"5447369\", \"1365044\", \"1231622\", \"133422\", \"4082325…\n$ ...551 &lt;chr&gt; \"1979 Apr\", \"5339240\", \"1358965\", \"1225389\", \"133576\", \"3980275…\n$ ...552 &lt;chr&gt; \"1979 Mar\", \"5116645\", \"1235026\", \"1107249\", \"127777\", \"3881619…\n$ ...553 &lt;chr&gt; \"1979 Feb\", \"4596062\", \"1260536\", \"1138544\", \"121992\", \"3335526…\n$ ...554 &lt;chr&gt; \"1979 Jan\", \"4678197\", \"1287894\", \"1184263\", \"103631\", \"3390303…\n$ ...555 &lt;chr&gt; \"1978 Dec\", \"4661898\", \"1071705\", \"978140\", \"93565\", \"3590193\",…\n$ ...556 &lt;chr&gt; \"1978 Nov\", \"4904315\", \"1134252\", \"1027427\", \"106825\", \"3770063…\n$ ...557 &lt;chr&gt; \"1978 Oct\", \"4794022\", \"1317706\", \"1222452\", \"95254\", \"3476316\"…\n$ ...558 &lt;chr&gt; \"1978 Sep\", \"4581372\", \"1310734\", \"1214005\", \"96729\", \"3270638\"…\n$ ...559 &lt;chr&gt; \"1978 Aug\", \"4527776\", \"1046596\", \"944329\", \"102267\", \"3481180\"…\n$ ...560 &lt;chr&gt; \"1978 Jul\", \"4491517\", \"1142075\", \"1046306\", \"95769\", \"3349442\"…\n$ ...561 &lt;chr&gt; \"1978 Jun\", \"4382352\", \"1163399\", \"1069592\", \"93807\", \"3218953\"…\n$ ...562 &lt;chr&gt; \"1978 May\", \"3977730\", \"1017858\", \"905922\", \"111936\", \"2959872\"…\n$ ...563 &lt;chr&gt; \"1978 Apr\", \"4312686\", \"1221069\", \"1128044\", \"93025\", \"3091617\"…\n$ ...564 &lt;chr&gt; \"1978 Mar\", \"4327432\", \"1091087\", \"989544\", \"101543\", \"3236345\"…\n$ ...565 &lt;chr&gt; \"1978 Feb\", \"3411896\", \"874762\", \"781184\", \"93578\", \"2537134\", …\n$ ...566 &lt;chr&gt; \"1978 Jan\", \"4213726\", \"1195028\", \"1106123\", \"88905\", \"3018698\"…\n$ ...567 &lt;chr&gt; \"1977 Dec\", \"4020278\", \"999769\", \"910909\", \"88860\", \"3020509\", …\n$ ...568 &lt;chr&gt; \"1977 Nov\", \"4015654\", \"1136044\", \"1040478\", \"95566\", \"2879610\"…\n$ ...569 &lt;chr&gt; \"1977 Oct\", \"3994065\", \"1085527\", \"992756\", \"92771\", \"2908538\",…\n$ ...570 &lt;chr&gt; \"1977 Sep\", \"4012879\", \"1054008\", \"967594\", \"86414\", \"2958871\",…\n$ ...571 &lt;chr&gt; \"1977 Aug\", \"4075178\", \"1142921\", \"1042862\", \"100059\", \"2932257…\n$ ...572 &lt;chr&gt; \"1977 Jul\", \"3926665\", \"1203797\", \"1103695\", \"100102\", \"2722868…\n$ ...573 &lt;chr&gt; \"1977 Jun\", \"3786276\", \"1175717\", \"1079954\", \"95763\", \"2610559\"…\n$ ...574 &lt;chr&gt; \"1977 May\", \"3473583\", \"968707\", \"851305\", \"117402\", \"2504876\",…\n$ ...575 &lt;chr&gt; \"1977 Apr\", \"3823531\", \"1020737\", \"908371\", \"112366\", \"2802794\"…\n$ ...576 &lt;chr&gt; \"1977 Mar\", \"3729916\", \"1099440\", \"1007965\", \"91475\", \"2630476\"…\n$ ...577 &lt;chr&gt; \"1977 Feb\", \"3067312\", \"852853\", \"757718\", \"95135\", \"2214459\", …\n$ ...578 &lt;chr&gt; \"1977 Jan\", \"3686934\", \"838730\", \"739961\", \"98769\", \"2848204\", …\n$ ...579 &lt;chr&gt; \"1976 Dec\", \"3560030\", \"1031641\", \"932529\", \"99112\", \"2528389\",…\n$ ...580 &lt;chr&gt; \"1976 Nov\", \"3495886\", \"986267\", \"886898\", \"99369\", \"2509619\", …\n$ ...581 &lt;chr&gt; \"1976 Oct\", \"3516256\", \"1030862\", \"936426\", \"94436\", \"2485394\",…\n$ ...582 &lt;chr&gt; \"1976 Sep\", \"3374302\", \"990464\", \"907474\", \"82990\", \"2383838\", …\n$ ...583 &lt;chr&gt; \"1976 Aug\", \"3347979\", \"952210\", \"864580\", \"87630\", \"2395769\", …\n$ ...584 &lt;chr&gt; \"1976 Jul\", \"3547263\", \"1075102\", \"973813\", \"101289\", \"2472161\"…\n$ ...585 &lt;chr&gt; \"1976 Jun\", \"2942772\", \"756987\", \"667586\", \"89401\", \"2185785\", …\n$ ...586 &lt;chr&gt; \"1976 May\", \"2707964\", \"704515\", \"625507\", \"79008\", \"2003449\", …\n$ ...587 &lt;chr&gt; \"1976 Apr\", \"3245711\", \"956742\", \"871932\", \"84810\", \"2288969\", …\n$ ...588 &lt;chr&gt; \"1976 Mar\", \"3042929\", \"757098\", \"670391\", \"86707\", \"2285831\", …\n$ ...589 &lt;chr&gt; \"1976 Feb\", \"2815720\", \"799221\", \"734943\", \"64278\", \"2016499\", …\n$ ...590 &lt;chr&gt; \"1976 Jan\", \"3073525\", \"932564\", \"855542\", \"77022\", \"2140961\", …\n$ ...591 &lt;chr&gt; \"1975 Dec\", \"2854600\", \"746600\", \"667800\", \"78800\", \"2108000\", …\n$ ...592 &lt;chr&gt; \"1975 Nov\", \"2787700\", \"914100\", \"830800\", \"83300\", \"1873600\", …\n$ ...593 &lt;chr&gt; \"1975 Oct\", \"2883300\", \"781600\", \"705400\", \"76200\", \"2101700\", …\n$ ...594 &lt;chr&gt; \"1975 Sep\", \"2752600\", \"693700\", \"636500\", \"57200\", \"2058900\", …\n$ ...595 &lt;chr&gt; \"1975 Aug\", \"2636600\", \"760500\", \"687800\", \"72700\", \"1876100\", …\n$ ...596 &lt;chr&gt; \"1975 Jul\", \"2652500\", \"774800\", \"707900\", \"66900\", \"1877700\", …\n$ ...597 &lt;chr&gt; \"1975 Jun\", \"2438000\", \"513100\", \"447900\", \"65200\", \"1924900\", …\n$ ...598 &lt;chr&gt; \"1975 May\", \"2635800\", \"718000\", \"650500\", \"67500\", \"1917800\", …\n$ ...599 &lt;chr&gt; \"1975 Apr\", \"2660500\", \"819400\", \"751400\", \"68000\", \"1841100\", …\n$ ...600 &lt;chr&gt; \"1975 Mar\", \"2546700\", \"708600\", \"644500\", \"64100\", \"1838100\", …\n$ ...601 &lt;chr&gt; \"1975 Feb\", \"2483900\", \"838800\", \"775300\", \"63500\", \"1645100\", …\n$ ...602 &lt;chr&gt; \"1975 Jan\", \"2696000\", \"756400\", \"679500\", \"76900\", \"1939600\", …\n$ ...603 &lt;chr&gt; \"1974 Dec\", \"2543100\", \"639300\", \"574700\", \"64600\", \"1903800\", …\n$ ...604 &lt;chr&gt; \"1974 Nov\", \"2783300\", \"770700\", \"698900\", \"71800\", \"2012600\", …\n$ ...605 &lt;chr&gt; \"1974 Oct\", \"2874900\", \"817000\", \"743800\", \"73200\", \"2057900\", …\n$ ...606 &lt;chr&gt; \"1974 Sep\", \"2842800\", \"777100\", \"718300\", \"58800\", \"2065700\", …\n$ ...607 &lt;chr&gt; \"1974 Aug\", \"3145900\", \"819100\", \"746600\", \"72500\", \"2326800\", …\n$ ...608 &lt;chr&gt; \"1974 Jul\", \"2975700\", \"865500\", \"796100\", \"69400\", \"2110200\", …\n$ ...609 &lt;chr&gt; \"1974 Jun\", \"3018700\", \"803600\", \"723300\", \"80300\", \"2215100\", …\n$ ...610 &lt;chr&gt; \"1974 May\", \"3382000\", \"1005200\", \"925300\", \"79900\", \"2376800\",…\n$ ...611 &lt;chr&gt; \"1974 Apr\", \"2888400\", \"818400\", \"732900\", \"85500\", \"2070000\", …\n$ ...612 &lt;chr&gt; \"1974 Mar\", \"3110500\", \"959900\", \"890500\", \"69400\", \"2150600\", …\n$ ...613 &lt;chr&gt; \"1974 Feb\", \"2533200\", \"650300\", \"587300\", \"63000\", \"1882900\", …\n$ ...614 &lt;chr&gt; \"1974 Jan\", \"2460900\", \"515200\", \"453400\", \"61800\", \"1945700\", …\n$ ...615 &lt;chr&gt; \"1973 Dec\", \"2134200\", \"336000\", \"292000\", \"44000\", \"1798200\", …\n$ ...616 &lt;chr&gt; \"1973 Nov\", \"2164800\", \"362900\", \"315000\", \"47900\", \"1801900\", …\n$ ...617 &lt;chr&gt; \"1973 Oct\", \"1922300\", \"281200\", \"241900\", \"39300\", \"1641100\", …\n$ ...618 &lt;chr&gt; \"1973 Sep\", \"1996000\", \"259900\", \"227200\", \"32700\", \"1736100\", …\n$ ...619 &lt;chr&gt; \"1973 Aug\", \"1859700\", \"303200\", \"268800\", \"34400\", \"1556500\", …\n$ ...620 &lt;chr&gt; \"1973 Jul\", \"1787100\", \"303100\", \"275600\", \"27500\", \"1484000\", …\n$ ...621 &lt;chr&gt; \"1973 Jun\", \"1693900\", \"264400\", \"231600\", \"32800\", \"1429500\", …\n$ ...622 &lt;chr&gt; \"1973 May\", \"1704800\", \"272200\", \"240800\", \"31400\", \"1432600\", …\n$ ...623 &lt;chr&gt; \"1973 Apr\", \"1520300\", \"210900\", \"181000\", \"29900\", \"1309400\", …\n$ ...624 &lt;chr&gt; \"1973 Mar\", \"1649900\", \"276000\", \"251500\", \"24500\", \"1373900\", …\n$ ...625 &lt;chr&gt; \"1973 Feb\", \"1330700\", \"232200\", \"203800\", \"28400\", \"1098500\", …\n$ ...626 &lt;chr&gt; \"1973 Jan\", \"1655900\", \"283700\", \"256700\", \"27000\", \"1372200\", …\n$ ...627 &lt;chr&gt; \"1972 Dec\", \"1451400\", \"223300\", \"190700\", \"32600\", \"1228100\", …\n$ ...628 &lt;chr&gt; \"1972 Nov\", \"1424700\", \"263700\", \"237300\", \"26400\", \"1161000\", …\n$ ...629 &lt;chr&gt; \"1972 Oct\", \"1398800\", \"239700\", \"209200\", \"30500\", \"1159100\", …\n$ ...630 &lt;chr&gt; \"1972 Sep\", \"1383500\", \"288400\", \"257800\", \"30600\", \"1095100\", …\n$ ...631 &lt;chr&gt; \"1972 Aug\", \"1447000\", \"266900\", \"238800\", \"28100\", \"1180100\", …\n$ ...632 &lt;chr&gt; \"1972 Jul\", \"1294700\", \"218300\", \"187100\", \"31200\", \"1076400\", …\n$ ...633 &lt;chr&gt; \"1972 Jun\", \"1225900\", \"221600\", \"194900\", \"26700\", \"1004300\", …\n$ ...634 &lt;chr&gt; \"1972 May\", \"1328700\", \"245600\", \"217600\", \"28000\", \"1083100\", …\n$ ...635 &lt;chr&gt; \"1972 Apr\", \"1200200\", \"221300\", \"193700\", \"27600\", \"978900\", \"…\n$ ...636 &lt;chr&gt; \"1972 Mar\", \"1279200\", \"271200\", \"242200\", \"29000\", \"1008000\", …\n$ ...637 &lt;chr&gt; \"1972 Feb\", \"1079400\", \"215900\", \"191600\", \"24300\", \"863500\", \"…\n$ ...638 &lt;chr&gt; \"1972 Jan\", \"1173800\", \"221200\", \"192300\", \"28900\", \"952600\", \"…\n$ ...639 &lt;chr&gt; \"1971 Dec\", \"1183500\", \"207600\", \"189600\", \"18000\", \"975900\", \"…\n$ ...640 &lt;chr&gt; \"1971 Nov\", \"1159000\", \"205600\", \"189300\", \"16300\", \"953400\", \"…\n$ ...641 &lt;chr&gt; \"1971 Oct\", \"1171800\", \"185000\", \"166500\", \"18500\", \"986800\", \"…\n$ ...642 &lt;chr&gt; \"1971 Sep\", \"1167100\", \"205800\", \"188400\", \"17400\", \"961300\", \"…\n$ ...643 &lt;chr&gt; \"1971 Aug\", \"1178900\", \"227500\", \"209100\", \"18400\", \"951400\", \"…\n$ ...644 &lt;chr&gt; \"1971 Jul\", \"1270300\", \"263900\", \"245500\", \"18400\", \"1006400\", …\n$ ...645 &lt;chr&gt; \"1971 Jun\", \"1221000\", \"213400\", \"194100\", \"19300\", \"1007600\", …\n$ ...646 &lt;chr&gt; \"1971 May\", \"1167900\", \"242800\", \"222200\", \"20600\", \"925100\", \"…\n$ ...647 &lt;chr&gt; \"1971 Apr\", \"1188100\", \"229900\", \"208300\", \"21600\", \"958200\", \"…\n$ ...648 &lt;chr&gt; \"1971 Mar\", \"1278800\", \"251900\", \"225200\", \"26700\", \"1026900\", …\n$ ...649 &lt;chr&gt; \"1971 Feb\", \"1016800\", \"194700\", \"174100\", \"20600\", \"822100\", \"…\n$ ...650 &lt;chr&gt; \"1971 Jan\", \"1023000\", \"194300\", \"174100\", \"20200\", \"828700\", \"…\n$ ...651 &lt;chr&gt; \"1970 Dec\", \"1166500\", \"213100\", \"185200\", \"27900\", \"953400\", \"…\n$ ...652 &lt;chr&gt; \"1970 Nov\", \"1046600\", \"184700\", \"159800\", \"24900\", \"861900\", \"…\n$ ...653 &lt;chr&gt; \"1970 Oct\", \"1062200\", \"179300\", \"150200\", \"29100\", \"882900\", \"…\n$ ...654 &lt;chr&gt; \"1970 Sep\", \"1014200\", \"170900\", \"146500\", \"24400\", \"843300\", \"…\n$ ...655 &lt;chr&gt; \"1970 Aug\", \"1053300\", \"175400\", \"149100\", \"26300\", \"877900\", \"…\n$ ...656 &lt;chr&gt; \"1970 Jul\", \"1056400\", \"185400\", \"161400\", \"24000\", \"871000\", \"…\n$ ...657 &lt;chr&gt; \"1970 Jun\", \"1020100\", \"176800\", \"152800\", \"24000\", \"843300\", \"…\n$ ...658 &lt;chr&gt; \"1970 May\", \"1000900\", \"197400\", \"175000\", \"22400\", \"803500\", \"…\n$ ...659 &lt;chr&gt; \"1970 Apr\", \"964000\", \"149100\", \"127500\", \"21600\", \"814900\", \"1…\n$ ...660 &lt;chr&gt; \"1970 Mar\", \"1002000\", \"175800\", \"156800\", \"19000\", \"826200\", \"…\n$ ...661 &lt;chr&gt; \"1970 Feb\", \"842100\", \"144900\", \"128800\", \"16100\", \"697200\", \"1…\n$ ...662 &lt;chr&gt; \"1970 Jan\", \"1061300\", \"164400\", \"144500\", \"19900\", \"896900\", \"…\n$ ...663 &lt;chr&gt; \"1969 Dec\", \"1007000\", \"208200\", \"189900\", \"18300\", \"798800\", \"…\n$ ...664 &lt;chr&gt; \"1969 Nov\", \"969200\", \"171700\", \"152200\", \"19500\", \"797500\", \"1…\n$ ...665 &lt;chr&gt; \"1969 Oct\", \"1056800\", \"206000\", \"185000\", \"21000\", \"850800\", \"…\n$ ...666 &lt;chr&gt; \"1969 Sep\", \"1004400\", \"175500\", \"157800\", \"17700\", \"828900\", \"…\n$ ...667 &lt;chr&gt; \"1969 Aug\", \"910200\", \"152900\", \"134300\", \"18600\", \"757300\", \"1…\n$ ...668 &lt;chr&gt; \"1969 Jul\", \"952800\", \"192000\", \"171000\", \"21000\", \"760800\", \"1…\n$ ...669 &lt;chr&gt; \"1969 Jun\", \"878500\", \"157000\", \"138600\", \"18400\", \"721500\", \"1…\n$ ...670 &lt;chr&gt; \"1969 May\", \"866200\", \"179500\", \"160900\", \"18600\", \"686700\", \"1…\n$ ...671 &lt;chr&gt; \"1969 Apr\", \"864600\", \"165300\", \"148500\", \"16800\", \"699300\", \"1…\n$ ...672 &lt;chr&gt; \"1969 Mar\", \"864400\", \"191100\", \"172300\", \"18800\", \"673300\", \"1…\n$ ...673 &lt;chr&gt; \"1969 Feb\", \"730000\", \"172000\", \"154500\", \"17500\", \"558000\", \"1…\n$ ...674 &lt;chr&gt; \"1969 Jan\", \"880200\", \"169400\", \"149200\", \"20200\", \"710800\", \"1…\n$ ...675 &lt;chr&gt; \"1968 Dec\", \"768600\", \"154000\", \"133100\", \"20900\", \"614600\", \"1…\n$ ...676 &lt;chr&gt; \"1968 Nov\", \"781000\", \"158500\", \"135400\", \"23100\", \"622500\", \"1…\n$ ...677 &lt;chr&gt; \"1968 Oct\", \"793000\", \"165900\", \"143900\", \"22000\", \"627100\", \"1…\n$ ...678 &lt;chr&gt; \"1968 Sep\", \"772400\", \"170400\", \"149500\", \"20900\", \"602000\", \"1…\n$ ...679 &lt;chr&gt; \"1968 Aug\", \"754900\", \"166700\", \"145500\", \"21200\", \"588200\", \"1…\n$ ...680 &lt;chr&gt; \"1968 Jul\", \"789300\", \"164300\", \"143900\", \"20400\", \"625000\", \"1…\n$ ...681 &lt;chr&gt; \"1968 Jun\", \"751300\", \"164800\", \"145200\", \"19600\", \"586500\", \"1…\n$ ...682 &lt;chr&gt; \"1968 May\", \"809800\", \"180800\", \"159000\", \"21800\", \"629000\", \"1…\n$ ...683 &lt;chr&gt; \"1968 Apr\", \"695700\", \"129600\", \"107400\", \"22200\", \"566100\", \"1…\n$ ...684 &lt;chr&gt; \"1968 Mar\", \"733000\", \"164700\", \"143400\", \"21300\", \"568300\", \"1…\n$ ...685 &lt;chr&gt; \"1968 Feb\", \"694700\", \"168800\", \"147900\", \"20900\", \"525900\", \"1…\n$ ...686 &lt;chr&gt; \"1968 Jan\", \"631000\", \"150000\", \"130900\", \"19100\", \"481000\", \"9…\n$ ...687 &lt;chr&gt; \"1967 Dec\", \"668200\", \"145100\", \"123200\", \"21900\", \"523100\", \"9…\n$ ...688 &lt;chr&gt; \"1967 Nov\", \"666900\", \"138800\", \"118400\", \"20400\", \"528100\", \"1…\n$ ...689 &lt;chr&gt; \"1967 Oct\", \"690900\", \"148300\", \"126900\", \"21400\", \"542600\", \"1…\n$ ...690 &lt;chr&gt; \"1967 Sep\", \"668900\", \"134500\", \"112800\", \"21700\", \"534400\", \"1…\n$ ...691 &lt;chr&gt; \"1967 Aug\", \"698400\", \"149500\", \"128700\", \"20800\", \"548900\", \"1…\n$ ...692 &lt;chr&gt; \"1967 Jul\", \"629400\", \"126500\", \"105300\", \"21200\", \"502900\", \"1…\n$ ...693 &lt;chr&gt; \"1967 Jun\", \"665500\", \"139500\", \"124500\", \"15000\", \"526000\", \"1…\n$ ...694 &lt;chr&gt; \"1967 May\", \"689500\", \"154200\", \"137800\", \"16400\", \"535300\", \"1…\n$ ...695 &lt;chr&gt; \"1967 Apr\", \"645700\", \"123400\", \"105200\", \"18200\", \"522300\", \"1…\n$ ...696 &lt;chr&gt; \"1967 Mar\", \"655600\", \"123600\", \"107900\", \"15700\", \"532000\", \"1…\n$ ...697 &lt;chr&gt; \"1967 Feb\", \"607200\", \"140900\", \"127100\", \"13800\", \"466300\", \"1…\n$ ...698 &lt;chr&gt; \"1967 Jan\", \"610700\", \"112100\", \"98100\", \"14000\", \"498600\", \"92…\n$ ...699 &lt;chr&gt; \"1966 Dec\", \"671800\", \"131300\", \"117000\", \"14300\", \"540500\", \"9…\n$ ...700 &lt;chr&gt; \"1966 Nov\", \"629200\", \"128300\", \"112900\", \"15400\", \"500900\", \"9…\n$ ...701 &lt;chr&gt; \"1966 Oct\", \"624900\", \"116800\", \"104200\", \"12600\", \"508100\", \"9…\n$ ...702 &lt;chr&gt; \"1966 Sep\", \"638900\", \"126600\", \"112900\", \"13700\", \"512300\", \"1…\n$ ...703 &lt;chr&gt; \"1966 Aug\", \"645800\", \"125400\", \"109800\", \"15600\", \"520400\", \"1…\n$ ...704 &lt;chr&gt; \"1966 Jul\", \"622100\", \"107200\", \"90500\", \"16700\", \"514900\", \"11…\n$ ...705 &lt;chr&gt; \"1966 Jun\", \"561200\", \"107900\", \"93500\", \"14400\", \"453300\", \"90…\n$ ...706 &lt;chr&gt; \"1966 May\", \"648500\", \"121800\", \"108100\", \"13700\", \"526700\", \"1…\n$ ...707 &lt;chr&gt; \"1966 Apr\", \"575200\", \"107400\", \"93600\", \"13800\", \"467800\", \"98…\n$ ...708 &lt;chr&gt; \"1966 Mar\", \"642500\", \"112200\", \"94100\", \"18100\", \"530300\", \"11…\n$ ...709 &lt;chr&gt; \"1966 Feb\", \"610000\", \"115200\", \"102600\", \"12600\", \"494800\", \"1…\n$ ...710 &lt;chr&gt; \"1966 Jan\", \"569100\", \"90600\", \"75300\", \"15300\", \"478500\", \"937…\n$ ...711 &lt;chr&gt; \"1965 Dec\", \"605600\", \"88000\", \"74100\", \"13900\", \"517600\", \"105…\n$ ...712 &lt;chr&gt; \"1965 Nov\", \"599700\", \"107500\", \"92800\", \"14700\", \"492200\", \"93…\n$ ...713 &lt;chr&gt; \"1965 Oct\", \"565400\", \"90900\", \"77400\", \"13500\", \"474500\", \"102…\n$ ...714 &lt;chr&gt; \"1965 Sep\", \"573900\", \"96000\", \"82200\", \"13800\", \"477900\", \"106…\n$ ...715 &lt;chr&gt; \"1965 Aug\", \"582500\", \"93800\", \"79000\", \"14800\", \"488700\", \"101…\n$ ...716 &lt;chr&gt; \"1965 Jul\", \"554000\", \"77700\", \"63700\", \"14000\", \"476300\", \"102…\n$ ...717 &lt;chr&gt; \"1965 Jun\", \"530200\", \"93200\", \"80200\", \"13000\", \"437000\", \"867…\n$ ...718 &lt;chr&gt; \"1965 May\", \"575000\", \"99300\", \"85400\", \"13900\", \"475700\", \"100…\n$ ...719 &lt;chr&gt; \"1965 Apr\", \"535700\", \"89000\", \"77100\", \"11900\", \"446700\", \"894…\n$ ...720 &lt;chr&gt; \"1965 Mar\", \"611500\", \"93700\", \"79600\", \"14100\", \"517800\", \"100…\n$ ...721 &lt;chr&gt; \"1965 Feb\", \"493200\", \"83700\", \"72300\", \"11400\", \"409500\", \"877…\n$ ...722 &lt;chr&gt; \"1965 Jan\", \"584600\", \"88700\", \"75600\", \"13100\", \"495900\", \"100…\n$ ...723 &lt;chr&gt; \"1964 Dec\", \"542200\", \"73200\", \"60100\", \"13100\", \"469000\", \"947…\n$ ...724 &lt;chr&gt; \"1964 Nov\", \"498400\", \"69200\", \"55200\", \"14000\", \"429200\", \"839…\n$ ...725 &lt;chr&gt; \"1964 Oct\", \"575000\", \"79400\", \"66000\", \"13400\", \"495600\", \"100…\n$ ...726 &lt;chr&gt; \"1964 Sep\", \"542300\", \"88900\", \"78900\", \"10000\", \"453400\", \"104…\n$ ...727 &lt;chr&gt; \"1964 Aug\", \"552300\", \"99700\", \"88500\", \"11200\", \"452600\", \"927…\n$ ...728 &lt;chr&gt; \"1964 Jul\", \"466000\", \"57100\", \"46900\", \"10200\", \"408900\", \"900…\n$ ...729 &lt;chr&gt; \"1964 Jun\", \"532800\", \"84300\", \"74700\", \"9600\", \"448500\", \"9520…\n$ ...730 &lt;chr&gt; \"1964 May\", \"513100\", \"90000\", \"79200\", \"10800\", \"423100\", \"895…\n$ ...731 &lt;chr&gt; \"1964 Apr\", \"501800\", \"76100\", \"64500\", \"11600\", \"425700\", \"869…\n$ ...732 &lt;chr&gt; \"1964 Mar\", \"499800\", \"91600\", \"79900\", \"11700\", \"408200\", \"913…\n$ ...733 &lt;chr&gt; \"1964 Feb\", \"466900\", \"69000\", \"59000\", \"10000\", \"397900\", \"893…\n$ ...734 &lt;chr&gt; \"1964 Jan\", \"564500\", \"91000\", \"78900\", \"12100\", \"473500\", \"108…\n\n\n\n\n\nThe output shows that we have successfully excluded non-relevant rows and retained only the actual trade-related data.\nTransposing the Data\nNext, since our columns represent month-year data, we need to transpose the dataset to improve its usability for subsequent data visualisation or time-series analysis. The month-year columns will be consolidated into a single column, transforming them into row identifiers, while trade-related variables will now be represented as columns.\nThe code chunk uses the t() function for transposing and the as.data.frame() function to ensure that the transposed data remains in a dataframe format:\n\ntransposed_merchandisetrade &lt;- as.data.frame(t(cleaned_merchandisetrade))\n\n# Set the first row as column names\ncolnames(transposed_merchandisetrade) &lt;- as.character(transposed_merchandisetrade[1, ])\n\n# Remove the first row from the data frame\ntransposed_merchandisetrade &lt;- transposed_merchandisetrade[-1, ]\n\nAfter transposing, we examined the structure of the resulting data frame using the glimpse() function.\n\nglimpse(transposed_merchandisetrade)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 733\nColumns: 69\n$ `Data Series`                                    &lt;chr&gt; \"2025 Jan\", \"2024 Dec…\n$ `Total Merchandise Trade, (At Current Prices)`   &lt;chr&gt; \"114153979.9\", \"11627…\n$ Oil                                              &lt;chr&gt; \"19490289.9\", \"184889…\n$ Petroleum                                        &lt;chr&gt; \"16418934.4\", \"155646…\n$ `Oil Bunkers`                                    &lt;chr&gt; \"3071355.5\", \"2924319…\n$ `Non-Oil`                                        &lt;chr&gt; \"94663689.9\", \"977898…\n$ `Food & Live Animals`                            &lt;chr&gt; \"2460910.6\", \"2704578…\n$ `Beverages & Tobacco`                            &lt;chr&gt; \"663688\", \"851520.1\",…\n$ `Crude Materials (Excl Fuels)`                   &lt;chr&gt; \"592338.1\", \"598748.5…\n$ `Animal & Vegetable Oils Fats & Waxes`           &lt;chr&gt; \"388184\", \"176576.3\",…\n$ `Chemicals & Chemical Products`                  &lt;chr&gt; \"8608979.8\", \"8845755…\n$ `Manufactured Goods`                             &lt;chr&gt; \"3573942.1\", \"3916616…\n$ `Machinery & Transport Equipment`                &lt;chr&gt; \"65218248\", \"66552514…\n$ `Miscellaneous Manufactured Articles`            &lt;chr&gt; \"8065229.8\", \"9388482…\n$ `Miscellaneous (Excluding Oil Bunkers)`          &lt;chr&gt; \"5092169.4\", \"4755027…\n$ `Total Merchandise Imports, (At Current Prices)` &lt;chr&gt; \"54746365.7\", \"561359…\n$ Oil                                              &lt;chr&gt; \"9791905.4\", \"9869429…\n$ Petroleum                                        &lt;chr&gt; \"9791905.4\", \"9869429…\n$ `Non-Oil`                                        &lt;chr&gt; \"44954460.3\", \"462664…\n$ `Food & Live Animals`                            &lt;chr&gt; \"1227050.7\", \"1264573…\n$ `Beverages & Tobacco`                            &lt;chr&gt; \"357340.2\", \"448450.3…\n$ `Crude Materials (Excl Fuels)`                   &lt;chr&gt; \"242666\", \"258481.7\",…\n$ `Animal & Vegetable Oils Fats & Waxes`           &lt;chr&gt; \"366400.3\", \"152675.6…\n$ `Chemicals & Chemical Products`                  &lt;chr&gt; \"3379008.9\", \"3541227…\n$ `Manufactured Goods`                             &lt;chr&gt; \"2189363.7\", \"2407338…\n$ `Machinery & Transport Equipment`                &lt;chr&gt; \"30999083.2\", \"318362…\n$ `Miscellaneous Manufactured Articles`            &lt;chr&gt; \"3736353.7\", \"4252470…\n$ `Miscellaneous (Excluding Oil Bunkers)`          &lt;chr&gt; \"2457193.5\", \"2105002…\n$ `Total Merchandise Exports, (At Current Prices)` &lt;chr&gt; \"59407614.2\", \"601428…\n$ Oil                                              &lt;chr&gt; \"9698384.5\", \"8619544…\n$ Petroleum                                        &lt;chr&gt; \"6627029\", \"5695224.9…\n$ `Oil Bunkers`                                    &lt;chr&gt; \"3071355.5\", \"2924319…\n$ `Non-Oil`                                        &lt;chr&gt; \"49709229.6\", \"515233…\n$ `Food & Live Animals`                            &lt;chr&gt; \"1233859.9\", \"1440005…\n$ `Beverages & Tobacco`                            &lt;chr&gt; \"306347.8\", \"403069.8…\n$ `Crude Materials (Excl Fuels)`                   &lt;chr&gt; \"349672\", \"340266.9\",…\n$ `Animal & Vegetable Oils Fats & Waxes`           &lt;chr&gt; \"21783.7\", \"23900.7\",…\n$ `Chemicals & Chemical Products`                  &lt;chr&gt; \"5229971\", \"5304528.3…\n$ `Manufactured Goods`                             &lt;chr&gt; \"1384578.4\", \"1509277…\n$ `Machinery & Transport Equipment`                &lt;chr&gt; \"34219164.8\", \"347162…\n$ `Miscellaneous Manufactured Articles`            &lt;chr&gt; \"4328876.1\", \"5136011…\n$ `Miscellaneous (Excluding Oil Bunkers)`          &lt;chr&gt; \"2634975.9\", \"2650024…\n$ `Total Domestic Exports, (At Current Prices)`    &lt;chr&gt; \"24671972.8\", \"236846…\n$ Oil                                              &lt;chr&gt; \"9539344\", \"8457134.7…\n$ Petroleum                                        &lt;chr&gt; \"6467988.4\", \"5532815…\n$ `Oil Bunkers`                                    &lt;chr&gt; \"3071355.5\", \"2924319…\n$ `Non-Oil`                                        &lt;chr&gt; \"15132628.8\", \"152275…\n$ `Food & Live Animals`                            &lt;chr&gt; \"1040217.3\", \"1256139…\n$ `Beverages & Tobacco`                            &lt;chr&gt; \"8963.9\", \"12835.9\", …\n$ `Crude Materials (Excl Fuels)`                   &lt;chr&gt; \"227455.1\", \"227288.8…\n$ `Animal & Vegetable Oils Fats & Waxes`           &lt;chr&gt; \"15118.6\", \"16292.1\",…\n$ `Chemicals & Chemical Products`                  &lt;chr&gt; \"3383720.5\", \"3105807…\n$ `Manufactured Goods`                             &lt;chr&gt; \"335830.5\", \"392376.5…\n$ `Machinery & Transport Equipment`                &lt;chr&gt; \"6180281.6\", \"6256105…\n$ `Miscellaneous Manufactured Articles`            &lt;chr&gt; \"2147368.7\", \"2690715…\n$ `Miscellaneous (Excluding Oil Bunkers)`          &lt;chr&gt; \"1793672.5\", \"1269988…\n$ `Total Re-Exports, (At Current Prices)`          &lt;chr&gt; \"34735641.4\", \"364581…\n$ Oil                                              &lt;chr&gt; \"159040.6\", \"162409.6…\n$ Petroleum                                        &lt;chr&gt; \"159040.6\", \"162409.6…\n$ `Non-Oil`                                        &lt;chr&gt; \"34576600.9\", \"362957…\n$ `Food & Live Animals`                            &lt;chr&gt; \"193642.6\", \"183865.9…\n$ `Beverages & Tobacco`                            &lt;chr&gt; \"297383.9\", \"390233.8…\n$ `Crude Materials (Excl Fuels)`                   &lt;chr&gt; \"122216.9\", \"112978\",…\n$ `Animal & Vegetable Oils Fats & Waxes`           &lt;chr&gt; \"6665.1\", \"7608.6\", \"…\n$ `Chemicals & Chemical Products`                  &lt;chr&gt; \"1846250.4\", \"2198720…\n$ `Manufactured Goods`                             &lt;chr&gt; \"1048747.9\", \"1116900…\n$ `Machinery & Transport Equipment`                &lt;chr&gt; \"28038883.2\", \"284601…\n$ `Miscellaneous Manufactured Articles`            &lt;chr&gt; \"2181507.4\", \"2445295…\n$ `Miscellaneous (Excluding Oil Bunkers)`          &lt;chr&gt; \"841303.4\", \"1380035.…\n\n\n\n\n\nFrom the output of glimpse(), the following issues were identified:\n\nThe column that has the dates is now labelled as “Data Series”. We will rename this to “Date”.\nAll data types are character strings (CHR). We will convert the “Date” column to date format and the remaining columns to numeric types for appropriate data handling.\n\nThe following code chunk renames the “Data Series” column to “Date”:\n\ncolnames(transposed_merchandisetrade)[1] &lt;- \"Date\"\n\nThe following code chunk converts the data types into date and numeric formats accordingly. It also filter out entries from Jan 2015 onwards.\n\n# Set the locale to English for consistent date parsing\nSys.setlocale(\"LC_TIME\", \"C\")\n\n[1] \"C\"\n\ntransposed_merchandisetrade$Date &lt;- as.Date(paste0(transposed_merchandisetrade$Date, \"-01\"), format=\"%Y %b-%d\")\n\n# Filter out entries from January 2015 onwards\nfiltered_merchandisetrade &lt;- transposed_merchandisetrade[transposed_merchandisetrade$Date &gt;= as.Date(\"2015-01-01\"), ]\n\nFurther data preparation and wrangling will be performed in the respective sections to prepare the data for the specific visualisation / analysis."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#non-oil-domestic-exports-by-major-commodity-sections-2024",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#non-oil-domestic-exports-by-major-commodity-sections-2024",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "3.3 Non-Oil Domestic Exports By Major Commodity Sections, 2024",
    "text": "3.3 Non-Oil Domestic Exports By Major Commodity Sections, 2024\n\n\n\n\n\n\n3.3.1 Critique - Quadrant III: Ugly and Confusing\n✅ Elements are well-aligned and spaced effectively.\n❌ The visualisation uses a stacked bar chart, which is typically meant for displaying proportional contributions. However, the data seems to focus on absolute values as they are displayed in a larger font size as compared to the percentages. This suggests a greater importance on actual values over relative proportions.\n❌ The segments within the stacked bar chart are not arranged in descending order of value, making it challenging to quickly assess which sectors are more significant based on size.\n❌ The visualisation highlights the top three commodities based on the text box at the bottom. However, presenting the data via a stacked bar chart makes it difficult for viewers to quickly identify the top 3 commodities.\n❌ The labels for the respective commodities do not follow the visual order of the segments in the stacked bar chart (e.g. Beverages suddenly presented after Miscellaneous Manufactured Articles), increasing cognitive load required to interpret the chart as viewers naturally expect the top-most label to correspond to the top-most segment in the chart, and so forth down the line.\n\n\n3.3.2 Proposed Data Visualisation Makeover\nThe image below presents a general mock-up of the proposed data visualization makeover, accompanied by an explanation of the thought process behind the suggested changes.\n\n\n\n3.3.3 Revised Data Visualisation\n\nAdditional Data Preparation\nSince we are only looking at Non-Oil Domestic Exports by Major Commodity Sections, we will filter out the following columns 48 to 56 from filtered_merchadisetrade obtained from Section 2.3. For reference, the column numbers and their respective names are shown in the code chunk below.\n\n\n\n\n\n\nExpand to See Column Names\n\n\n\n\n\n\ncolnames(filtered_merchandisetrade)\n\n [1] \"Date\"                                          \n [2] \"Total Merchandise Trade, (At Current Prices)\"  \n [3] \"Oil\"                                           \n [4] \"Petroleum\"                                     \n [5] \"Oil Bunkers\"                                   \n [6] \"Non-Oil\"                                       \n [7] \"Food & Live Animals\"                           \n [8] \"Beverages & Tobacco\"                           \n [9] \"Crude Materials (Excl Fuels)\"                  \n[10] \"Animal & Vegetable Oils Fats & Waxes\"          \n[11] \"Chemicals & Chemical Products\"                 \n[12] \"Manufactured Goods\"                            \n[13] \"Machinery & Transport Equipment\"               \n[14] \"Miscellaneous Manufactured Articles\"           \n[15] \"Miscellaneous (Excluding Oil Bunkers)\"         \n[16] \"Total Merchandise Imports, (At Current Prices)\"\n[17] \"Oil\"                                           \n[18] \"Petroleum\"                                     \n[19] \"Non-Oil\"                                       \n[20] \"Food & Live Animals\"                           \n[21] \"Beverages & Tobacco\"                           \n[22] \"Crude Materials (Excl Fuels)\"                  \n[23] \"Animal & Vegetable Oils Fats & Waxes\"          \n[24] \"Chemicals & Chemical Products\"                 \n[25] \"Manufactured Goods\"                            \n[26] \"Machinery & Transport Equipment\"               \n[27] \"Miscellaneous Manufactured Articles\"           \n[28] \"Miscellaneous (Excluding Oil Bunkers)\"         \n[29] \"Total Merchandise Exports, (At Current Prices)\"\n[30] \"Oil\"                                           \n[31] \"Petroleum\"                                     \n[32] \"Oil Bunkers\"                                   \n[33] \"Non-Oil\"                                       \n[34] \"Food & Live Animals\"                           \n[35] \"Beverages & Tobacco\"                           \n[36] \"Crude Materials (Excl Fuels)\"                  \n[37] \"Animal & Vegetable Oils Fats & Waxes\"          \n[38] \"Chemicals & Chemical Products\"                 \n[39] \"Manufactured Goods\"                            \n[40] \"Machinery & Transport Equipment\"               \n[41] \"Miscellaneous Manufactured Articles\"           \n[42] \"Miscellaneous (Excluding Oil Bunkers)\"         \n[43] \"Total Domestic Exports, (At Current Prices)\"   \n[44] \"Oil\"                                           \n[45] \"Petroleum\"                                     \n[46] \"Oil Bunkers\"                                   \n[47] \"Non-Oil\"                                       \n[48] \"Food & Live Animals\"                           \n[49] \"Beverages & Tobacco\"                           \n[50] \"Crude Materials (Excl Fuels)\"                  \n[51] \"Animal & Vegetable Oils Fats & Waxes\"          \n[52] \"Chemicals & Chemical Products\"                 \n[53] \"Manufactured Goods\"                            \n[54] \"Machinery & Transport Equipment\"               \n[55] \"Miscellaneous Manufactured Articles\"           \n[56] \"Miscellaneous (Excluding Oil Bunkers)\"         \n[57] \"Total Re-Exports, (At Current Prices)\"         \n[58] \"Oil\"                                           \n[59] \"Petroleum\"                                     \n[60] \"Non-Oil\"                                       \n[61] \"Food & Live Animals\"                           \n[62] \"Beverages & Tobacco\"                           \n[63] \"Crude Materials (Excl Fuels)\"                  \n[64] \"Animal & Vegetable Oils Fats & Waxes\"          \n[65] \"Chemicals & Chemical Products\"                 \n[66] \"Manufactured Goods\"                            \n[67] \"Machinery & Transport Equipment\"               \n[68] \"Miscellaneous Manufactured Articles\"           \n[69] \"Miscellaneous (Excluding Oil Bunkers)\"         \n\n\n\n\n\nThe following code chunk stores these filtered out columns into a new dataframe called filtered_merchandisetrade2:\n\nfiltered_merchandisetrade2 &lt;- filtered_merchandisetrade[, c(1, 48:56)]\n\nSince we are only focusing on non-oil domestic exports in 2024, we will only retain 2024 records via the following code chunk:\n\nfiltered_merchandisetrade2$Date &lt;- as.Date(filtered_merchandisetrade2$Date)\nfiltered_merchandisetrade2$Year &lt;- format(filtered_merchandisetrade2$Date, \"%Y\")\nfiltered_merchandisetrade2$Year &lt;- as.numeric(filtered_merchandisetrade2$Year)\nfiltered_merchandisetrade2 &lt;- filtered_merchandisetrade2 %&gt;%\n  filter(Year == 2024)\n\nWe will also aggregate the non-domestic exports for each commodity section for 2024 and convert them to billions for better readability via the following code chunk:\n\nfiltered_merchandisetrade2[, 2:10] &lt;- lapply(filtered_merchandisetrade2[, 2:10], function(x) as.numeric(gsub(\",\", \"\", x)))\n\ndomesticexport_2024 &lt;- data.frame(t(colSums(filtered_merchandisetrade2[, 2:10], na.rm = TRUE)/1e6))\n\n# Add Year column to indicate that these totals belong to 2024\ndomesticexport_2024$Year &lt;- 2024\n\nWe will tranpose domesticexport_2024 for easier processing:\n\n\n\n\n\n\nExpand to See the Code\n\n\n\n\n\n\ndomesticexport_2024_long &lt;- domesticexport_2024 %&gt;%\n  pivot_longer(cols = -Year, names_to = \"Category\", values_to = \"Value\") %&gt;%\n  mutate(Category = str_replace_all(Category, \"\\\\.\", \" \")) %&gt;%  # Replace dots with spaces\n  arrange(desc(Value))\n\ndomesticexport_2024_long$Category &lt;- str_squish(domesticexport_2024_long$Category)\n\nreplacement_names &lt;- c(\n  \"Machinery Transport Equipment\" = \"Machinery & Transport Equipment\",\n  \"Chemicals Chemical Products\" = \"Chemicals & Chemical Products\",\n  \"Miscellaneous Manufactured Articles\" = \"Miscellaneous Manufactured Articles\",\n  \"Food Live Animals\" = \"Food & Live Animals\",\n  \"Miscellaneous Excluding Oil Bunkers\" = \"Miscellaneous (Excluding Oil Bunkers)\",\n  \"Manufactured Goods\" = \"Manufactured Goods\",\n  \"Crude Materials Excl Fuels\" = \"Crude Materials (Excl Fuels)\",\n  \"Beverages Tobacco\" = \"Beverages & Tobacco\",\n  \"Animal Vegetable Oils Fats Waxes\" = \"Animal & Vegetable Oils Fats & Waxes\"\n)\n\ndomesticexport_2024_long &lt;- domesticexport_2024_long %&gt;%\n  mutate(Category = recode(Category, !!!replacement_names))\n\n\n\n\n\n\nData Visualisation\nAfter all the data preparation has been completed, the following code chunk plots the revised data visualisation.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntop_3_categories &lt;- domesticexport_2024_long$Category[1:3]\n\ndomesticexport_2024_long &lt;- domesticexport_2024_long %&gt;%\n  mutate(Color = ifelse(Category %in% top_3_categories, Category, \"Others\"))\n\ncolor_palette &lt;- c(\"#FFC000\", \"#70AD47\", \"#ED7D31\", \"#D9D9D9\")\n\n\ndomesticexport_2024_long &lt;- domesticexport_2024_long %&gt;%\n  mutate(Percentage = Value / sum(Value))\n\n\nplot1 &lt;- ggplot(domesticexport_2024_long, aes(x = reorder(Category, Value), y = Value, fill = Color)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = paste0(\"S$\", formatC(Value, format = \"f\", big.mark = \",\", digits = 1), \"B\")),\n            hjust = -0.1, size = 4, color = \"black\") +  # Data Labels\n  scale_fill_manual(values = setNames(color_palette, c(top_3_categories, \"Others\"))) +\n  labs(title = \"Non-Oil Domestic Exports \\n by Commodity Sections (2024)\", x = NULL, y = \"S$ Billion\") +\n  coord_flip() +  \n  scale_y_continuous(limits = c(0, 100)) +  \n  theme_minimal() +\n  theme(\n    legend.position = \"none\",  \n    plot.title = element_text(size = 12, hjust = 0.5, face = \"bold\")\n  )\n\nplot2 &lt;- ggplot(domesticexport_2024_long, aes(x = \"\", y = Value, fill = Color)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  scale_fill_manual(values = setNames(color_palette, c(top_3_categories, \"Others\"))) +\n  coord_polar(\"y\", start = 0) +\n  labs(title = \"Proportion of Non-Oil Domestic Exports\\nby Commodity Sections (2024)\") +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 12, hjust = 0.5, face = \"bold\")\n  ) +\n\n  \n  annotate(\"text\", x = 1.3, y = sum(domesticexport_2024_long$Value) * 0.8, \n           label = \"Machinery & Transport Equipment: \\n                    40.5%\", \n           size = 4, fontface = \"bold\", color = \"black\", vjust=4.5, hjust=0.1) +\n\n  annotate(\"text\", x = 1.3, y = sum(domesticexport_2024_long$Value) * 0.5, \n           label = \"Chemicals & \\n         Chemical Products:\\n   25.6%\", \n           size = 4, fontface = \"bold\", color = \"black\", vjust=-3, hjust=1.3) +\n\n  annotate(\"text\", x = 1.3, y = sum(domesticexport_2024_long$Value) * 0.2, \n           label = \"Miscellaneous \\nManufactured Articles:\\n16.5%\", \n           size = 4, fontface = \"bold\", color = \"black\", vjust=1.5, hjust=0.5)\n\n\nfinal_plot &lt;- (plot1 | plot2) + \n  plot_annotation(\n    title = \"Machinery & Transport Equipment contributed the most \\n to non-oil domestic exports in 2024.\",\n    theme = theme(plot.title = element_text(size = 20, hjust = 0.5, face = \"bold\")) \n  )\n\n\nprint(final_plot)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nThe read_csv() function of the readr package will be used to import eventlog.csv into R:\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nThe kable() function will be used to review the structure of the imported data frame:\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\n\nStep 1. The code chunk below creates two new fields (wkday and hour):\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2. The code chunk below creates the attacks tibble data frame:\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nkable() is used again to view the table after processing:\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#importing-data",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "The read_csv() function of the readr package will be used to import eventlog.csv into R:\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#examining-the-data-structure",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#examining-the-data-structure",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "The kable() function will be used to review the structure of the imported data frame:\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "Step 1. The code chunk below creates two new fields (wkday and hour):\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2. The code chunk below creates the attacks tibble data frame:\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nkable() is used again to view the table after processing:\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#building-multiple-calendar-heatmaps",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#building-multiple-calendar-heatmaps",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "2.1 Building Multiple Calendar Heatmaps",
    "text": "2.1 Building Multiple Calendar Heatmaps\nStep 1. Deriving attack by country object through calculating the % of attacks by country.\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2. Preparing the tidy data frame.\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3. Plotting the multiple calendar heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#data-import",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#data-import",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "3.1 Data Import",
    "text": "3.1 Data Import\nThe code chunk below imports arrivals_by_air.xlsx by using the read_excel() function:\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#deriving-month-and-year-fields",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#deriving-month-and-year-fields",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "3.2 Deriving Month and Year Fields",
    "text": "3.2 Deriving Month and Year Fields\nTwo fields, month and year are derived from the Month-Year field via the code chunk below:\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#extracting-the-target-country",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#extracting-the-target-country",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "3.3 Extracting the Target Country",
    "text": "3.3 Extracting the Target Country\nThe code chunk below extracts data for the target country, Vietnam:\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#computing-year-average-arrivals-by-month",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#computing-year-average-arrivals-by-month",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "3.4 Computing Year Average Arrivals by Month",
    "text": "3.4 Computing Year Average Arrivals by Month\nThe code chunk below uses group_by() and `summarise()~ to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-cycle-plot",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-cycle-plot",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "3.5 Plotting the Cycle Plot",
    "text": "3.5 Plotting the Cycle Plot\nThe code chunk below is used to plot the cycle plot:\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#data-import-1",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#data-import-1",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "4.1 Data Import",
    "text": "4.1 Data Import\nThe code chunk below imports rice.csv via read_csv():\n\nrice &lt;- read_csv(\"data/rice.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-slopegraph",
    "href": "Hands-on Exercise/Hands-on_Ex07/Hands-on_Ex07.html#plotting-the-slopegraph",
    "title": "Hands-on Exercise 7.0: Visualising and Analysing Time-Oriented Data",
    "section": "4.2 Plotting the Slopegraph",
    "text": "4.2 Plotting the Slopegraph\nThe code chunk below plots a basic slopegraph:\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\")"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#overall-exports-and-imports-of-services-2020---2024-1",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#overall-exports-and-imports-of-services-2020---2024-1",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "3.1 Overall Exports and Imports of Services, 2020 - 2024",
    "text": "3.1 Overall Exports and Imports of Services, 2020 - 2024\n\n\n\n\n\n\n3.1.1 Critique - Quadrant IV: Confusing yet Beautiful\n✅ The y-axis starts at 0, which makes it easier to gauge and assess the data’s scale.\n✅ Subtle gridlines were used, which is less distracting for the viewer.\n❌ Using dollar bill icons to represent data in the bar chart adds visual confusion as we may interpret each icon representing a specific value.\n❌ Alternating exports and imports makes it difficult to visually track the growth trends of each category independently, thus disrupting the understanding of CAGR for exports and imports as there is no continuous visual path that readers can follow easily.\n❌ The CAGR figures are positioned away from the main chart and are represented in a separate element at the bottom, which may cause viewers to overlook these figures or fail to connect them with the corresponding data in the chart.\n❌ The visualisation contains too much information such as yearly totals, individual exports and imports and trade balance. This might overwhelm the viewer, especially when trying to extract specific insights quickly.\n❌ The visualisation lacks a lead-in paragraph that could set the context, making it difficult to immediately understand the message the visualisation.\n\n\n3.1.2 Proposed Data Visualisation Makeover\nThe image below presents a general mock-up of the proposed data visualization makeover, accompanied by an explanation of the thought process behind the suggested changes.\n\n\n\n3.1.3 Revised Data Visualisation\n\nAdditional Data Preparation for the Visualisation\nSince we are only looking at the overall export and import of services from 2020 to 2024, we will filter the filtered_servicetrade from Section 2.2.3 to only contain these information: Date, Exports of Services and Imports Of Services.\nThere is achieved via using the select function as shown in the code chunk below:\n\nfiltered_servicetrade1 &lt;- filtered_servicetrade %&gt;%\n  select(Date, `Exports Of Services`, `Imports Of Services`)\n\nSince we are looking at the total merchandise trade by year, we will extract the year from the following code chunk, and filter for the period 2020 - 2024:\n\nfiltered_servicetrade1$Year &lt;- format(filtered_servicetrade1$Date, \"%Y\")\n\nfiltered_servicetrade1 &lt;- filtered_servicetrade1[filtered_servicetrade1$Year %in% c(\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"), ]\n\nWe will also convert Exports of Services and Imports Of Services. into numeric format via the following code chunk:\n\nfiltered_servicetrade1$`Exports Of Services` &lt;- as.numeric(gsub(\",\", \"\", filtered_servicetrade1$`Exports Of Services`))\nfiltered_servicetrade1$`Imports Of Services` &lt;- as.numeric(gsub(\",\", \"\", filtered_servicetrade1$`Imports Of Services`))\n\nWe will also create two new variables that measures the growth in service exports and imports year-on-year. This is done by summing up the exports and imports by year, and computing the % difference.\n\nannual_servicetrade &lt;- filtered_servicetrade1 %&gt;%\n  group_by(Date) %&gt;%\n  summarise(\n    `Total Exports of Services` = sum(`Exports Of Services`, na.rm = TRUE),\n    `Total Imports of Services` = sum(`Imports Of Services`, na.rm = TRUE)\n  ) %&gt;%\n  arrange(Date) %&gt;% \n  mutate(\n    `Exports Growth Rate` = ((`Total Exports of Services` / lag(`Total Exports of Services`)) - 1) * 100,\n    `Imports Growth Rate` = ((`Total Imports of Services` / lag(`Total Imports of Services`)) - 1) * 100\n  )\n\n# Replace NA growth rates (first year) with 0\nannual_servicetrade$`Exports Growth Rate`[is.na(annual_servicetrade$`Exports Growth Rate`)] &lt;- 0\nannual_servicetrade$`Imports Growth Rate`[is.na(annual_servicetrade$`Imports Growth Rate`)] &lt;- 0\n\nWe will also convert all numeric values into billions so that it’s easier for readers to interpret numeric values.\n\nannual_servicetrade &lt;- annual_servicetrade %&gt;%   mutate(\n  `Total Exports of Services` = `Total Exports of Services` / 1e3,\n  `Total Imports of Services` = `Total Imports of Services` / 1e3\n)\n\nannual_servicetrade &lt;- annual_servicetrade %&gt;%\n  mutate(Year = as.integer(format(Date, \"%Y\")))\n\nWe would also need to compute the CAGR for exports and imports of services from 2020 to 2024:\n\n# Compute CAGR for Exports and Imports\nstart_year &lt;- min(annual_servicetrade$Year, na.rm = TRUE)\nend_year &lt;- max(annual_servicetrade$Year, na.rm = TRUE)\n\nstart_exports &lt;- annual_servicetrade$`Total Exports of Services`[annual_servicetrade$Year == start_year]\nend_exports &lt;- annual_servicetrade$`Total Exports of Services`[annual_servicetrade$Year == end_year]\nCAGR_exports &lt;- ((end_exports / start_exports)^(1 / (end_year - start_year)) - 1) * 100\n\nstart_imports &lt;- annual_servicetrade$`Total Imports of Services`[annual_servicetrade$Year == start_year]\nend_imports &lt;- annual_servicetrade$`Total Imports of Services`[annual_servicetrade$Year == end_year]\nCAGR_imports &lt;- ((end_imports / start_imports)^(1 / (end_year - start_year)) - 1) * 100\n\nCAGR_text &lt;- paste0(\n  \"Exports CAGR (\", start_year, \"-\", end_year, \"): \", sprintf(\"%.1f\", CAGR_exports), \"%\\n\",\n  \"Imports CAGR (\", start_year, \"-\", end_year, \"): \", sprintf(\"%.1f\", CAGR_imports), \"%\"\n)\n\n\n\nData Visualisation\nAfter all the data preparation has been completed, the following code chunk plots the revised data visualisation.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny_max &lt;- max(annual_servicetrade$`Total Exports of Services`, \n             annual_servicetrade$`Total Imports of Services`, na.rm = TRUE)\n\nplot1 &lt;- ggplot(annual_servicetrade, aes(x = Year, y = `Total Exports of Services`)) +\n  geom_bar(stat = \"identity\", fill = \"mediumseagreen\") +\n  geom_text(aes(label = paste0(\"S$\", formatC(`Total Exports of Services`, format = \"f\", big.mark = \",\", digits = 1), \"B\")), \n            vjust = -0.5, color = \"black\", size = 4) +\n  labs(title = \"Overall Exports of Services, 2020-2024\", x = \"Year\", y = \"S$ Billion\") +\n  ylim(0, y_max * 1.1) +  \n  theme_minimal()\n\n\nplot2 &lt;- ggplot(annual_servicetrade, aes(x = Year, y = `Total Imports of Services`)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(aes(label = paste0(\"S$\", formatC(`Total Imports of Services`, format = \"f\", big.mark = \",\", digits = 1), \"B\")), \n            vjust = -0.5, color = \"black\", size = 4) +\n  labs(title = \"Overall Imports of Services, 2020-2024\", x = \"Year\", y = \"S$ Billion\") +\n  ylim(0, y_max * 1.1) +  \n  theme_minimal()\n\n\nplot3 &lt;- ggplot(annual_servicetrade, aes(x = Year)) +\n  geom_line(aes(y = `Exports Growth Rate`, color = \"Exports Growth Rate\"), size = 1) +\n  geom_point(aes(y = `Exports Growth Rate`, color = \"Exports Growth Rate\"), size = 2) +\n  geom_line(aes(y = `Imports Growth Rate`, color = \"Imports Growth Rate\"), size = 1) +\n  geom_point(aes(y = `Imports Growth Rate`, color = \"Imports Growth Rate\"), size = 2) +\n  \n  scale_x_continuous(breaks = seq(2020, 2025, 1), limits = c(2020, 2025)) +\n  scale_color_manual(values = c(\"Exports Growth Rate\" = \"mediumseagreen\", \"Imports Growth Rate\" = \"steelblue\")) +\n\n  \n  annotate(\"text\", x = 2022.5, y = min(annual_servicetrade$`Exports Growth Rate`, na.rm = TRUE), \n           label = CAGR_text, size = 4, hjust = -1.2, fontface = \"bold\", \n           color = \"black\", vjust = -1.6, bg = \"white\", alpha = 0.8) +\n\n  labs(title = \"Overall Growth Rate in Exports and Imports of Services\", x = \"Year\", y = \"Growth Rate (%)\", color = \"Legend\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\nfinal_plot &lt;- ((plot1 | plot2) / plot3) + \n  plot_layout(widths = c(1, 1, 0.8)) +\n  plot_annotation(\n    title = \"Growth in exports of services surpassed imports in 2024 for the first time in three years, \\nwith a Compound Annual Growth Rate (CAGR) of 15.2% vs. 12.8% for imports.\",\n    theme = theme(plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5))\n  )\n\nfinal_plot"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#total-merchandise-trade-at-current-prices-2020---2024-1",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#total-merchandise-trade-at-current-prices-2020---2024-1",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "3.2 Total Merchandise Trade At Current Prices, 2020 - 2024",
    "text": "3.2 Total Merchandise Trade At Current Prices, 2020 - 2024\n\n\n\n\n\n\n3.2.1 Critique - Quadrant IV: Confusing yet Beautiful\n✅ Elements are well-aligned and spaced effectively.\n✅ Bars are represented as a single shipping container instead of disjointed units like the dollar bills in Section 3.1, making it easier to interpret values.\n❌ The visualisation aims to present the total merchandise trade, yet it splits the data into separate bars for exports and imports. This division makes it misleading as readers may focus on the differences between exports and imports rather than on the aggregate trade figures. It also makes it harder to quickly assess the overall trade performance year-on-year.\n❌ Tick marks were omitted from the x-axis despite the value of merchandise trade being a continuous variable. This makes it difficult to interpret the scale of the data and estimate values.\n❌ The years are not labeled directly on the y-axis or associated clearly with the corresponding data bars (which are in various hues of colour, adding more visual confusion). Instead, they are indicated in separate text boxes that state the total merchandise trade for each year. The disjointed presentation can confuse readers as it requires them to match the data visually across different parts of the chart.\n❌ The % increase in merchandise trade in 2024 is placed separately at the bottom of the chart, detached from the visual data representation. Furthermore, the total trade values for each year are in separate text boxes and does not visually represent the percentage growth. Readers would not be able to intuitively interpret the growth rate without doing mental calculations.\n\n\n3.2.2 Proposed Data Visualisation Makeover\nThe image below presents a general mock-up of the proposed data visualization makeover, accompanied by an explanation of the thought process behind the suggested changes.\n\n\n\n3.2.3 Revised Data Visualisation\n\nAdditional Data Preparation for the Visualisation\nSince we are only looking at Total Merchandise Trade, (At Current Prices), we will filter out the Date and Total Merchandise Trade, (At Current Prices) from filtered_merchandise trade. This is achieved via the following code chunk:\n\nfiltered_totalmerchandisetrade &lt;- filtered_merchandisetrade %&gt;%\n  select(Date, `Total Merchandise Trade, (At Current Prices)`, `Total Merchandise Exports, (At Current Prices)`, `Total Merchandise Imports, (At Current Prices)`)\n\nWe will also convert Total Merchandise Trade, (At Current Prices) into numeric format and ensure that the Date column is in date format via the following code chunk:\n\nfiltered_totalmerchandisetrade$`Total Merchandise Trade, (At Current Prices)` &lt;- as.numeric(gsub(\",\", \"\", filtered_totalmerchandisetrade$`Total Merchandise Trade, (At Current Prices)`))\nfiltered_totalmerchandisetrade$`Total Merchandise Exports, (At Current Prices)` &lt;- as.numeric(gsub(\",\", \"\", filtered_totalmerchandisetrade$`Total Merchandise Exports, (At Current Prices)`))\nfiltered_totalmerchandisetrade$`Total Merchandise Imports, (At Current Prices)` &lt;- as.numeric(gsub(\",\", \"\", filtered_totalmerchandisetrade$`Total Merchandise Imports, (At Current Prices)`))\n\nfiltered_totalmerchandisetrade$Date &lt;- as.Date(filtered_totalmerchandisetrade$Date)\n\nSince we are looking at the total merchandise trade by year, we will extract the year from the following code chunk, and filter for the period 2020 - 2024:\n\nfiltered_totalmerchandisetrade$Year &lt;- format(filtered_totalmerchandisetrade$Date, \"%Y\")\n\nfiltered_totalmerchandisetrade &lt;- filtered_totalmerchandisetrade[filtered_totalmerchandisetrade$Year %in% c(\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"), ]\n\nWe will also create a new variable called “Growth Rate” that measures the growth in total merchandise trade year-on-year. This is done by summing up the total merchandise trade by year, and computing the % difference.\n\nannual_merchandisetrade &lt;- filtered_totalmerchandisetrade %&gt;%\n  mutate(Year = format(Date, \"%Y\")) %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    `Total Merchandise Trade` = sum(`Total Merchandise Trade, (At Current Prices)`, na.rm = TRUE),\n    `Total Merchandise Imports` = sum(`Total Merchandise Imports, (At Current Prices)`, na.rm = TRUE),\n    `Total Merchandise Exports` = sum(`Total Merchandise Exports, (At Current Prices)`, na.rm = TRUE)\n  )\n\nannual_merchandisetrade &lt;- annual_merchandisetrade %&gt;%\n  mutate(\n    `Trade Growth Rate` = ( (`Total Merchandise Trade` / lag(`Total Merchandise Trade`) - 1) * 100 ),\n    `Imports Growth Rate` = ( (`Total Merchandise Imports` / lag(`Total Merchandise Imports`) - 1) * 100 ),\n    `Exports Growth Rate` = ( (`Total Merchandise Exports` / lag(`Total Merchandise Exports`) - 1) * 100 )\n  )\n\nannual_merchandisetrade[is.na(annual_merchandisetrade)] &lt;- 0\n\nWe will also convert all the values into billions so that it’s easier for readers to interpret numeric values.\n\nannual_merchandisetrade &lt;- annual_merchandisetrade %&gt;%\n  mutate(\n    `Total Merchandise Trade` = `Total Merchandise Trade` / 1e6,\n    `Total Merchandise Imports` = `Total Merchandise Imports` / 1e6,\n    `Total Merchandise Exports` = `Total Merchandise Exports` / 1e6\n  )\n\n\n\nData Visualisation\nAfter all the data preparation has been completed, the following code chunk plots the revised data visualisation.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax_trade &lt;- max(annual_merchandisetrade$`Total Merchandise Trade`, na.rm = TRUE)\nmax_growth &lt;- max(abs(annual_merchandisetrade$`Trade Growth Rate`), na.rm = TRUE) #\n\nggplot(annual_merchandisetrade, aes(x = Year)) +\n  \n  geom_bar(aes(y = `Total Merchandise Trade`, fill = \"Total Merchandise Trade\"), \n           stat = \"identity\") +\n  \n  geom_text(aes(y = `Total Merchandise Trade`, \n                label = paste0(\"S$\", formatC(`Total Merchandise Trade`, format = \"f\", big.mark = \",\", digits = 1), \"B\")), \n            vjust = -0.5, color = \"black\", size = 4.5) +\n  \n  geom_line(aes(y = `Trade Growth Rate` * max_trade / 40, color = \"Trade Growth Rate\"), \n            size = 1, group = 1) +\n  geom_point(aes(y = `Trade Growth Rate` * max_trade / 40, color = \"Trade Growth Rate\"), \n             size = 2) +\n  \n  geom_text(aes(y = `Trade Growth Rate` * max_trade / 40, \n                label = sprintf(\"%.1f%%\", `Trade Growth Rate`)), \n            vjust = -2, color = \"black\", size = 4.5) +\n\n  scale_y_continuous(\n    name = \"Total Merchandise Trade (S$ Billion)\",\n    labels = function(x) paste0(\"S$\", formatC(x, format = \"f\", big.mark = \",\", digits = 0), \"B\"),\n    sec.axis = sec_axis(~ . * 40 / max_trade,\n                        name = \"Merchandise Trade Annual Growth Rate (%)\", \n                        breaks = seq(-40, 40, 10),  \n                        labels = function(x) paste0(x, \"%\")) \n  ) +\n\n  labs(title = \"Total merchandise trade rebounded and grew by 6.6% in 2024, \\n reversing the contraction in 2023. However, this growth rate \\n did not reach the levels seen before 2023.\", \n       x = \"Year\",\n       fill = \"Legend\", \n       color = \"Legend\") + \n       \n  scale_fill_manual(values = c(\"Total Merchandise Trade\" = \"gold\")) +\n  scale_color_manual(values = c(\"Trade Growth Rate\" = \"black\")) +\n\n  theme_minimal() +\n  \ntheme(\n  plot.title = element_text(hjust = 0.5, size=20), \n  axis.title.y.left = element_text(margin = margin(r = 10)),  \n  axis.title.y.right = element_text(margin = margin(l = 10)),\n  legend.position = \"top\",\n  legend.title = element_blank()\n)"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html",
    "href": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html",
    "title": "In-class Exercise 5.0",
    "section": "",
    "text": "The code chunk below installs the required R Packages for this exercise:\n\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\n\n\n\nts_data &lt;- read_csv(\n  \"data/visitor_arrivals_by_air.csv\")\n\nIn the code chunk below, dmy() of lubridate package is used to convert data type of Month-Year field from Character to Date.\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\nThe original data file uses ‘/’ in the dates. However, upon seeing ‘/’, R will automatically convert it to a chr field.\nWe now want to convert a typical dataframe into a time-series tsibble function:\n\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\nIn R, it would be indicated as a “Time-Series” data frame:\n\nThe code chunk below converting ts_data from tibble object into tsibble object by using as_tsibble() of tsibble R package.\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html#importing-the-dataset",
    "href": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html#importing-the-dataset",
    "title": "In-class Exercise 5.0",
    "section": "",
    "text": "ts_data &lt;- read_csv(\n  \"data/visitor_arrivals_by_air.csv\")\n\nIn the code chunk below, dmy() of lubridate package is used to convert data type of Month-Year field from Character to Date.\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\nThe original data file uses ‘/’ in the dates. However, upon seeing ‘/’, R will automatically convert it to a chr field.\nWe now want to convert a typical dataframe into a time-series tsibble function:\n\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\nIn R, it would be indicated as a “Time-Series” data frame:\n\nThe code chunk below converting ts_data from tibble object into tsibble object by using as_tsibble() of tsibble R package.\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html#visualising-single-time-series",
    "href": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html#visualising-single-time-series",
    "title": "In-class Exercise 5.0",
    "section": "2.1 Visualising Single Time-Series",
    "text": "2.1 Visualising Single Time-Series\n\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(size = 0.5)\n\n\n\n\n\n\n\n\nCreating a trellis plot to plot the time-series for the respective countries:\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals))+\n  geom_line(size = 0.5) +\n  facet_wrap(~ Country, # Facet_wrap allows me to wrap for each line so I don't need to define the number of rows.\n             ncol = 3, # You can define the ncols and nrows.\n             scales = \"free_y\") +\n  theme_bw()"
  },
  {
    "objectID": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html#visualising-seasonality-with-cycle-plot",
    "href": "In-Class Exercise/In-Class_Ex07/In-Class_Ex07.html#visualising-seasonality-with-cycle-plot",
    "title": "In-class Exercise 5.0",
    "section": "2.2 Visualising Seasonality with Cycle Plot",
    "text": "2.2 Visualising Seasonality with Cycle Plot\n\ntsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  autoplot(Arrivals) + \n  facet_grid(Country ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals) # Built-in function gg_subseries that allows you to create a cycle plot."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#merchandise-trade-by-region-and-selected-market-domestic-exports",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#merchandise-trade-by-region-and-selected-market-domestic-exports",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "2.4 Merchandise Trade By Region And Selected Market (Domestic Exports)",
    "text": "2.4 Merchandise Trade By Region And Selected Market (Domestic Exports)\n\n2.4.1 Data Import\nFor the purpose of the time-series analysis and forecasting (Section 4.0), we will be looking at the Merchandise Trade By Region and Selected Market (Domestic Exports ) dataset, which can be found here. The follow code chunk uses the read_csv() function to import the domesticexports.csv file into R.\n\ndomesticexports &lt;- read_csv(\"data/domesticexports.csv\")\n\n\n\n2.4.2 Understanding the Data\nAfter loading the data was loaded, the glimpse() function was then used to understand its structure and the type of data it contains.\n\nglimpse(domesticexports)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 191\nColumns: 266\n$ ...1   &lt;chr&gt; \"Theme: Trade & Investment\", \"Subject: Merchandise Trade\", \"Top…\n$ ...2   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2025 Jan\", \"24672\", \"4263.…\n$ ...3   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Dec\", \"23684.7\", \"360…\n$ ...4   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Nov\", \"23438.7\", \"312…\n$ ...5   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Oct\", \"22147.8\", \"293…\n$ ...6   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Sep\", \"21966.7\", \"329…\n$ ...7   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Aug\", \"23984\", \"3447.…\n$ ...8   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Jul\", \"26421.3\", \"509…\n$ ...9   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Jun\", \"22945.7\", \"329…\n$ ...10  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 May\", \"25555.3\", \"372…\n$ ...11  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Apr\", \"24062.9\", \"349…\n$ ...12  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Mar\", \"24093.9\", \"338…\n$ ...13  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Feb\", \"23159.9\", \"392…\n$ ...14  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2024 Jan\", \"25136.8\", \"380…\n$ ...15  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Dec\", \"22546\", \"3425\"…\n$ ...16  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Nov\", \"24833.9\", \"400…\n$ ...17  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Oct\", \"26297.7\", \"346…\n$ ...18  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Sep\", \"23093.3\", \"374…\n$ ...19  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Aug\", \"23134.7\", \"350…\n$ ...20  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Jul\", \"22445.5\", \"437…\n$ ...21  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Jun\", \"23470\", \"3742.…\n$ ...22  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 May\", \"23026.6\", \"345…\n$ ...23  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Apr\", \"24015\", \"4700.…\n$ ...24  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Mar\", \"27554.9\", \"558…\n$ ...25  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Feb\", \"22273.8\", \"323…\n$ ...26  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2023 Jan\", \"22361.4\", \"319…\n$ ...27  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Dec\", \"24423.6\", \"339…\n$ ...28  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Nov\", \"24976.4\", \"357…\n$ ...29  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Oct\", \"25546\", \"3879.…\n$ ...30  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Sep\", \"27479.1\", \"390…\n$ ...31  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Aug\", \"30220.5\", \"459…\n$ ...32  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Jul\", \"30998.1\", \"369…\n$ ...33  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Jun\", \"30072.1\", \"446…\n$ ...34  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 May\", \"29142.3\", \"354…\n$ ...35  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Apr\", \"28376.1\", \"397…\n$ ...36  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Mar\", \"29495.6\", \"496…\n$ ...37  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Feb\", \"24202.3\", \"307…\n$ ...38  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2022 Jan\", \"24736.8\", \"385…\n$ ...39  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Dec\", \"26075.1\", \"332…\n$ ...40  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Nov\", \"26480.9\", \"357…\n$ ...41  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Oct\", \"23992.9\", \"310…\n$ ...42  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Sep\", \"22928.6\", \"330…\n$ ...43  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Aug\", \"23119.3\", \"302…\n$ ...44  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Jul\", \"23284.6\", \"294…\n$ ...45  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Jun\", \"23737.8\", \"325…\n$ ...46  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 May\", \"21616.3\", \"336…\n$ ...47  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Apr\", \"22801.9\", \"324…\n$ ...48  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Mar\", \"25218.4\", \"370…\n$ ...49  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Feb\", \"19517.4\", \"289…\n$ ...50  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2021 Jan\", \"20202.2\", \"275…\n$ ...51  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Dec\", \"20137.9\", \"355…\n$ ...52  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Nov\", \"18017.3\", \"302…\n$ ...53  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Oct\", \"18651.6\", \"278…\n$ ...54  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Sep\", \"18815.7\", \"252…\n$ ...55  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Aug\", \"20063.2\", \"289…\n$ ...56  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Jul\", \"19502.9\", \"451…\n$ ...57  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Jun\", \"18021.1\", \"294…\n$ ...58  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 May\", \"16915.5\", \"406…\n$ ...59  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Apr\", \"19246.4\", \"460…\n$ ...60  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Mar\", \"22373.5\", \"368…\n$ ...61  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Feb\", \"21069.5\", \"333…\n$ ...62  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2020 Jan\", \"21635\", \"3453.…\n$ ...63  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Dec\", \"20385\", \"2315.…\n$ ...64  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Nov\", \"21027.8\", \"270…\n$ ...65  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Oct\", \"21927.3\", \"258…\n$ ...66  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Sep\", \"19546\", \"2651.…\n$ ...67  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Aug\", \"20850.4\", \"270…\n$ ...68  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Jul\", \"21144.2\", \"307…\n$ ...69  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Jun\", \"19933\", \"2979.…\n$ ...70  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 May\", \"23259.1\", \"362…\n$ ...71  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Apr\", \"21486.6\", \"273…\n$ ...72  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Mar\", \"20723.8\", \"307…\n$ ...73  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Feb\", \"19909.7\", \"301…\n$ ...74  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2019 Jan\", \"21400.7\", \"277…\n$ ...75  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Dec\", \"21093.1\", \"261…\n$ ...76  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Nov\", \"24480.7\", \"295…\n$ ...77  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Oct\", \"26021.8\", \"322…\n$ ...78  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Sep\", \"22549.9\", \"315…\n$ ...79  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Aug\", \"24732\", \"3334\"…\n$ ...80  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Jul\", \"23569.5\", \"324…\n$ ...81  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Jun\", \"23385.7\", \"306…\n$ ...82  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 May\", \"25908\", \"3641.…\n$ ...83  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Apr\", \"23078.8\", \"311…\n$ ...84  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Mar\", \"22997.9\", \"316…\n$ ...85  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Feb\", \"20113.2\", \"251…\n$ ...86  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2018 Jan\", \"23207.3\", \"269…\n$ ...87  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Dec\", \"23287.9\", \"229…\n$ ...88  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Nov\", \"23434.9\", \"226…\n$ ...89  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Oct\", \"22545.5\", \"244…\n$ ...90  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Sep\", \"20428.5\", \"225…\n$ ...91  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Aug\", \"21594.6\", \"244…\n$ ...92  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Jul\", \"19856.1\", \"214…\n$ ...93  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Jun\", \"21088.2\", \"239…\n$ ...94  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 May\", \"22282.2\", \"264…\n$ ...95  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Apr\", \"20736.5\", \"248…\n$ ...96  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Mar\", \"23098.2\", \"281…\n$ ...97  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Feb\", \"20545\", \"2063.…\n$ ...98  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2017 Jan\", \"20404.3\", \"223…\n$ ...99  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Dec\", \"21516.2\", \"199…\n$ ...100 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Nov\", \"20283\", \"2206.…\n$ ...101 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Oct\", \"18278.5\", \"190…\n$ ...102 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Sep\", \"19014.9\", \"239…\n$ ...103 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Aug\", \"18194.4\", \"234…\n$ ...104 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Jul\", \"18547.8\", \"258…\n$ ...105 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Jun\", \"19591.8\", \"276…\n$ ...106 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 May\", \"20068.4\", \"253…\n$ ...107 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Apr\", \"18822\", \"2355\"…\n$ ...108 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Mar\", \"17947.9\", \"230…\n$ ...109 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Feb\", \"15024.3\", \"191…\n$ ...110 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2016 Jan\", \"16643.9\", \"193…\n$ ...111 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Dec\", \"18332.7\", \"202…\n$ ...112 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Nov\", \"17321\", \"2163.…\n$ ...113 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Oct\", \"20189.5\", \"271…\n$ ...114 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Sep\", \"19701.7\", \"247…\n$ ...115 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Aug\", \"18999.3\", \"263…\n$ ...116 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Jul\", \"21909.5\", \"267…\n$ ...117 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Jun\", \"21109.2\", \"282…\n$ ...118 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 May\", \"19637.1\", \"253…\n$ ...119 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Apr\", \"20829.5\", \"280…\n$ ...120 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Mar\", \"23159.6\", \"303…\n$ ...121 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Feb\", \"16622.1\", \"198…\n$ ...122 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2015 Jan\", \"19921.7\", \"242…\n$ ...123 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Dec\", \"20793.6\", \"244…\n$ ...124 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Nov\", \"20041.9\", \"256…\n$ ...125 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Oct\", \"22476.2\", \"253…\n$ ...126 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Sep\", \"22797.5\", \"296…\n$ ...127 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Aug\", \"23707\", \"3132.…\n$ ...128 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Jul\", \"23475.4\", \"298…\n$ ...129 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Jun\", \"22555.3\", \"310…\n$ ...130 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 May\", \"22942.4\", \"270…\n$ ...131 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Apr\", \"23976.2\", \"316…\n$ ...132 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Mar\", \"22279.1\", \"272…\n$ ...133 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Feb\", \"22219.8\", \"282…\n$ ...134 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2014 Jan\", \"22513.7\", \"283…\n$ ...135 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Dec\", \"22119.6\", \"279…\n$ ...136 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Nov\", \"21501.6\", \"271…\n$ ...137 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Oct\", \"24112.2\", \"303…\n$ ...138 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Sep\", \"23868.5\", \"314…\n$ ...139 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Aug\", \"22578.8\", \"314…\n$ ...140 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Jul\", \"24041.1\", \"313…\n$ ...141 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Jun\", \"22544.3\", \"317…\n$ ...142 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 May\", \"22157.5\", \"302…\n$ ...143 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Apr\", \"22973.9\", \"325…\n$ ...144 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Mar\", \"22806.5\", \"321…\n$ ...145 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Feb\", \"20123.7\", \"256…\n$ ...146 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2013 Jan\", \"22389\", \"3052.…\n$ ...147 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Dec\", \"21102.4\", \"234…\n$ ...148 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Nov\", \"22994.7\", \"298…\n$ ...149 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Oct\", \"24825.7\", \"359…\n$ ...150 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Sep\", \"22273.7\", \"295…\n$ ...151 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Aug\", \"23230.6\", \"322…\n$ ...152 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Jul\", \"23067.8\", \"303…\n$ ...153 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Jun\", \"24121.7\", \"314…\n$ ...154 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 May\", \"25067.4\", \"318…\n$ ...155 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Apr\", \"24135.8\", \"338…\n$ ...156 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Mar\", \"25063.4\", \"322…\n$ ...157 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Feb\", \"26337\", \"3934.…\n$ ...158 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2012 Jan\", \"22948.8\", \"372…\n$ ...159 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Dec\", \"24644.1\", \"368…\n$ ...160 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Nov\", \"23382.7\", \"298…\n$ ...161 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Oct\", \"22829\", \"3143.…\n$ ...162 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Sep\", \"24403.9\", \"311…\n$ ...163 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Aug\", \"26302.9\", \"347…\n$ ...164 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Jul\", \"23385\", \"3397.…\n$ ...165 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Jun\", \"23554.3\", \"358…\n$ ...166 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 May\", \"22893.8\", \"301…\n$ ...167 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Apr\", \"23029.6\", \"353…\n$ ...168 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Mar\", \"24934.1\", \"446…\n$ ...169 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Feb\", \"19710.8\", \"290…\n$ ...170 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2011 Jan\", \"22659\", \"3072.…\n$ ...171 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Dec\", \"21397.5\", \"274…\n$ ...172 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Nov\", \"20754.3\", \"274…\n$ ...173 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Oct\", \"22881.8\", \"382…\n$ ...174 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Sep\", \"21820.7\", \"359…\n$ ...175 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Aug\", \"22392.6\", \"326…\n$ ...176 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Jul\", \"20570.6\", \"277…\n$ ...177 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Jun\", \"21016.7\", \"303…\n$ ...178 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 May\", \"20174.3\", \"266…\n$ ...179 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Apr\", \"21633.5\", \"389…\n$ ...180 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Mar\", \"20832.7\", \"263…\n$ ...181 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Feb\", \"17671.1\", \"254…\n$ ...182 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2010 Jan\", \"17889.8\", \"263…\n$ ...183 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Dec\", \"19404.7\", \"272…\n$ ...184 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Nov\", \"18866.9\", \"315…\n$ ...185 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Oct\", \"17864.5\", \"274…\n$ ...186 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Sep\", \"18615.7\", \"290…\n$ ...187 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Aug\", \"17459.2\", \"292…\n$ ...188 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Jul\", \"18233.2\", \"286…\n$ ...189 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Jun\", \"16391.2\", \"315…\n$ ...190 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 May\", \"15149.1\", \"218…\n$ ...191 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Apr\", \"15538.8\", \"280…\n$ ...192 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Mar\", \"15748.8\", \"237…\n$ ...193 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Feb\", \"13393.6\", \"221…\n$ ...194 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2009 Jan\", \"13544\", \"2094.…\n$ ...195 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Dec\", \"14339.9\", \"229…\n$ ...196 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Nov\", \"17554.7\", \"351…\n$ ...197 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Oct\", \"20099.6\", \"303…\n$ ...198 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Sep\", \"22702.3\", \"345…\n$ ...199 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Aug\", \"22719.7\", \"331…\n$ ...200 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Jul\", \"23970.8\", \"306…\n$ ...201 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Jun\", \"21655.1\", \"319…\n$ ...202 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 May\", \"20358.7\", \"287…\n$ ...203 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Apr\", \"22332.4\", \"319…\n$ ...204 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Mar\", \"21135.5\", \"381…\n$ ...205 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Feb\", \"18976.4\", \"302…\n$ ...206 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2008 Jan\", \"21881.5\", \"368…\n$ ...207 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Dec\", \"19544.7\", \"308…\n$ ...208 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Nov\", \"20384.7\", \"344…\n$ ...209 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Oct\", \"21609.9\", \"359…\n$ ...210 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Sep\", \"20435.3\", \"339…\n$ ...211 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Aug\", \"19902.7\", \"350…\n$ ...212 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Jul\", \"20233.2\", \"339…\n$ ...213 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Jun\", \"19725.2\", \"327…\n$ ...214 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 May\", \"19348.1\", \"314…\n$ ...215 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Apr\", \"18783.4\", \"326…\n$ ...216 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Mar\", \"19971.9\", \"337…\n$ ...217 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Feb\", \"15446.6\", \"279…\n$ ...218 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2007 Jan\", \"19562\", \"3324.…\n$ ...219 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Dec\", \"17564.9\", \"243…\n$ ...220 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Nov\", \"19359.8\", \"291…\n$ ...221 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Oct\", \"18964\", \"3145.…\n$ ...222 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Sep\", \"19500.2\", \"322…\n$ ...223 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Aug\", \"19302.6\", \"315…\n$ ...224 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Jul\", \"19041.4\", \"330…\n$ ...225 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Jun\", \"20398.8\", \"302…\n$ ...226 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 May\", \"19481.9\", \"290…\n$ ...227 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Apr\", \"17989.8\", \"312…\n$ ...228 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Mar\", \"20235.3\", \"344…\n$ ...229 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Feb\", \"17720.4\", \"276…\n$ ...230 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2006 Jan\", \"17830.7\", \"247…\n$ ...231 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Dec\", \"20549.8\", \"294…\n$ ...232 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Nov\", \"18738.1\", \"285…\n$ ...233 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Oct\", \"19489.1\", \"274…\n$ ...234 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Sep\", \"18509.5\", \"266…\n$ ...235 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Aug\", \"18645\", \"2574.…\n$ ...236 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Jul\", \"16940.7\", \"252…\n$ ...237 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Jun\", \"16897.4\", \"237…\n$ ...238 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 May\", \"16272.7\", \"220…\n$ ...239 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Apr\", \"15873\", \"2256.…\n$ ...240 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Mar\", \"16702.9\", \"255…\n$ ...241 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Feb\", \"14155.7\", \"240…\n$ ...242 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2005 Jan\", \"14701.6\", \"237…\n$ ...243 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Dec\", \"16119.8\", \"241…\n$ ...244 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Nov\", \"15694.3\", \"245…\n$ ...245 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Oct\", \"16453.4\", \"260…\n$ ...246 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Sep\", \"16484.8\", \"271…\n$ ...247 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Aug\", \"15612.6\", \"272…\n$ ...248 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Jul\", \"15452.7\", \"276…\n$ ...249 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Jun\", \"15205.3\", \"258…\n$ ...250 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 May\", \"14527.2\", \"265…\n$ ...251 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Apr\", \"14202.5\", \"235…\n$ ...252 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Mar\", \"14810\", \"2560.…\n$ ...253 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Feb\", \"12917.7\", \"201…\n$ ...254 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2004 Jan\", \"12730.7\", \"212…\n$ ...255 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Dec\", \"13759.3\", \"238…\n$ ...256 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Nov\", \"12504.9\", \"220…\n$ ...257 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Oct\", \"13733.4\", \"255…\n$ ...258 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Sep\", \"13541.1\", \"233…\n$ ...259 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Aug\", \"11785.1\", \"206…\n$ ...260 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Jul\", \"12646.8\", \"223…\n$ ...261 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Jun\", \"12169.3\", \"242…\n$ ...262 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 May\", \"11905.6\", \"237…\n$ ...263 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Apr\", \"12258.4\", \"234…\n$ ...264 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Mar\", \"12707.3\", \"238…\n$ ...265 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"2003 Feb\", \"10658\", \"2081.…\n$ ...266 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, \"Million Dollars\", \"2003 Jan\", …\n\n\n\n\n\nThe output of the glimpse() function indicates that there are 191 rows and 266 columns. The first few rows appear to serve as a document header, with entries such as “Theme: Trade & Investment” and “Subject: Merchandise Trade”, followed by numerous NA cells. The actual trade data likely begins in subsequent rows, with each column representing a specific month and year, and each row representing various trade-related variables.\n\n\n2.4.3 Data Wrangling\nRemoving Non-Relevant Rows\nGiven the structure of our dataset, particularly the presence of non-data rows at the beginning with a large number of NA values, we will use na.omit() to remove rows containing NA values.\n\ncleaned_domesticexports &lt;- na.omit(domesticexports)\n\nAfter removing the rows containing the NA entries, we used the glimpse() function once again to review the structure of the cleaned dataset.\n\nglimpse(cleaned_domesticexports)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 161\nColumns: 266\n$ ...1   &lt;chr&gt; \"Data Series\", \"Total All Markets\", \"America\", \"Antigua And Bar…\n$ ...2   &lt;chr&gt; \"2025 Jan\", \"24672\", \"4263.1\", \"8.8\", \"5.3\", \"51.4\", \"2.7\", \"40…\n$ ...3   &lt;chr&gt; \"2024 Dec\", \"23684.7\", \"3607.9\", \"7.1\", \"6\", \"48.1\", \"7.7\", \"32…\n$ ...4   &lt;chr&gt; \"2024 Nov\", \"23438.7\", \"3128.7\", \"8.3\", \"3.9\", \"60.5\", \"0.5\", \"…\n$ ...5   &lt;chr&gt; \"2024 Oct\", \"22147.8\", \"2935.5\", \"7.7\", \"6.4\", \"36.1\", \"5.4\", \"…\n$ ...6   &lt;chr&gt; \"2024 Sep\", \"21966.7\", \"3294.2\", \"8.2\", \"3\", \"59.3\", \"0.7\", \"30…\n$ ...7   &lt;chr&gt; \"2024 Aug\", \"23984\", \"3447.8\", \"9.3\", \"4.3\", \"77.3\", \"5.5\", \"49…\n$ ...8   &lt;chr&gt; \"2024 Jul\", \"26421.3\", \"5094.3\", \"10\", \"3.6\", \"80.1\", \"2.9\", \"5…\n$ ...9   &lt;chr&gt; \"2024 Jun\", \"22945.7\", \"3298.2\", \"8.4\", \"3.9\", \"79.8\", \"2.5\", \"…\n$ ...10  &lt;chr&gt; \"2024 May\", \"25555.3\", \"3722.3\", \"15.4\", \"4.8\", \"71.4\", \"1.4\", …\n$ ...11  &lt;chr&gt; \"2024 Apr\", \"24062.9\", \"3494.1\", \"18.3\", \"3.8\", \"78.1\", \"10.8\",…\n$ ...12  &lt;chr&gt; \"2024 Mar\", \"24093.9\", \"3381.5\", \"8.9\", \"18.9\", \"84.9\", \"2.4\", …\n$ ...13  &lt;chr&gt; \"2024 Feb\", \"23159.9\", \"3921.7\", \"14.7\", \"4.3\", \"71.5\", \"8.1\", …\n$ ...14  &lt;chr&gt; \"2024 Jan\", \"25136.8\", \"3807.8\", \"11.1\", \"4.5\", \"101.7\", \"0.4\",…\n$ ...15  &lt;chr&gt; \"2023 Dec\", \"22546\", \"3425\", \"10.5\", \"3.3\", \"85\", \"4.6\", \"43.5\"…\n$ ...16  &lt;chr&gt; \"2023 Nov\", \"24833.9\", \"4007.9\", \"13.9\", \"3\", \"75.1\", \"2.1\", \"4…\n$ ...17  &lt;chr&gt; \"2023 Oct\", \"26297.7\", \"3468.8\", \"6.3\", \"1.9\", \"92.6\", \"6.2\", \"…\n$ ...18  &lt;chr&gt; \"2023 Sep\", \"23093.3\", \"3743.2\", \"11.3\", \"4\", \"75.5\", \"3.5\", \"4…\n$ ...19  &lt;chr&gt; \"2023 Aug\", \"23134.7\", \"3508.5\", \"15\", \"2.7\", \"63.9\", \"6.3\", \"5…\n$ ...20  &lt;chr&gt; \"2023 Jul\", \"22445.5\", \"4378.6\", \"8.1\", \"4.7\", \"58.9\", \"1.8\", \"…\n$ ...21  &lt;chr&gt; \"2023 Jun\", \"23470\", \"3742.1\", \"6.6\", \"2.2\", \"64\", \"2.6\", \"71.3…\n$ ...22  &lt;chr&gt; \"2023 May\", \"23026.6\", \"3455.4\", \"7.8\", \"3.3\", \"74.4\", \"7.7\", \"…\n$ ...23  &lt;chr&gt; \"2023 Apr\", \"24015\", \"4700.6\", \"9.4\", \"2.3\", \"75.3\", \"5.4\", \"39…\n$ ...24  &lt;chr&gt; \"2023 Mar\", \"27554.9\", \"5589.5\", \"12.9\", \"6.7\", \"83.3\", \"6.4\", …\n$ ...25  &lt;chr&gt; \"2023 Feb\", \"22273.8\", \"3230.4\", \"11.3\", \"6.1\", \"73.3\", \"4.8\", …\n$ ...26  &lt;chr&gt; \"2023 Jan\", \"22361.4\", \"3199.4\", \"5.5\", \"3.9\", \"104.7\", \"14.5\",…\n$ ...27  &lt;chr&gt; \"2022 Dec\", \"24423.6\", \"3398.3\", \"9\", \"1.6\", \"92.4\", \"1\", \"62\",…\n$ ...28  &lt;chr&gt; \"2022 Nov\", \"24976.4\", \"3571.6\", \"12.9\", \"4.2\", \"101.8\", \"17.5\"…\n$ ...29  &lt;chr&gt; \"2022 Oct\", \"25546\", \"3879.4\", \"6.3\", \"3.6\", \"101.3\", \"19.8\", \"…\n$ ...30  &lt;chr&gt; \"2022 Sep\", \"27479.1\", \"3905.9\", \"12.4\", \"23.8\", \"118.8\", \"8\", …\n$ ...31  &lt;chr&gt; \"2022 Aug\", \"30220.5\", \"4598.1\", \"11.4\", \"19.1\", \"141.8\", \"11.2…\n$ ...32  &lt;chr&gt; \"2022 Jul\", \"30998.1\", \"3691.7\", \"11.8\", \"3\", \"115.5\", \"4.2\", \"…\n$ ...33  &lt;chr&gt; \"2022 Jun\", \"30072.1\", \"4460.3\", \"9.6\", \"4.8\", \"141.4\", \"17.3\",…\n$ ...34  &lt;chr&gt; \"2022 May\", \"29142.3\", \"3546.5\", \"13\", \"7.6\", \"118.6\", \"9\", \"51…\n$ ...35  &lt;chr&gt; \"2022 Apr\", \"28376.1\", \"3974.5\", \"13.1\", \"7\", \"105.3\", \"1\", \"73…\n$ ...36  &lt;chr&gt; \"2022 Mar\", \"29495.6\", \"4967.3\", \"12.6\", \"3.9\", \"76.1\", \"9.2\", …\n$ ...37  &lt;chr&gt; \"2022 Feb\", \"24202.3\", \"3075.2\", \"8.6\", \"4.4\", \"88\", \"20.4\", \"4…\n$ ...38  &lt;chr&gt; \"2022 Jan\", \"24736.8\", \"3857\", \"10.3\", \"4.8\", \"100.3\", \"14.3\", …\n$ ...39  &lt;chr&gt; \"2021 Dec\", \"26075.1\", \"3321.9\", \"10.4\", \"3.8\", \"89.7\", \"5.2\", …\n$ ...40  &lt;chr&gt; \"2021 Nov\", \"26480.9\", \"3579.7\", \"8\", \"2.4\", \"90.1\", \"6.3\", \"45…\n$ ...41  &lt;chr&gt; \"2021 Oct\", \"23992.9\", \"3102.2\", \"6.3\", \"2.4\", \"74.3\", \"11.7\", …\n$ ...42  &lt;chr&gt; \"2021 Sep\", \"22928.6\", \"3301.5\", \"8.3\", \"1.8\", \"90.4\", \"2.2\", \"…\n$ ...43  &lt;chr&gt; \"2021 Aug\", \"23119.3\", \"3027.3\", \"4.5\", \"2.7\", \"84.4\", \"11.2\", …\n$ ...44  &lt;chr&gt; \"2021 Jul\", \"23284.6\", \"2941.7\", \"6.3\", \"4.4\", \"79.2\", \"4.3\", \"…\n$ ...45  &lt;chr&gt; \"2021 Jun\", \"23737.8\", \"3252.9\", \"9.4\", \"2.6\", \"76.3\", \"1.3\", \"…\n$ ...46  &lt;chr&gt; \"2021 May\", \"21616.3\", \"3369.2\", \"8.1\", \"4.1\", \"68.8\", \"5.2\", \"…\n$ ...47  &lt;chr&gt; \"2021 Apr\", \"22801.9\", \"3243.6\", \"7.4\", \"2.8\", \"61.6\", \"4.5\", \"…\n$ ...48  &lt;chr&gt; \"2021 Mar\", \"25218.4\", \"3709.1\", \"10.5\", \"15.7\", \"87.6\", \"7\", \"…\n$ ...49  &lt;chr&gt; \"2021 Feb\", \"19517.4\", \"2891.3\", \"8.2\", \"9\", \"62.8\", \"6.8\", \"38…\n$ ...50  &lt;chr&gt; \"2021 Jan\", \"20202.2\", \"2750.3\", \"6.5\", \"1.5\", \"74\", \"3\", \"38\",…\n$ ...51  &lt;chr&gt; \"2020 Dec\", \"20137.9\", \"3552.7\", \"6.8\", \"3\", \"63.9\", \"7.1\", \"37…\n$ ...52  &lt;chr&gt; \"2020 Nov\", \"18017.3\", \"3024.1\", \"7.1\", \"17\", \"51.8\", \"5.3\", \"2…\n$ ...53  &lt;chr&gt; \"2020 Oct\", \"18651.6\", \"2781.2\", \"6.4\", \"12.3\", \"51.8\", \"3.9\", …\n$ ...54  &lt;chr&gt; \"2020 Sep\", \"18815.7\", \"2528.1\", \"8.1\", \"8.6\", \"45.7\", \"4.5\", \"…\n$ ...55  &lt;chr&gt; \"2020 Aug\", \"20063.2\", \"2891.2\", \"3.8\", \"11.9\", \"47.9\", \"2.7\", …\n$ ...56  &lt;chr&gt; \"2020 Jul\", \"19502.9\", \"4517.1\", \"2.8\", \"9.9\", \"47.8\", \"2.7\", \"…\n$ ...57  &lt;chr&gt; \"2020 Jun\", \"18021.1\", \"2949\", \"5\", \"6.3\", \"35.4\", \"2\", \"49.9\",…\n$ ...58  &lt;chr&gt; \"2020 May\", \"16915.5\", \"4066.3\", \"4\", \"1\", \"40.5\", \"3.6\", \"55.6…\n$ ...59  &lt;chr&gt; \"2020 Apr\", \"19246.4\", \"4604.8\", \"7.9\", \"14.3\", \"55.5\", \"2.3\", …\n$ ...60  &lt;chr&gt; \"2020 Mar\", \"22373.5\", \"3687.7\", \"13\", \"2.1\", \"82.6\", \"1.8\", \"3…\n$ ...61  &lt;chr&gt; \"2020 Feb\", \"21069.5\", \"3331.4\", \"10.5\", \"2\", \"109.9\", \"10.8\", …\n$ ...62  &lt;chr&gt; \"2020 Jan\", \"21635\", \"3453.7\", \"20.1\", \"6.8\", \"125.9\", \"16.9\", …\n$ ...63  &lt;chr&gt; \"2019 Dec\", \"20385\", \"2315.5\", \"3.6\", \"2.3\", \"19.6\", \"4.6\", \"28…\n$ ...64  &lt;chr&gt; \"2019 Nov\", \"21027.8\", \"2702.5\", \"7.9\", \"2.2\", \"40\", \"3.9\", \"48…\n$ ...65  &lt;chr&gt; \"2019 Oct\", \"21927.3\", \"2581.5\", \"10.4\", \"9.6\", \"57.1\", \"5.6\", …\n$ ...66  &lt;chr&gt; \"2019 Sep\", \"19546\", \"2651.7\", \"9.3\", \"1.6\", \"55.3\", \"5.5\", \"49…\n$ ...67  &lt;chr&gt; \"2019 Aug\", \"20850.4\", \"2707\", \"9.7\", \"5\", \"84.6\", \"5.4\", \"45.5…\n$ ...68  &lt;chr&gt; \"2019 Jul\", \"21144.2\", \"3074.8\", \"11.5\", \"7.5\", \"74.4\", \"8.2\", …\n$ ...69  &lt;chr&gt; \"2019 Jun\", \"19933\", \"2979.7\", \"11.7\", \"13.1\", \"62.4\", \"3\", \"36…\n$ ...70  &lt;chr&gt; \"2019 May\", \"23259.1\", \"3624.5\", \"15.4\", \"7.8\", \"86.8\", \"1.5\", …\n$ ...71  &lt;chr&gt; \"2019 Apr\", \"21486.6\", \"2732.8\", \"12.4\", \"7.7\", \"65\", \"10.7\", \"…\n$ ...72  &lt;chr&gt; \"2019 Mar\", \"20723.8\", \"3078.2\", \"9.8\", \"5.2\", \"74.3\", \"4.3\", \"…\n$ ...73  &lt;chr&gt; \"2019 Feb\", \"19909.7\", \"3013\", \"10.9\", \"1.7\", \"72.1\", \"10.1\", \"…\n$ ...74  &lt;chr&gt; \"2019 Jan\", \"21400.7\", \"2774.2\", \"9\", \"3.8\", \"73.7\", \"7.7\", \"50…\n$ ...75  &lt;chr&gt; \"2018 Dec\", \"21093.1\", \"2617.9\", \"15.4\", \"4.9\", \"82.8\", \"2.1\", …\n$ ...76  &lt;chr&gt; \"2018 Nov\", \"24480.7\", \"2952.5\", \"19\", \"3.6\", \"105.5\", \"9\", \"36…\n$ ...77  &lt;chr&gt; \"2018 Oct\", \"26021.8\", \"3223.4\", \"9.3\", \"3.3\", \"98.2\", \"11.5\", …\n$ ...78  &lt;chr&gt; \"2018 Sep\", \"22549.9\", \"3155.5\", \"11.8\", \"7.2\", \"103.2\", \"5.5\",…\n$ ...79  &lt;chr&gt; \"2018 Aug\", \"24732\", \"3334\", \"14.4\", \"2.4\", \"88.4\", \"5.3\", \"64.…\n$ ...80  &lt;chr&gt; \"2018 Jul\", \"23569.5\", \"3240.9\", \"13\", \"2.3\", \"94.3\", \"5.3\", \"6…\n$ ...81  &lt;chr&gt; \"2018 Jun\", \"23385.7\", \"3066.1\", \"12.6\", \"3\", \"88.9\", \"13.9\", \"…\n$ ...82  &lt;chr&gt; \"2018 May\", \"25908\", \"3641.8\", \"10.4\", \"3.6\", \"93\", \"16.7\", \"58…\n$ ...83  &lt;chr&gt; \"2018 Apr\", \"23078.8\", \"3118.8\", \"12.4\", \"6.4\", \"90.5\", \"17.6\",…\n$ ...84  &lt;chr&gt; \"2018 Mar\", \"22997.9\", \"3168.5\", \"14.4\", \"2.7\", \"78\", \"14.8\", \"…\n$ ...85  &lt;chr&gt; \"2018 Feb\", \"20113.2\", \"2512.2\", \"15.2\", \"2.4\", \"88.6\", \"10.6\",…\n$ ...86  &lt;chr&gt; \"2018 Jan\", \"23207.3\", \"2694.2\", \"10.4\", \"2.7\", \"89.5\", \"9.4\", …\n$ ...87  &lt;chr&gt; \"2017 Dec\", \"23287.9\", \"2298.9\", \"9.7\", \"3.5\", \"78.9\", \"5.7\", \"…\n$ ...88  &lt;chr&gt; \"2017 Nov\", \"23434.9\", \"2264.2\", \"12.1\", \"3\", \"63.3\", \"10.6\", \"…\n$ ...89  &lt;chr&gt; \"2017 Oct\", \"22545.5\", \"2448.9\", \"14.4\", \"13.8\", \"82.1\", \"11.5\"…\n$ ...90  &lt;chr&gt; \"2017 Sep\", \"20428.5\", \"2250.9\", \"13.3\", \"4.8\", \"64\", \"13.2\", \"…\n$ ...91  &lt;chr&gt; \"2017 Aug\", \"21594.6\", \"2442.1\", \"12.5\", \"5.5\", \"70.4\", \"10.9\",…\n$ ...92  &lt;chr&gt; \"2017 Jul\", \"19856.1\", \"2141.5\", \"11.2\", \"4.3\", \"51.4\", \"5.1\", …\n$ ...93  &lt;chr&gt; \"2017 Jun\", \"21088.2\", \"2397.2\", \"16.5\", \"3.8\", \"60.7\", \"16.9\",…\n$ ...94  &lt;chr&gt; \"2017 May\", \"22282.2\", \"2649.7\", \"16.5\", \"4.8\", \"68.3\", \"14.4\",…\n$ ...95  &lt;chr&gt; \"2017 Apr\", \"20736.5\", \"2485.3\", \"12.7\", \"2.7\", \"75.3\", \"12.4\",…\n$ ...96  &lt;chr&gt; \"2017 Mar\", \"23098.2\", \"2812.1\", \"16.9\", \"5.7\", \"58.5\", \"14.1\",…\n$ ...97  &lt;chr&gt; \"2017 Feb\", \"20545\", \"2063.9\", \"12.6\", \"3\", \"76.4\", \"5.6\", \"40.…\n$ ...98  &lt;chr&gt; \"2017 Jan\", \"20404.3\", \"2233.2\", \"15.5\", \"4.9\", \"47.8\", \"15.9\",…\n$ ...99  &lt;chr&gt; \"2016 Dec\", \"21516.2\", \"1990.2\", \"18.3\", \"4\", \"54.5\", \"7.4\", \"3…\n$ ...100 &lt;chr&gt; \"2016 Nov\", \"20283\", \"2206.1\", \"16.7\", \"3.7\", \"60.6\", \"9.3\", \"2…\n$ ...101 &lt;chr&gt; \"2016 Oct\", \"18278.5\", \"1900.4\", \"16.4\", \"2.7\", \"45.4\", \"5.3\", …\n$ ...102 &lt;chr&gt; \"2016 Sep\", \"19014.9\", \"2391.2\", \"14.4\", \"3.4\", \"50.7\", \"6.7\", …\n$ ...103 &lt;chr&gt; \"2016 Aug\", \"18194.4\", \"2340\", \"14.4\", \"9.1\", \"57.9\", \"13.7\", \"…\n$ ...104 &lt;chr&gt; \"2016 Jul\", \"18547.8\", \"2582\", \"12\", \"16.6\", \"54\", \"6.4\", \"45.1…\n$ ...105 &lt;chr&gt; \"2016 Jun\", \"19591.8\", \"2767.7\", \"16.1\", \"43.6\", \"53.8\", \"10\", …\n$ ...106 &lt;chr&gt; \"2016 May\", \"20068.4\", \"2532.1\", \"15.1\", \"8\", \"48.1\", \"10.6\", \"…\n$ ...107 &lt;chr&gt; \"2016 Apr\", \"18822\", \"2355\", \"12.4\", \"2.1\", \"36.8\", \"3.7\", \"25.…\n$ ...108 &lt;chr&gt; \"2016 Mar\", \"17947.9\", \"2301\", \"9.7\", \"4.1\", \"33.3\", \"6.3\", \"31…\n$ ...109 &lt;chr&gt; \"2016 Feb\", \"15024.3\", \"1911.5\", \"9.3\", \"3.3\", \"42.1\", \"11.2\", …\n$ ...110 &lt;chr&gt; \"2016 Jan\", \"16643.9\", \"1938.3\", \"14.6\", \"3.2\", \"47.2\", \"13.1\",…\n$ ...111 &lt;chr&gt; \"2015 Dec\", \"18332.7\", \"2029.5\", \"17.1\", \"5.1\", \"65.1\", \"6.5\", …\n$ ...112 &lt;chr&gt; \"2015 Nov\", \"17321\", \"2163.4\", \"20.1\", \"2.8\", \"51.2\", \"14.8\", \"…\n$ ...113 &lt;chr&gt; \"2015 Oct\", \"20189.5\", \"2718.2\", \"19.1\", \"4.8\", \"54.6\", \"11.5\",…\n$ ...114 &lt;chr&gt; \"2015 Sep\", \"19701.7\", \"2475.5\", \"21.5\", \"2.8\", \"62.9\", \"11.3\",…\n$ ...115 &lt;chr&gt; \"2015 Aug\", \"18999.3\", \"2636.1\", \"25.9\", \"4\", \"58\", \"8.7\", \"34\"…\n$ ...116 &lt;chr&gt; \"2015 Jul\", \"21909.5\", \"2672.8\", \"30.1\", \"4.4\", \"65.6\", \"14.9\",…\n$ ...117 &lt;chr&gt; \"2015 Jun\", \"21109.2\", \"2823.6\", \"31.7\", \"4.8\", \"63.4\", \"15.4\",…\n$ ...118 &lt;chr&gt; \"2015 May\", \"19637.1\", \"2537.4\", \"31\", \"4.1\", \"56.4\", \"22.1\", \"…\n$ ...119 &lt;chr&gt; \"2015 Apr\", \"20829.5\", \"2809.9\", \"20.1\", \"4.4\", \"64.4\", \"16.7\",…\n$ ...120 &lt;chr&gt; \"2015 Mar\", \"23159.6\", \"3037.4\", \"24.5\", \"4.4\", \"70.9\", \"22.6\",…\n$ ...121 &lt;chr&gt; \"2015 Feb\", \"16622.1\", \"1983.5\", \"16.5\", \"4.1\", \"62.3\", \"15.2\",…\n$ ...122 &lt;chr&gt; \"2015 Jan\", \"19921.7\", \"2422.1\", \"25.5\", \"4.6\", \"73.4\", \"23.6\",…\n$ ...123 &lt;chr&gt; \"2014 Dec\", \"20793.6\", \"2445.2\", \"20.2\", \"3.8\", \"76.3\", \"21.8\",…\n$ ...124 &lt;chr&gt; \"2014 Nov\", \"20041.9\", \"2566.2\", \"29.2\", \"10.7\", \"96.3\", \"16.1\"…\n$ ...125 &lt;chr&gt; \"2014 Oct\", \"22476.2\", \"2537.5\", \"27.9\", \"2.3\", \"98.3\", \"37\", \"…\n$ ...126 &lt;chr&gt; \"2014 Sep\", \"22797.5\", \"2968.7\", \"32.2\", \"3.3\", \"113.8\", \"27.2\"…\n$ ...127 &lt;chr&gt; \"2014 Aug\", \"23707\", \"3132.9\", \"30\", \"3.1\", \"76.1\", \"31.8\", \"52…\n$ ...128 &lt;chr&gt; \"2014 Jul\", \"23475.4\", \"2980.8\", \"42.3\", \"4.6\", \"102.6\", \"34.3\"…\n$ ...129 &lt;chr&gt; \"2014 Jun\", \"22555.3\", \"3104.9\", \"37.2\", \"5.9\", \"90.8\", \"32.2\",…\n$ ...130 &lt;chr&gt; \"2014 May\", \"22942.4\", \"2702\", \"36.5\", \"5.9\", \"114.2\", \"50.3\", …\n$ ...131 &lt;chr&gt; \"2014 Apr\", \"23976.2\", \"3162.9\", \"27.1\", \"9.5\", \"115.5\", \"28.5\"…\n$ ...132 &lt;chr&gt; \"2014 Mar\", \"22279.1\", \"2726.7\", \"28.1\", \"58.4\", \"91.7\", \"28.3\"…\n$ ...133 &lt;chr&gt; \"2014 Feb\", \"22219.8\", \"2822.4\", \"31.9\", \"9.2\", \"120.8\", \"40\", …\n$ ...134 &lt;chr&gt; \"2014 Jan\", \"22513.7\", \"2838.7\", \"37.3\", \"28.9\", \"150.4\", \"46.7…\n$ ...135 &lt;chr&gt; \"2013 Dec\", \"22119.6\", \"2798.7\", \"28.2\", \"3.3\", \"95.2\", \"45.9\",…\n$ ...136 &lt;chr&gt; \"2013 Nov\", \"21501.6\", \"2719.9\", \"39.3\", \"3.5\", \"109.1\", \"31.4\"…\n$ ...137 &lt;chr&gt; \"2013 Oct\", \"24112.2\", \"3030.1\", \"26.2\", \"8\", \"105.6\", \"39.4\", …\n$ ...138 &lt;chr&gt; \"2013 Sep\", \"23868.5\", \"3144.3\", \"45.6\", \"5.7\", \"68\", \"54.2\", \"…\n$ ...139 &lt;chr&gt; \"2013 Aug\", \"22578.8\", \"3148.4\", \"33.1\", \"2.9\", \"116.3\", \"35\", …\n$ ...140 &lt;chr&gt; \"2013 Jul\", \"24041.1\", \"3137.4\", \"41.2\", \"6.6\", \"97.4\", \"28.9\",…\n$ ...141 &lt;chr&gt; \"2013 Jun\", \"22544.3\", \"3170.1\", \"31.1\", \"5.2\", \"89.1\", \"35.6\",…\n$ ...142 &lt;chr&gt; \"2013 May\", \"22157.5\", \"3027.4\", \"32.2\", \"5.5\", \"92\", \"27.9\", \"…\n$ ...143 &lt;chr&gt; \"2013 Apr\", \"22973.9\", \"3250.7\", \"41\", \"6.6\", \"118.6\", \"36.9\", …\n$ ...144 &lt;chr&gt; \"2013 Mar\", \"22806.5\", \"3217.4\", \"35.8\", \"5\", \"83.4\", \"45.8\", \"…\n$ ...145 &lt;chr&gt; \"2013 Feb\", \"20123.7\", \"2561.4\", \"45.3\", \"2.8\", \"120.8\", \"27.4\"…\n$ ...146 &lt;chr&gt; \"2013 Jan\", \"22389\", \"3052.2\", \"34.5\", \"5.5\", \"92.4\", \"30.6\", \"…\n$ ...147 &lt;chr&gt; \"2012 Dec\", \"21102.4\", \"2341.8\", \"35.5\", \"3.7\", \"81\", \"23.7\", \"…\n$ ...148 &lt;chr&gt; \"2012 Nov\", \"22994.7\", \"2983.5\", \"40.6\", \"7.2\", \"84.6\", \"22.9\",…\n$ ...149 &lt;chr&gt; \"2012 Oct\", \"24825.7\", \"3593.8\", \"26.6\", \"7.8\", \"74.5\", \"29.3\",…\n$ ...150 &lt;chr&gt; \"2012 Sep\", \"22273.7\", \"2958\", \"42.5\", \"3.2\", \"104.3\", \"38.1\", …\n$ ...151 &lt;chr&gt; \"2012 Aug\", \"23230.6\", \"3223\", \"47.3\", \"5.9\", \"73.7\", \"33.6\", \"…\n$ ...152 &lt;chr&gt; \"2012 Jul\", \"23067.8\", \"3034.8\", \"34.8\", \"5.4\", \"109.6\", \"28.2\"…\n$ ...153 &lt;chr&gt; \"2012 Jun\", \"24121.7\", \"3144.9\", \"56.3\", \"6.6\", \"134\", \"22.3\", …\n$ ...154 &lt;chr&gt; \"2012 May\", \"25067.4\", \"3189.1\", \"67.7\", \"29.5\", \"107.8\", \"41.8…\n$ ...155 &lt;chr&gt; \"2012 Apr\", \"24135.8\", \"3386.2\", \"61\", \"5.5\", \"123.7\", \"31.4\", …\n$ ...156 &lt;chr&gt; \"2012 Mar\", \"25063.4\", \"3229.7\", \"41.5\", \"3.8\", \"116.9\", \"30.5\"…\n$ ...157 &lt;chr&gt; \"2012 Feb\", \"26337\", \"3934.4\", \"54.3\", \"3\", \"112.1\", \"25.7\", \"3…\n$ ...158 &lt;chr&gt; \"2012 Jan\", \"22948.8\", \"3729.8\", \"61.5\", \"10.5\", \"135.8\", \"36.6…\n$ ...159 &lt;chr&gt; \"2011 Dec\", \"24644.1\", \"3688.2\", \"41\", \"11.8\", \"97.2\", \"34.5\", …\n$ ...160 &lt;chr&gt; \"2011 Nov\", \"23382.7\", \"2987.9\", \"53.5\", \"5.1\", \"96.3\", \"28.5\",…\n$ ...161 &lt;chr&gt; \"2011 Oct\", \"22829\", \"3143.5\", \"55.4\", \"13.2\", \"97.6\", \"33.3\", …\n$ ...162 &lt;chr&gt; \"2011 Sep\", \"24403.9\", \"3118.8\", \"53.1\", \"11.8\", \"132\", \"30.2\",…\n$ ...163 &lt;chr&gt; \"2011 Aug\", \"26302.9\", \"3476.3\", \"59.8\", \"6.6\", \"94.6\", \"33.3\",…\n$ ...164 &lt;chr&gt; \"2011 Jul\", \"23385\", \"3397.8\", \"53.2\", \"10.7\", \"114.7\", \"19.9\",…\n$ ...165 &lt;chr&gt; \"2011 Jun\", \"23554.3\", \"3584\", \"55.6\", \"5.6\", \"127\", \"26.5\", \"3…\n$ ...166 &lt;chr&gt; \"2011 May\", \"22893.8\", \"3014.9\", \"54.8\", \"4.7\", \"77.7\", \"10.6\",…\n$ ...167 &lt;chr&gt; \"2011 Apr\", \"23029.6\", \"3535.6\", \"61.9\", \"8.8\", \"113.8\", \"27.4\"…\n$ ...168 &lt;chr&gt; \"2011 Mar\", \"24934.1\", \"4463.9\", \"60.7\", \"19.2\", \"97.7\", \"14.3\"…\n$ ...169 &lt;chr&gt; \"2011 Feb\", \"19710.8\", \"2908.2\", \"52.7\", \"12.7\", \"104\", \"18.6\",…\n$ ...170 &lt;chr&gt; \"2011 Jan\", \"22659\", \"3072.7\", \"60.7\", \"7.6\", \"84.8\", \"25.2\", \"…\n$ ...171 &lt;chr&gt; \"2010 Dec\", \"21397.5\", \"2741.1\", \"39.6\", \"7.1\", \"81.9\", \"21.9\",…\n$ ...172 &lt;chr&gt; \"2010 Nov\", \"20754.3\", \"2743.5\", \"45.4\", \"14.5\", \"90.6\", \"9.7\",…\n$ ...173 &lt;chr&gt; \"2010 Oct\", \"22881.8\", \"3822.3\", \"48\", \"10.9\", \"57.9\", \"16.9\", …\n$ ...174 &lt;chr&gt; \"2010 Sep\", \"21820.7\", \"3596.9\", \"52.4\", \"17.5\", \"75.9\", \"26.7\"…\n$ ...175 &lt;chr&gt; \"2010 Aug\", \"22392.6\", \"3267.5\", \"51.1\", \"17.9\", \"63.4\", \"12.6\"…\n$ ...176 &lt;chr&gt; \"2010 Jul\", \"20570.6\", \"2770.1\", \"57.7\", \"19.3\", \"81\", \"10.5\", …\n$ ...177 &lt;chr&gt; \"2010 Jun\", \"21016.7\", \"3039.3\", \"49.4\", \"24.2\", \"80.1\", \"14.9\"…\n$ ...178 &lt;chr&gt; \"2010 May\", \"20174.3\", \"2666.8\", \"56.7\", \"9.5\", \"80.8\", \"12.3\",…\n$ ...179 &lt;chr&gt; \"2010 Apr\", \"21633.5\", \"3893\", \"41.7\", \"17.7\", \"78.8\", \"22.7\", …\n$ ...180 &lt;chr&gt; \"2010 Mar\", \"20832.7\", \"2638.7\", \"46.8\", \"5.4\", \"85.9\", \"12.8\",…\n$ ...181 &lt;chr&gt; \"2010 Feb\", \"17671.1\", \"2543.8\", \"50.1\", \"3.2\", \"83.5\", \"23.6\",…\n$ ...182 &lt;chr&gt; \"2010 Jan\", \"17889.8\", \"2635.1\", \"42.6\", \"4.6\", \"90.7\", \"13.3\",…\n$ ...183 &lt;chr&gt; \"2009 Dec\", \"19404.7\", \"2728.5\", \"44.4\", \"4.4\", \"74.7\", \"19.4\",…\n$ ...184 &lt;chr&gt; \"2009 Nov\", \"18866.9\", \"3150.7\", \"63.2\", \"4.4\", \"66.3\", \"19.2\",…\n$ ...185 &lt;chr&gt; \"2009 Oct\", \"17864.5\", \"2749.4\", \"37.2\", \"3.3\", \"71.2\", \"15.7\",…\n$ ...186 &lt;chr&gt; \"2009 Sep\", \"18615.7\", \"2909.3\", \"42\", \"3.8\", \"73.3\", \"23.8\", \"…\n$ ...187 &lt;chr&gt; \"2009 Aug\", \"17459.2\", \"2921.2\", \"41.6\", \"3\", \"68.6\", \"15.5\", \"…\n$ ...188 &lt;chr&gt; \"2009 Jul\", \"18233.2\", \"2864\", \"32.1\", \"3.1\", \"76.7\", \"15.2\", \"…\n$ ...189 &lt;chr&gt; \"2009 Jun\", \"16391.2\", \"3157.3\", \"32.1\", \"2.7\", \"47.9\", \"13.5\",…\n$ ...190 &lt;chr&gt; \"2009 May\", \"15149.1\", \"2185.8\", \"30.8\", \"3.4\", \"53.1\", \"14.1\",…\n$ ...191 &lt;chr&gt; \"2009 Apr\", \"15538.8\", \"2804\", \"22.4\", \"13.7\", \"37.3\", \"20.5\", …\n$ ...192 &lt;chr&gt; \"2009 Mar\", \"15748.8\", \"2379.1\", \"23.4\", \"3.6\", \"49\", \"14.6\", \"…\n$ ...193 &lt;chr&gt; \"2009 Feb\", \"13393.6\", \"2210.4\", \"19.7\", \"3.3\", \"54.7\", \"11.6\",…\n$ ...194 &lt;chr&gt; \"2009 Jan\", \"13544\", \"2094.8\", \"18\", \"4.2\", \"37.2\", \"7.3\", \"24.…\n$ ...195 &lt;chr&gt; \"2008 Dec\", \"14339.9\", \"2293.6\", \"20.9\", \"5.4\", \"42.1\", \"5.8\", …\n$ ...196 &lt;chr&gt; \"2008 Nov\", \"17554.7\", \"3514.2\", \"38\", \"34\", \"69.5\", \"21.8\", \"6…\n$ ...197 &lt;chr&gt; \"2008 Oct\", \"20099.6\", \"3032.7\", \"57.6\", \"8.9\", \"77.6\", \"21\", \"…\n$ ...198 &lt;chr&gt; \"2008 Sep\", \"22702.3\", \"3454.8\", \"58.2\", \"53.7\", \"144.3\", \"40.4…\n$ ...199 &lt;chr&gt; \"2008 Aug\", \"22719.7\", \"3313.6\", \"72.6\", \"4.5\", \"125.4\", \"47.8\"…\n$ ...200 &lt;chr&gt; \"2008 Jul\", \"23970.8\", \"3062.2\", \"62.2\", \"12.2\", \"94.8\", \"33.6\"…\n$ ...201 &lt;chr&gt; \"2008 Jun\", \"21655.1\", \"3194.5\", \"58.1\", \"5.5\", \"106.6\", \"32.5\"…\n$ ...202 &lt;chr&gt; \"2008 May\", \"20358.7\", \"2877.1\", \"53.3\", \"5\", \"85\", \"25.9\", \"43…\n$ ...203 &lt;chr&gt; \"2008 Apr\", \"22332.4\", \"3197.9\", \"34\", \"6.1\", \"106.5\", \"27.5\", …\n$ ...204 &lt;chr&gt; \"2008 Mar\", \"21135.5\", \"3810.8\", \"38.8\", \"5.1\", \"63.8\", \"23.6\",…\n$ ...205 &lt;chr&gt; \"2008 Feb\", \"18976.4\", \"3027.5\", \"36.8\", \"7.3\", \"68\", \"32\", \"33…\n$ ...206 &lt;chr&gt; \"2008 Jan\", \"21881.5\", \"3680.7\", \"38.8\", \"5.4\", \"65.8\", \"22.3\",…\n$ ...207 &lt;chr&gt; \"2007 Dec\", \"19544.7\", \"3082.4\", \"33.9\", \"4.6\", \"75.5\", \"26.8\",…\n$ ...208 &lt;chr&gt; \"2007 Nov\", \"20384.7\", \"3443.7\", \"36.6\", \"7\", \"59.8\", \"10.4\", \"…\n$ ...209 &lt;chr&gt; \"2007 Oct\", \"21609.9\", \"3595.2\", \"24\", \"6.3\", \"60.5\", \"15\", \"10…\n$ ...210 &lt;chr&gt; \"2007 Sep\", \"20435.3\", \"3394\", \"29.9\", \"5.7\", \"49.6\", \"8.8\", \"2…\n$ ...211 &lt;chr&gt; \"2007 Aug\", \"19902.7\", \"3507.8\", \"20.5\", \"4.3\", \"50.2\", \"18\", \"…\n$ ...212 &lt;chr&gt; \"2007 Jul\", \"20233.2\", \"3398.9\", \"21.4\", \"4.8\", \"44.2\", \"13.3\",…\n$ ...213 &lt;chr&gt; \"2007 Jun\", \"19725.2\", \"3272.5\", \"29.7\", \"5.8\", \"42.5\", \"5.4\", …\n$ ...214 &lt;chr&gt; \"2007 May\", \"19348.1\", \"3143.6\", \"24.8\", \"4.4\", \"45.6\", \"6.6\", …\n$ ...215 &lt;chr&gt; \"2007 Apr\", \"18783.4\", \"3266.9\", \"18.9\", \"4.6\", \"41.8\", \"10.1\",…\n$ ...216 &lt;chr&gt; \"2007 Mar\", \"19971.9\", \"3374.4\", \"16.3\", \"8.7\", \"48.8\", \"11.4\",…\n$ ...217 &lt;chr&gt; \"2007 Feb\", \"15446.6\", \"2793.5\", \"16.1\", \"4.2\", \"35.2\", \"7.3\", …\n$ ...218 &lt;chr&gt; \"2007 Jan\", \"19562\", \"3324.6\", \"17.8\", \"24\", \"40.2\", \"9.5\", \"99…\n$ ...219 &lt;chr&gt; \"2006 Dec\", \"17564.9\", \"2433.7\", \"15.8\", \"5.7\", \"29\", \"2.7\", \"8…\n$ ...220 &lt;chr&gt; \"2006 Nov\", \"19359.8\", \"2910.5\", \"14.1\", \"5.8\", \"38.6\", \"3.5\", …\n$ ...221 &lt;chr&gt; \"2006 Oct\", \"18964\", \"3145.4\", \"17.8\", \"6\", \"35.9\", \"13.1\", \"16…\n$ ...222 &lt;chr&gt; \"2006 Sep\", \"19500.2\", \"3225.3\", \"15.4\", \"2.9\", \"39.2\", \"8.4\", …\n$ ...223 &lt;chr&gt; \"2006 Aug\", \"19302.6\", \"3150.5\", \"15.9\", \"4.2\", \"37.7\", \"7.1\", …\n$ ...224 &lt;chr&gt; \"2006 Jul\", \"19041.4\", \"3303.1\", \"19\", \"4.2\", \"35.2\", \"13.6\", \"…\n$ ...225 &lt;chr&gt; \"2006 Jun\", \"20398.8\", \"3023.6\", \"14.5\", \"6\", \"39.2\", \"9.1\", \"7…\n$ ...226 &lt;chr&gt; \"2006 May\", \"19481.9\", \"2906.2\", \"17.1\", \"4\", \"33.4\", \"14.2\", \"…\n$ ...227 &lt;chr&gt; \"2006 Apr\", \"17989.8\", \"3125.9\", \"16.6\", \"6\", \"44\", \"5.5\", \"128…\n$ ...228 &lt;chr&gt; \"2006 Mar\", \"20235.3\", \"3443.2\", \"22.3\", \"7.2\", \"45.4\", \"6.5\", …\n$ ...229 &lt;chr&gt; \"2006 Feb\", \"17720.4\", \"2760.6\", \"21.3\", \"9.6\", \"31.1\", \"5.8\", …\n$ ...230 &lt;chr&gt; \"2006 Jan\", \"17830.7\", \"2472.6\", \"19.9\", \"7.3\", \"34.1\", \"6.1\", …\n$ ...231 &lt;chr&gt; \"2005 Dec\", \"20549.8\", \"2945.9\", \"20.9\", \"8.4\", \"30.8\", \"5.2\", …\n$ ...232 &lt;chr&gt; \"2005 Nov\", \"18738.1\", \"2857.5\", \"21.7\", \"8.3\", \"45.7\", \"9.3\", …\n$ ...233 &lt;chr&gt; \"2005 Oct\", \"19489.1\", \"2740.3\", \"18.9\", \"7.5\", \"36.9\", \"4.7\", …\n$ ...234 &lt;chr&gt; \"2005 Sep\", \"18509.5\", \"2664.4\", \"20.9\", \"4.6\", \"48.9\", \"5.6\", …\n$ ...235 &lt;chr&gt; \"2005 Aug\", \"18645\", \"2574.8\", \"20.5\", \"9\", \"35.7\", \"5\", \"88.2\"…\n$ ...236 &lt;chr&gt; \"2005 Jul\", \"16940.7\", \"2529.2\", \"15.1\", \"5.8\", \"32.6\", \"4.3\", …\n$ ...237 &lt;chr&gt; \"2005 Jun\", \"16897.4\", \"2374.6\", \"13.7\", \"4.2\", \"26.7\", \"3.5\", …\n$ ...238 &lt;chr&gt; \"2005 May\", \"16272.7\", \"2200\", \"14.8\", \"3.7\", \"37.7\", \"3.2\", \"6…\n$ ...239 &lt;chr&gt; \"2005 Apr\", \"15873\", \"2256.7\", \"11.7\", \"3.6\", \"28.8\", \"1.2\", \"7…\n$ ...240 &lt;chr&gt; \"2005 Mar\", \"16702.9\", \"2555.9\", \"9.1\", \"4\", \"21.6\", \"0\", \"33.5…\n$ ...241 &lt;chr&gt; \"2005 Feb\", \"14155.7\", \"2403.4\", \"10.9\", \"3.1\", \"26.4\", \"1\", \"8…\n$ ...242 &lt;chr&gt; \"2005 Jan\", \"14701.6\", \"2379.1\", \"9.7\", \"4.4\", \"27.8\", \"2.8\", \"…\n$ ...243 &lt;chr&gt; \"2004 Dec\", \"16119.8\", \"2410.1\", \"10\", \"3.1\", \"27.2\", \"4.6\", \"3…\n$ ...244 &lt;chr&gt; \"2004 Nov\", \"15694.3\", \"2457.3\", \"19.4\", \"2.8\", \"21.7\", \"1.7\", …\n$ ...245 &lt;chr&gt; \"2004 Oct\", \"16453.4\", \"2601.7\", \"14.4\", \"4.5\", \"13.9\", \"5.2\", …\n$ ...246 &lt;chr&gt; \"2004 Sep\", \"16484.8\", \"2715.4\", \"12.4\", \"5.6\", \"25.6\", \"1.8\", …\n$ ...247 &lt;chr&gt; \"2004 Aug\", \"15612.6\", \"2729.2\", \"12.2\", \"3.8\", \"16.4\", \"3.5\", …\n$ ...248 &lt;chr&gt; \"2004 Jul\", \"15452.7\", \"2760\", \"14.9\", \"3.1\", \"17.3\", \"1.5\", \"3…\n$ ...249 &lt;chr&gt; \"2004 Jun\", \"15205.3\", \"2583.9\", \"8.8\", \"3.1\", \"25.2\", \"3.5\", \"…\n$ ...250 &lt;chr&gt; \"2004 May\", \"14527.2\", \"2650.4\", \"11.8\", \"204.4\", \"23.7\", \"4.7\"…\n$ ...251 &lt;chr&gt; \"2004 Apr\", \"14202.5\", \"2350.8\", \"11.7\", \"3.1\", \"29.4\", \"1.5\", …\n$ ...252 &lt;chr&gt; \"2004 Mar\", \"14810\", \"2560.9\", \"29.7\", \"2.9\", \"19.9\", \"2\", \"23.…\n$ ...253 &lt;chr&gt; \"2004 Feb\", \"12917.7\", \"2017.2\", \"10.3\", \"3\", \"19.8\", \"1.3\", \"1…\n$ ...254 &lt;chr&gt; \"2004 Jan\", \"12730.7\", \"2127.4\", \"11.1\", \"3\", \"26.8\", \"1.2\", \"1…\n$ ...255 &lt;chr&gt; \"2003 Dec\", \"13759.3\", \"2387.9\", \"7.4\", \"2.9\", \"20.4\", \"1.6\", \"…\n$ ...256 &lt;chr&gt; \"2003 Nov\", \"12504.9\", \"2208.3\", \"7.7\", \"1.7\", \"15.2\", \"0.4\", \"…\n$ ...257 &lt;chr&gt; \"2003 Oct\", \"13733.4\", \"2553.3\", \"7.3\", \"2.5\", \"22.3\", \"1.8\", \"…\n$ ...258 &lt;chr&gt; \"2003 Sep\", \"13541.1\", \"2339.6\", \"7.8\", \"3.6\", \"20.6\", \"3.2\", \"…\n$ ...259 &lt;chr&gt; \"2003 Aug\", \"11785.1\", \"2060.7\", \"8.7\", \"21\", \"18.8\", \"1.4\", \"1…\n$ ...260 &lt;chr&gt; \"2003 Jul\", \"12646.8\", \"2236.7\", \"6.3\", \"2.4\", \"20.5\", \"2\", \"16…\n$ ...261 &lt;chr&gt; \"2003 Jun\", \"12169.3\", \"2421.4\", \"6.8\", \"1.8\", \"21\", \"2.9\", \"13…\n$ ...262 &lt;chr&gt; \"2003 May\", \"11905.6\", \"2379.6\", \"7\", \"2.5\", \"25.5\", \"2.8\", \"15…\n$ ...263 &lt;chr&gt; \"2003 Apr\", \"12258.4\", \"2349.3\", \"7.1\", \"3.1\", \"22.2\", \"3.3\", \"…\n$ ...264 &lt;chr&gt; \"2003 Mar\", \"12707.3\", \"2384.9\", \"4.5\", \"1.4\", \"21.3\", \"2.7\", \"…\n$ ...265 &lt;chr&gt; \"2003 Feb\", \"10658\", \"2081.9\", \"8.7\", \"0.8\", \"26.1\", \"2.1\", \"13…\n$ ...266 &lt;chr&gt; \"2003 Jan\", \"12888.7\", \"2679.1\", \"5.1\", \"0.7\", \"23\", \"3.1\", \"14…\n\n\n\n\n\nThe output shows that we have successfully excluded non-relevant rows and retained only the actual trade-related data.\nTransposing the Data\nNext, since our columns represent month-year data, we need to transpose the dataset to improve its usability for subsequent data visualisation or time-series analysis. The month-year columns will be consolidated into a single column, transforming them into row identifiers, while trade-related variables will now be represented as columns.\nThe code chunk uses the t() function for transposing and the as.data.frame() function to ensure that the transposed data remains in a dataframe format:\n\ntransposed_domesticexports &lt;- as.data.frame(t(cleaned_domesticexports))\n\n# Set the first row as column names\ncolnames(transposed_domesticexports) &lt;- as.character(transposed_domesticexports[1, ])\n\n# Remove the first row from the data frame\ntransposed_domesticexports &lt;- transposed_domesticexports[-1, ]\n\nAfter transposing, we examined the structure of the resulting data frame using the glimpse() function.\n\nglimpse(transposed_domesticexports)\n\n\n\n\n\n\n\nExpand to See the Code Output\n\n\n\n\n\n\n\nRows: 265\nColumns: 161\n$ `Data Series`                    &lt;chr&gt; \"2025 Jan\", \"2024 Dec\", \"2024 Nov\", \"…\n$ `Total All Markets`              &lt;chr&gt; \"24672\", \"23684.7\", \"23438.7\", \"22147…\n$ America                          &lt;chr&gt; \"4263.1\", \"3607.9\", \"3128.7\", \"2935.5…\n$ `Antigua And Barbuda`            &lt;chr&gt; \"8.8\", \"7.1\", \"8.3\", \"7.7\", \"8.2\", \"9…\n$ Argentina                        &lt;chr&gt; \"5.3\", \"6\", \"3.9\", \"6.4\", \"3\", \"4.3\",…\n$ Bahamas                          &lt;chr&gt; \"51.4\", \"48.1\", \"60.5\", \"36.1\", \"59.3…\n$ Bermuda                          &lt;chr&gt; \"2.7\", \"7.7\", \"0.5\", \"5.4\", \"0.7\", \"5…\n$ Brazil                           &lt;chr&gt; \"40.2\", \"32.3\", \"37.8\", \"62.2\", \"30\",…\n$ Canada                           &lt;chr&gt; \"33.7\", \"35.6\", \"78.9\", \"38.6\", \"33.5…\n$ Chile                            &lt;chr&gt; \"5.1\", \"4.7\", \"4.4\", \"6.9\", \"6.8\", \"5…\n$ Colombia                         &lt;chr&gt; \"4.3\", \"7.8\", \"4.2\", \"5.3\", \"7.4\", \"5…\n$ `Costa Rica`                     &lt;chr&gt; \"4.8\", \"4\", \"4.5\", \"4.3\", \"4.9\", \"6.3…\n$ Cuba                             &lt;chr&gt; \"0\", \"0.4\", \"0\", \"0\", \"1.6\", \"0\", \"0\"…\n$ `Dominican Rep`                  &lt;chr&gt; \"1.1\", \"3.3\", \"1.2\", \"1.7\", \"0.9\", \"1…\n$ Ecuador                          &lt;chr&gt; \"2.9\", \"2.1\", \"3.2\", \"3.3\", \"3.7\", \"2…\n$ `El Salvador`                    &lt;chr&gt; \"0.6\", \"0.1\", \"0.8\", \"0.5\", \"0.4\", \"0…\n$ Guatemala                        &lt;chr&gt; \"0.3\", \"0.5\", \"0.6\", \"0.4\", \"0.8\", \"1…\n$ Guyana                           &lt;chr&gt; \"7.2\", \"6.9\", \"4.1\", \"2.9\", \"6.2\", \"3…\n$ Honduras                         &lt;chr&gt; \"0.9\", \"0.5\", \"0.1\", \"0.6\", \"0.8\", \"0…\n$ Jamaica                          &lt;chr&gt; \"0\", \"0.1\", \"0\", \"0.1\", \"0\", \"0\", \"0.…\n$ Mexico                           &lt;chr&gt; \"48.2\", \"52\", \"69.4\", \"60.4\", \"214\", …\n$ `Netherlands Antilles`           &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ Panama                           &lt;chr&gt; \"532.6\", \"493\", \"520.7\", \"492.9\", \"53…\n$ Paraguay                         &lt;chr&gt; \"0.2\", \"0.2\", \"0\", \"0.2\", \"0\", \"0.4\",…\n$ Peru                             &lt;chr&gt; \"3.7\", \"4.8\", \"5.7\", \"5.9\", \"3.9\", \"3…\n$ `Puerto Rico`                    &lt;chr&gt; \"238.5\", \"89.1\", \"122.4\", \"49.4\", \"12…\n$ `St. Vincent And The Grenadines` &lt;chr&gt; \"0.7\", \"0.9\", \"0.1\", \"1.6\", \"1.9\", \"1…\n$ `Trinidad And Tobago`            &lt;chr&gt; \"0.3\", \"0.8\", \"0.3\", \"0.6\", \"0.4\", \"0…\n$ `United States`                  &lt;chr&gt; \"3254.7\", \"2781.3\", \"2179.1\", \"2126.5…\n$ `United States Virgin Islands`   &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ Uruguay                          &lt;chr&gt; \"0.6\", \"1.2\", \"0.4\", \"0.4\", \"0.7\", \"0…\n$ Venezuela                        &lt;chr&gt; \"0\", \"0\", \"0.1\", \"0.1\", \"0.1\", \"0\", \"…\n$ `Other Markets America`          &lt;chr&gt; \"14.3\", \"17.5\", \"17.3\", \"15.2\", \"19.1…\n$ Asia                             &lt;chr&gt; \"15623.3\", \"15306\", \"14697.1\", \"14497…\n$ Afghanistan                      &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ Bahrain                          &lt;chr&gt; \"2.3\", \"5\", \"13.6\", \"2.3\", \"3.5\", \"1.…\n$ Bangladesh                       &lt;chr&gt; \"194.6\", \"168.9\", \"280.4\", \"202.4\", \"…\n$ Brunei                           &lt;chr&gt; \"17.8\", \"15.5\", \"20\", \"19.7\", \"14.3\",…\n$ Cambodia                         &lt;chr&gt; \"103.9\", \"87\", \"139.6\", \"208.6\", \"127…\n$ China                            &lt;chr&gt; \"2257.3\", \"2871.4\", \"2633.5\", \"2845\",…\n$ `Christmas Island`               &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ `Hong Kong`                      &lt;chr&gt; \"1866.1\", \"1583.9\", \"1538.5\", \"1060.3…\n$ India                            &lt;chr&gt; \"638.1\", \"544.9\", \"709\", \"516.3\", \"56…\n$ Indonesia                        &lt;chr&gt; \"2002.7\", \"2068\", \"1839.6\", \"1633.6\",…\n$ Iran                             &lt;chr&gt; \"1.1\", \"0.1\", \"1.2\", \"0\", \"0.7\", \"0.1…\n$ Iraq                             &lt;chr&gt; \"8.4\", \"7.1\", \"4.9\", \"5.9\", \"4.2\", \"8…\n$ Israel                           &lt;chr&gt; \"27.4\", \"23.2\", \"22.3\", \"27.4\", \"24.4…\n$ Japan                            &lt;chr&gt; \"830\", \"828.6\", \"771.5\", \"793.6\", \"71…\n$ Jordan                           &lt;chr&gt; \"0.8\", \"8\", \"1.8\", \"9.7\", \"2.2\", \"1.7…\n$ Kazakhstan                       &lt;chr&gt; \"5.7\", \"3\", \"2.5\", \"2\", \"1.8\", \"2.1\",…\n$ `Korea, Dem Peo Rep Of`          &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ `Korea, Rep Of`                  &lt;chr&gt; \"1110.4\", \"944\", \"881.7\", \"886.3\", \"8…\n$ Kuwait                           &lt;chr&gt; \"16.2\", \"14.5\", \"16.3\", \"20.5\", \"16.5…\n$ Lao                              &lt;chr&gt; \"3.6\", \"3.3\", \"3.1\", \"2.6\", \"2.7\", \"3…\n$ Lebanon                          &lt;chr&gt; \"0.7\", \"0.3\", \"0.7\", \"0.4\", \"0.5\", \"0…\n$ Macao                            &lt;chr&gt; \"4.4\", \"5.6\", \"6.6\", \"3.1\", \"6.1\", \"4…\n$ Malaysia                         &lt;chr&gt; \"2468.6\", \"2276.5\", \"2189.8\", \"2406.4…\n$ Maldives                         &lt;chr&gt; \"9.1\", \"9.4\", \"4.9\", \"4.2\", \"6\", \"24.…\n$ Mongolia                         &lt;chr&gt; \"2.9\", \"3.2\", \"4.9\", \"2.7\", \"2.6\", \"4…\n$ Myanmar                          &lt;chr&gt; \"273.4\", \"208.8\", \"189.3\", \"223.3\", \"…\n$ Nepal                            &lt;chr&gt; \"5.7\", \"5.8\", \"2.4\", \"2.8\", \"2.2\", \"3…\n$ Oman                             &lt;chr&gt; \"91.8\", \"13.3\", \"14.3\", \"17.5\", \"9.8\"…\n$ Pakistan                         &lt;chr&gt; \"180.4\", \"83.2\", \"128.8\", \"112.3\", \"7…\n$ Philippines                      &lt;chr&gt; \"566.1\", \"347.7\", \"424.9\", \"488.2\", \"…\n$ Qatar                            &lt;chr&gt; \"87.7\", \"72.8\", \"58.8\", \"62.2\", \"42.4…\n$ `Saudi Arabia`                   &lt;chr&gt; \"73.6\", \"117.2\", \"85.5\", \"121\", \"118.…\n$ `Sri Lanka`                      &lt;chr&gt; \"77.9\", \"105.3\", \"84.8\", \"173.7\", \"10…\n$ Syria                            &lt;chr&gt; \"0.2\", \"0\", \"0.1\", \"0.1\", \"0\", \"0\", \"…\n$ Taiwan                           &lt;chr&gt; \"1099.7\", \"1255\", \"1101.6\", \"1146.6\",…\n$ Thailand                         &lt;chr&gt; \"616.5\", \"684.7\", \"760.2\", \"591.1\", \"…\n$ Turkiye                          &lt;chr&gt; \"30.6\", \"39.3\", \"41.6\", \"26.7\", \"26.8…\n$ `United Arab Emirates`           &lt;chr&gt; \"178\", \"195.9\", \"187.9\", \"153.5\", \"16…\n$ `Viet Nam`                       &lt;chr&gt; \"759.2\", \"694.8\", \"520.2\", \"714.9\", \"…\n$ Yemen                            &lt;chr&gt; \"1\", \"0.1\", \"0.7\", \"0.1\", \"0.8\", \"1.4…\n$ `Other Markets Asia`             &lt;chr&gt; \"9.6\", \"10.9\", \"9.6\", \"10.3\", \"7\", \"6…\n$ Europe                           &lt;chr&gt; \"2123.3\", \"2053\", \"2268.5\", \"2258.1\",…\n$ Austria                          &lt;chr&gt; \"5.4\", \"9.1\", \"8.5\", \"18.4\", \"24.2\", …\n$ Belarus                          &lt;chr&gt; \"0\", \"0.2\", \"0.1\", \"0.1\", \"0.1\", \"0.1…\n$ Belgium                          &lt;chr&gt; \"128.9\", \"206.7\", \"136.4\", \"165.9\", \"…\n$ Bulgaria                         &lt;chr&gt; \"0.2\", \"0.3\", \"0.1\", \"0.6\", \"0.3\", \"0…\n$ Croatia                          &lt;chr&gt; \"2.1\", \"1.9\", \"1.3\", \"17.9\", \"0.2\", \"…\n$ Cyprus                           &lt;chr&gt; \"46.1\", \"36\", \"63.2\", \"38.1\", \"50.6\",…\n$ `Czech Rep`                      &lt;chr&gt; \"3.8\", \"3.6\", \"6.2\", \"3\", \"3.9\", \"5.2…\n$ Denmark                          &lt;chr&gt; \"36.4\", \"37.5\", \"38.3\", \"33.8\", \"36.4…\n$ Estonia                          &lt;chr&gt; \"12.2\", \"16.3\", \"3.8\", \"3.2\", \"0.1\", …\n$ Finland                          &lt;chr&gt; \"5.9\", \"8.4\", \"4.7\", \"2.8\", \"3.4\", \"3…\n$ France                           &lt;chr&gt; \"114.2\", \"93.3\", \"141.2\", \"114\", \"138…\n$ Germany                          &lt;chr&gt; \"189\", \"265.8\", \"184.6\", \"166.5\", \"20…\n$ Greece                           &lt;chr&gt; \"65.2\", \"79.2\", \"84.6\", \"54.2\", \"89.5…\n$ Hungary                          &lt;chr&gt; \"44.2\", \"4.6\", \"18.8\", \"44.8\", \"37\", …\n$ Ireland                          &lt;chr&gt; \"92.4\", \"74.3\", \"126.9\", \"95.1\", \"93.…\n$ Italy                            &lt;chr&gt; \"55\", \"50.2\", \"75.2\", \"94.5\", \"59.5\",…\n$ Latvia                           &lt;chr&gt; \"0.6\", \"1.6\", \"0.2\", \"1.7\", \"0.5\", \"0…\n$ Lithuania                        &lt;chr&gt; \"0.1\", \"0.2\", \"0.8\", \"0.2\", \"0.1\", \"0…\n$ Luxembourg                       &lt;chr&gt; \"1.4\", \"8.7\", \"2.1\", \"5.5\", \"9.3\", \"1…\n$ Malta                            &lt;chr&gt; \"189.6\", \"167.9\", \"186.8\", \"164.3\", \"…\n$ Netherlands                      &lt;chr&gt; \"622.8\", \"420.5\", \"372.6\", \"385.5\", \"…\n$ Norway                           &lt;chr&gt; \"65.5\", \"59.5\", \"51.1\", \"47.4\", \"66\",…\n$ Poland                           &lt;chr&gt; \"33.1\", \"21.4\", \"24.5\", \"24.8\", \"23.6…\n$ Portugal                         &lt;chr&gt; \"70.3\", \"52\", \"59.5\", \"49.1\", \"54.4\",…\n$ Romania                          &lt;chr&gt; \"3.9\", \"3.1\", \"6.3\", \"3.3\", \"3.8\", \"4…\n$ Russia                           &lt;chr&gt; \"9.8\", \"9.5\", \"10.3\", \"4.4\", \"9.2\", \"…\n$ Slovakia                         &lt;chr&gt; \"0.5\", \"0.6\", \"0.6\", \"1\", \"1.1\", \"0.3…\n$ Slovenia                         &lt;chr&gt; \"1.8\", \"2.9\", \"3.8\", \"4.5\", \"3.7\", \"2…\n$ Spain                            &lt;chr&gt; \"9.2\", \"17.5\", \"11.2\", \"10.5\", \"58.6\"…\n$ `Svalbard And Jan Mayen Islands` &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ Sweden                           &lt;chr&gt; \"2.1\", \"2.4\", \"2\", \"4.6\", \"3.8\", \"3\",…\n$ Switzerland                      &lt;chr&gt; \"137.8\", \"76.8\", \"93.1\", \"87.1\", \"83.…\n$ Ukraine                          &lt;chr&gt; \"0.4\", \"0\", \"0\", \"1.4\", \"1.1\", \"7.6\",…\n$ `United Kingdom`                 &lt;chr&gt; \"134.3\", \"288.3\", \"521\", \"572.6\", \"35…\n$ `Other Markets Europe`           &lt;chr&gt; \"39.1\", \"32.6\", \"28.4\", \"37.4\", \"20.7…\n$ Oceania                          &lt;chr&gt; \"1821.9\", \"1885.4\", \"2475.6\", \"1723.8…\n$ Antarctica                       &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ Australia                        &lt;chr&gt; \"908\", \"928\", \"1234.7\", \"803.5\", \"837…\n$ Fiji                             &lt;chr&gt; \"21.3\", \"66.6\", \"38.3\", \"72.6\", \"35.3…\n$ `French Polynesia`               &lt;chr&gt; \"4.1\", \"0.6\", \"3.3\", \"7.3\", \"4.9\", \"1…\n$ Guam                             &lt;chr&gt; \"24.1\", \"24.6\", \"22.4\", \"8.1\", \"41.4\"…\n$ `Marshall Islands`               &lt;chr&gt; \"425.5\", \"393.9\", \"680.8\", \"445.3\", \"…\n$ `New Caledonia`                  &lt;chr&gt; \"16.3\", \"20.2\", \"68.5\", \"17.9\", \"17.7…\n$ `New Zealand`                    &lt;chr&gt; \"303.9\", \"344.8\", \"300.2\", \"224.2\", \"…\n$ `Northern Mariana Islands`       &lt;chr&gt; \"4.5\", \"11.7\", \"11\", \"2.2\", \"20.2\", \"…\n$ `Papua New Guinea`               &lt;chr&gt; \"82.4\", \"61.2\", \"80.1\", \"91.2\", \"85.5…\n$ Samoa                            &lt;chr&gt; \"0\", \"13.6\", \"4.7\", \"12\", \"5.9\", \"10\"…\n$ `Solomon Islands`                &lt;chr&gt; \"16.7\", \"7.4\", \"15.8\", \"14.3\", \"10.7\"…\n$ Vanuatu                          &lt;chr&gt; \"1.3\", \"1.5\", \"4.8\", \"2.7\", \"0.5\", \"1…\n$ `Other Markets Oceania`          &lt;chr&gt; \"13.7\", \"11.4\", \"10.9\", \"22.6\", \"19.2…\n$ Africa                           &lt;chr&gt; \"840.3\", \"832.4\", \"868.8\", \"733.2\", \"…\n$ Algeria                          &lt;chr&gt; \"2\", \"4.9\", \"2.6\", \"1.2\", \"2.6\", \"1.1…\n$ Angola                           &lt;chr&gt; \"21.6\", \"13.5\", \"40.5\", \"7.4\", \"7.8\",…\n$ Benin                            &lt;chr&gt; \"0\", \"0.2\", \"0.1\", \"0\", \"0.1\", \"0\", \"…\n$ Cameroon                         &lt;chr&gt; \"2.1\", \"3.6\", \"3.5\", \"4\", \"0.8\", \"1.6…\n$ `Cape Verde`                     &lt;chr&gt; \"0.1\", \"0\", \"0\", \"0.1\", \"0\", \"0.1\", \"…\n$ Comoros                          &lt;chr&gt; \"0.1\", \"3.7\", \"1.5\", \"1\", \"0\", \"1.6\",…\n$ `Congo, Dem Rep Of`              &lt;chr&gt; \"1.9\", \"1\", \"1.6\", \"1.7\", \"1.5\", \"1.4…\n$ `Cote D'ivoire`                  &lt;chr&gt; \"4.4\", \"0.5\", \"1.1\", \"1\", \"3.8\", \"1.9…\n$ Djibouti                         &lt;chr&gt; \"0.1\", \"0.2\", \"0.1\", \"0.4\", \"1.3\", \"0…\n$ Egypt                            &lt;chr&gt; \"16.2\", \"15.7\", \"19\", \"14.9\", \"18.9\",…\n$ Ethiopia                         &lt;chr&gt; \"2.2\", \"1.9\", \"2.8\", \"2\", \"1.4\", \"3.2…\n$ Gabon                            &lt;chr&gt; \"1\", \"1.9\", \"3.2\", \"10.6\", \"2.9\", \"4.…\n$ Ghana                            &lt;chr&gt; \"4\", \"25.6\", \"4.1\", \"6.1\", \"4.8\", \"5\"…\n$ Guinea                           &lt;chr&gt; \"2.5\", \"3.7\", \"2.5\", \"1.2\", \"1.8\", \"1…\n$ Kenya                            &lt;chr&gt; \"2.7\", \"10.9\", \"7.5\", \"4.9\", \"6.3\", \"…\n$ Liberia                          &lt;chr&gt; \"669.5\", \"624.4\", \"645.7\", \"548.1\", \"…\n$ Libya                            &lt;chr&gt; \"4\", \"1.6\", \"3\", \"3.9\", \"2.6\", \"5.1\",…\n$ Madagascar                       &lt;chr&gt; \"0.1\", \"0.1\", \"0\", \"0.2\", \"0.2\", \"0.3…\n$ Mauritius                        &lt;chr&gt; \"8.1\", \"2.4\", \"2.4\", \"11.1\", \"9.5\", \"…\n$ Morocco                          &lt;chr&gt; \"19.6\", \"17.5\", \"34.7\", \"38.3\", \"34.5…\n$ Mozambique                       &lt;chr&gt; \"0.6\", \"3\", \"1.1\", \"0.8\", \"1\", \"25.6\"…\n$ Nigeria                          &lt;chr&gt; \"21.2\", \"7.8\", \"9.7\", \"5.1\", \"6.6\", \"…\n$ Reunion                          &lt;chr&gt; \"23.4\", \"51.2\", \"45.3\", \"28.3\", \"54\",…\n$ Seychelles                       &lt;chr&gt; \"0.6\", \"0.7\", \"0.4\", \"0.8\", \"1.2\", \"1…\n$ `Sierra Leone`                   &lt;chr&gt; \"2.5\", \"2.2\", \"2.6\", \"2.3\", \"1.9\", \"2…\n$ Somalia                          &lt;chr&gt; \"0\", \"0.2\", \"0.2\", \"0.1\", \"0\", \"0\", \"…\n$ `South Africa`                   &lt;chr&gt; \"12.9\", \"16.7\", \"16.6\", \"18.3\", \"18.2…\n$ Sudan                            &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ Swaziland                        &lt;chr&gt; \"1.5\", \"2.1\", \"2\", \"2.9\", \"0\", \"0\", \"…\n$ Tanzania                         &lt;chr&gt; \"7\", \"4.3\", \"4.6\", \"3.6\", \"3.7\", \"7.9…\n$ Tunisia                          &lt;chr&gt; \"0.6\", \"1\", \"0.1\", \"0.7\", \"0.2\", \"0.7…\n$ Zambia                           &lt;chr&gt; \"0.3\", \"0.5\", \"0.3\", \"0.1\", \"0\", \"0.2…\n$ Zimbabwe                         &lt;chr&gt; \"0.9\", \"0.3\", \"1.1\", \"0.4\", \"1.4\", \"0…\n$ `Other Markets Africa`           &lt;chr&gt; \"6.6\", \"9\", \"8.7\", \"11.9\", \"4.4\", \"5.…\n\n\n\n\n\nFrom the output of glimpse(), the following issues were identified:\n\nThe column that has the dates is now labelled as “Data Series”. We will rename this to “Date”.\nAll data types are character strings (CHR). We will convert the “Date” column to date format and the remaining columns to numeric types for appropriate data handling.\n\nThe following code chunk renames the “Data Series” column to “Date”:\n\ncolnames(transposed_domesticexports)[1] &lt;- \"Date\"\n\nThe following code chunk converts the data types into date and numeric formats accordingly. It also filter out entries from Jan 2015 onwards.\n\n# Set the locale to English for consistent date parsing\nSys.setlocale(\"LC_TIME\", \"C\")\n\n[1] \"C\"\n\ntransposed_domesticexports$Date &lt;- as.Date(paste0(transposed_domesticexports$Date, \"-01\"), format=\"%Y %b-%d\")\n\n# Filter out entries from January 2015 onwards\nfiltered_domesticexports &lt;- transposed_domesticexports[transposed_domesticexports$Date &gt;= as.Date(\"2015-01-01\"), ]\n\n# Convert remaining columns into numeric columns.\nfiltered_domesticexports[,-1] &lt;- sapply(filtered_domesticexports[,-1], function(x) as.numeric(as.character(x)))\n\nSince we are planning to use the filtered_domesticexports for our time-series analysis and forecasting in Section 4.0, we will need to convert the dataframe into a tsibble, which provides a structured and consistent framework for handling temporal data in R:\n\ndomesticexports_tsibble &lt;- filtered_domesticexports %&gt;%\n  mutate(YearMonth = yearmonth(as.Date(Date, format=\"%Y-%m-%d\"))) %&gt;%\n  as_tsibble(index = YearMonth) \n\n\nhead(domesticexports_tsibble)\n\n# A tsibble: 6 x 162 [1M]\n  Date       `Total All Markets` America `Antigua And Barbuda` Argentina Bahamas\n  &lt;date&gt;                   &lt;dbl&gt;   &lt;dbl&gt;                 &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 2015-01-01              19922.   2422.                  25.5       4.6    73.4\n2 2015-02-01              16622.   1984.                  16.5       4.1    62.3\n3 2015-03-01              23160.   3037.                  24.5       4.4    70.9\n4 2015-04-01              20830.   2810.                  20.1       4.4    64.4\n5 2015-05-01              19637.   2537.                  31         4.1    56.4\n6 2015-06-01              21109.   2824.                  31.7       4.8    63.4\n# ℹ 156 more variables: Bermuda &lt;dbl&gt;, Brazil &lt;dbl&gt;, Canada &lt;dbl&gt;, Chile &lt;dbl&gt;,\n#   Colombia &lt;dbl&gt;, `Costa Rica` &lt;dbl&gt;, Cuba &lt;dbl&gt;, `Dominican Rep` &lt;dbl&gt;,\n#   Ecuador &lt;dbl&gt;, `El Salvador` &lt;dbl&gt;, Guatemala &lt;dbl&gt;, Guyana &lt;dbl&gt;,\n#   Honduras &lt;dbl&gt;, Jamaica &lt;dbl&gt;, Mexico &lt;dbl&gt;, `Netherlands Antilles` &lt;dbl&gt;,\n#   Panama &lt;dbl&gt;, Paraguay &lt;dbl&gt;, Peru &lt;dbl&gt;, `Puerto Rico` &lt;dbl&gt;,\n#   `St. Vincent And The Grenadines` &lt;dbl&gt;, `Trinidad And Tobago` &lt;dbl&gt;,\n#   `United States` &lt;dbl&gt;, `United States Virgin Islands` &lt;dbl&gt;, …\n\n\nIn order to visualise the time-series data effectively, we need to organise the data frame from wide to long format by using pivot_longer() of tidyr package as shown below.\n\nts_longer &lt;- domesticexports_tsibble %&gt;%\n  pivot_longer(\n    cols = where(is.numeric), \n    names_to = \"Country\",\n    values_to = \"Exports\"\n  )\n\nhead(ts_longer)\n\n# A tsibble: 6 x 4 [1M]\n# Key:       Country [6]\n  Date       YearMonth Country             Exports\n  &lt;date&gt;         &lt;mth&gt; &lt;chr&gt;                 &lt;dbl&gt;\n1 2015-01-01  2015 Jan Total All Markets   19922. \n2 2015-01-01  2015 Jan America              2422. \n3 2015-01-01  2015 Jan Antigua And Barbuda    25.5\n4 2015-01-01  2015 Jan Argentina               4.6\n5 2015-01-01  2015 Jan Bahamas                73.4\n6 2015-01-01  2015 Jan Bermuda                23.6\n\n\n\nus_exports &lt;- ts_longer %&gt;%\n  filter(Country == \"United States\",\n         !(YearMonth == ymd(\"2025-01-01\")))\n\nus_exports\n\n# A tsibble: 120 x 4 [1M]\n# Key:       Country [1]\n   Date       YearMonth Country       Exports\n   &lt;date&gt;         &lt;mth&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 2015-01-01  2015 Jan United States   1248.\n 2 2015-02-01  2015 Feb United States   1038.\n 3 2015-03-01  2015 Mar United States   1564.\n 4 2015-04-01  2015 Apr United States   1459.\n 5 2015-05-01  2015 May United States   1318.\n 6 2015-06-01  2015 Jun United States   1439.\n 7 2015-07-01  2015 Jul United States   1643.\n 8 2015-08-01  2015 Aug United States   1460.\n 9 2015-09-01  2015 Sep United States   1411.\n10 2015-10-01  2015 Oct United States   1407.\n# ℹ 110 more rows"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#visual-analysis-of-time-series",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#visual-analysis-of-time-series",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "4.1 Visual Analysis of Time Series",
    "text": "4.1 Visual Analysis of Time Series"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#visualising-time-series-data",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#visualising-time-series-data",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "4.1 Visualising Time-Series Data",
    "text": "4.1 Visualising Time-Series Data\nBefore we proceed with the time-series forecasting, we will perform some exploratory data analysis to understand the dataset. The code chunk below plots both a line chart and seasonal plot to visually inspect the trend and confirm the presence of seasonality in the data:\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| fig-width: 12\n\np1 &lt;- us_exports %&gt;%\n  gg_season(Exports) +\n  labs(title = \"Seasonal Plot of Domestic Exports to the United States, \\n 2015 to 2024\",\n       x = \"Month of the Year\",\n       y = \"Exports\") +\n  facet_wrap(~ Country, scales = \"free_y\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10))\n\np2 &lt;- us_exports %&gt;%\n  ggplot(aes(x = YearMonth, y = Exports, group = Country)) +\n  geom_line() +\n  labs(title = \"Time Series of Domestic Exports to the United States, \\n 2015 to 2024\",\n       x = \"Year\",\n       y = \"Exports\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 10))\n\n\ncombined_plot &lt;- p2 / p1 + \n  plot_annotation(\n    title = \"Domestic Exports to the United States \\n grew from 2015 to 2024, peaking in March 2024.\",\n    theme = theme(plot.title = element_text(size = 14, hjust = 0.5))\n  )\n\ncombined_plot\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nDomestic exports to the United States generally increased from 2015 to 2024.\nThere are strong seasonal peaks in March and July, especially in recent years.\nThere is an increase in variability over the years, with the amplitude of peaks and troughs increasing over the years, suggesting a potential multiplicative effect.\n\n\n\nFor the purpose of forecasting, we will use the last 12 months (Jan 24 - Dec 24) for hold-out and the rest for training.\n\nus_exports2 &lt;- us_exports %&gt;%\n  mutate(Type = if_else(\n    YearMonth &gt;= ymd(\"2024-01-01\"),  # Ensure YearMonth is compared as a Date\n    \"Hold-out\", \n    \"Training\"))\n\nThe code chunk below extracts the training dataset from us_exports2 by using the filter() of the dplyr package:\n\nus_exports_train &lt;- us_exports2 %&gt;%\n  filter(Type == \"Training\")\n\nTo further understand the underlying structure of domestic exports from Singapore to the United States, an STL decomposition was performed via the following code chunk:\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nus_exports_train %&gt;%\n  model(stl = STL(Exports)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nThe trend component demonstrates a general upward trend from 2015 to 2024, implying a growth in export volumes during this period.\nThe seasonal component displays consistent patterns annually, with peaks typically occurring in 1H of each year. The amplitude of seasonal fluctuations increased from 2020.\nThe remainder component shows significant fluctuations (i.e. increased noise) after 2020, suggesting increased uncertainty or unexplained variations in export activity. This period of uncertainty coincides with major global events such as the COVID-19 pandemic and the presence of geopolitical tensions (e.g. trade war between US and China, Russo-Ukrainian War) during this period."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#united-states",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#united-states",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "4.2 United States",
    "text": "4.2 United States\n\nus_exports %&gt;%\n  gg_season(Exports) +\n  labs(title = \"Seasonal Patterns of Exports for United States\",\n       x = \"Month of the Year\",\n       y = \"Exports\") +\n  facet_wrap(~ Country, scales = \"free_y\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nus_exports2 &lt;- us_exports %&gt;%\n  mutate(Type = if_else(\n    YearMonth &gt;= ymd(\"2024-01-01\"),  # Ensure YearMonth is compared as a Date\n    \"Hold-out\", \n    \"Training\"))\n\n\nus_exports2\n\n# A tsibble: 120 x 5 [1M]\n# Key:       Country [1]\n   Date       YearMonth Country       Exports Type    \n   &lt;date&gt;         &lt;mth&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   \n 1 2015-01-01  2015 Jan United States   1248. Training\n 2 2015-02-01  2015 Feb United States   1038. Training\n 3 2015-03-01  2015 Mar United States   1564. Training\n 4 2015-04-01  2015 Apr United States   1459. Training\n 5 2015-05-01  2015 May United States   1318. Training\n 6 2015-06-01  2015 Jun United States   1439. Training\n 7 2015-07-01  2015 Jul United States   1643. Training\n 8 2015-08-01  2015 Aug United States   1460. Training\n 9 2015-09-01  2015 Sep United States   1411. Training\n10 2015-10-01  2015 Oct United States   1407. Training\n# ℹ 110 more rows\n\n\n\nus_exports_train &lt;- us_exports2 %&gt;%\n  filter(Type == \"Training\")\n\n\nus_exports_train\n\n# A tsibble: 108 x 5 [1M]\n# Key:       Country [1]\n   Date       YearMonth Country       Exports Type    \n   &lt;date&gt;         &lt;mth&gt; &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   \n 1 2015-01-01  2015 Jan United States   1248. Training\n 2 2015-02-01  2015 Feb United States   1038. Training\n 3 2015-03-01  2015 Mar United States   1564. Training\n 4 2015-04-01  2015 Apr United States   1459. Training\n 5 2015-05-01  2015 May United States   1318. Training\n 6 2015-06-01  2015 Jun United States   1439. Training\n 7 2015-07-01  2015 Jul United States   1643. Training\n 8 2015-08-01  2015 Aug United States   1460. Training\n 9 2015-09-01  2015 Sep United States   1411. Training\n10 2015-10-01  2015 Oct United States   1407. Training\n# ℹ 98 more rows\n\n\n\nus_exports_train %&gt;%\n  model(stl = STL(Exports)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nfit_ses &lt;- us_exports_train %&gt;%\n  model(ETS(Exports ~ error(\"A\") \n            + trend(\"N\") \n            + season(\"N\")))\nfit_ses\n\n# A mable: 1 x 2\n# Key:     Country [1]\n  Country       `ETS(Exports ~ error(\"A\") + trend(\"N\") + season(\"N\"))`\n  &lt;chr&gt;                                                        &lt;model&gt;\n1 United States                                           &lt;ETS(A,N,N)&gt;\n\n\n\nfit_ses %&gt;%\n  report()\n\nSeries: Exports \nModel: ETS(A,N,N) \n  Smoothing parameters:\n    alpha = 0.2172323 \n\n  Initial states:\n     l[0]\n 1336.145\n\n  sigma^2:  201083.9\n\n     AIC     AICc      BIC \n1828.491 1828.722 1836.537 \n\n\n\ngg_tsresiduals(fit_ses)\n\n\n\n\n\n\n\n\n\nus_H &lt;- us_exports_train %&gt;%\n  model(`Holt's method` = \n          ETS(Exports ~ error(\"A\") +\n                trend(\"A\") + \n                season(\"N\")))\nus_H %&gt;% report()\n\nSeries: Exports \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.1083098 \n    beta  = 0.0001000733 \n\n  Initial states:\n     l[0]     b[0]\n 1342.313 14.14718\n\n  sigma^2:  199306.7\n\n     AIC     AICc      BIC \n1829.475 1830.063 1842.886 \n\n\n\nus_HAd &lt;- us_exports_train %&gt;%\n  model(`Holt's method` = \n          ETS(Exports ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")))\nus_HAd %&gt;% report()\n\nSeries: Exports \nModel: ETS(A,Ad,N) \n  Smoothing parameters:\n    alpha = 0.1708252 \n    beta  = 0.0001000092 \n    phi   = 0.98 \n\n  Initial states:\n     l[0]     b[0]\n 1317.098 25.60957\n\n  sigma^2:  203957.3\n\n     AIC     AICc      BIC \n1832.923 1833.754 1849.015 \n\n\n\nus_WH &lt;- us_exports_train %&gt;%\n  model(\n    Additive = ETS(Exports ~ error(\"A\") \n                   + trend(\"A\") \n                   + season(\"A\")),\n    Multiplicative = ETS(Exports ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n    )\n\nus_WH %&gt;% report()\n\n# A tibble: 2 × 10\n  Country       .model    sigma2 log_lik   AIC  AICc   BIC    MSE   AMSE     MAE\n  &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 United States Additive 1.71e+5   -895. 1824. 1830. 1869. 1.45e5 1.53e5 272.   \n2 United States Multipl… 2.53e-2   -865. 1764. 1771. 1810. 1.36e5 1.45e5   0.111\n\n\n\nfit_ETS &lt;- us_exports_train %&gt;%\n  model(`SES` = ETS(Exports ~ error(\"A\") + \n                      trend(\"N\") + \n                      season(\"N\")),\n        `Holt`= ETS(Exports ~ error(\"A\") +\n                      trend(\"A\") +\n                      season(\"N\")),\n        `damped Holt` = \n          ETS(Exports ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")),\n        `WH_A` = ETS(\n          Exports ~ error(\"A\") + \n            trend(\"A\") + \n            season(\"A\")),\n        `WH_M` = ETS(Exports ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n  )\n\n\nfit_ETS %&gt;%\n  tidy()\n\n# A tibble: 45 × 4\n   Country       .model      term     estimate\n   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;\n 1 United States SES         alpha    0.217   \n 2 United States SES         l[0]  1336.      \n 3 United States Holt        alpha    0.108   \n 4 United States Holt        beta     0.000100\n 5 United States Holt        l[0]  1342.      \n 6 United States Holt        b[0]    14.1     \n 7 United States damped Holt alpha    0.171   \n 8 United States damped Holt beta     0.000100\n 9 United States damped Holt phi      0.980   \n10 United States damped Holt l[0]  1317.      \n# ℹ 35 more rows\n\n\n\nfit_ETS %&gt;%\n  forecast(h = \"12 months\") %&gt;%\n  autoplot(us_exports2, \n           level = NULL)\n\n\n\n\n\n\n\n\n\nfit_autoARIMA &lt;- us_exports_train %&gt;%\n  model(ARIMA(Exports))\nreport(fit_autoARIMA)\n\nSeries: Exports \nModel: ARIMA(0,1,1)(1,0,0)[12] \n\nCoefficients:\n          ma1    sar1\n      -0.7513  0.2624\ns.e.   0.0866  0.1056\n\nsigma^2 estimated as 190760:  log likelihood=-802.15\nAIC=1610.29   AICc=1610.53   BIC=1618.31\n\n\n\nus_fit &lt;- us_exports_train %&gt;%\n  model(\n    ets = ETS(Exports),\n    arima = ARIMA(Exports)\n  )\n\n\nus_fc &lt;- us_fit %&gt;%\n  forecast(h = \"12 months\")\n\n\nus_fc %&gt;%\n  autoplot(us_exports2)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#time-series-forecasting-1",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#time-series-forecasting-1",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "4.2 Time-Series Forecasting",
    "text": "4.2 Time-Series Forecasting\n\n4.2.1 Fitting Exponential Smoothing State Space (ETS) Model\nTo conduct the time-series analysis, the following code utilizes the dplyr and fable packages in R to fit multiple Exponential Smoothing State Space (ETS) models to the training dataset. The models applied include Simple Exponential Smoothing (SES), Holt’s Linear, Damped Holt’s Linear, and both Additive and Multiplicative versions of the Winter’s Holt models.\n\nPlotResultsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 5 × 10\n  Country       .model    sigma2 log_lik   AIC  AICc   BIC    MSE   AMSE     MAE\n  &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 United States SES      2.01e+5   -911. 1828. 1829. 1837. 1.97e5 2.13e5 288.   \n2 United States Holt     1.99e+5   -910. 1829. 1830. 1843. 1.92e5 2.01e5 293.   \n3 United States damped … 2.04e+5   -910. 1833. 1834. 1849. 1.95e5 2.07e5 290.   \n4 United States WH_A     1.71e+5   -895. 1824. 1830. 1869. 1.45e5 1.53e5 272.   \n5 United States WH_M     2.53e-2   -865. 1764. 1771. 1810. 1.36e5 1.45e5   0.111\n\n\n\n\n\nfit_ETS &lt;- us_exports_train %&gt;%\n  model(`SES` = ETS(Exports ~ error(\"A\") + \n                      trend(\"N\") + \n                      season(\"N\")),\n        `Holt`= ETS(Exports ~ error(\"A\") +\n                      trend(\"A\") +\n                      season(\"N\")),\n        `damped Holt` = \n          ETS(Exports ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")),\n        `WH_A` = ETS(\n          Exports ~ error(\"A\") + \n            trend(\"A\") + \n            season(\"A\")),\n        `WH_M` = ETS(Exports ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nThe trend component demonstrates a general upward trend from 2015 to 2024, implying a growth in export volumes during this period.\nThe seasonal component displays consistent patterns annually, with peaks typically occurring in 1H of each year. The amplitude of seasonal fluctuations increased from 2020.\nThe remainder component shows significant fluctuations (i.e. increased noise) after 2020, suggesting increased uncertainty or unexplained variations in export activity. This period of uncertainty coincides with major global events such as the COVID-19 pandemic and geopolitical tensions (e.g. trade war between US and China, Russo-Ukrainian War).\n\n\n\n\nfit_autoARIMA &lt;- us_exports_train %&gt;%\n  model(ARIMA(Exports))\nreport(fit_autoARIMA)\n\nSeries: Exports \nModel: ARIMA(0,1,1)(1,0,0)[12] \n\nCoefficients:\n          ma1    sar1\n      -0.7513  0.2624\ns.e.   0.0866  0.1056\n\nsigma^2 estimated as 190760:  log likelihood=-802.15\nAIC=1610.29   AICc=1610.53   BIC=1618.31\n\n\n\nus_fit &lt;- us_exports_train %&gt;%\n  model(\n    ets = ETS(Exports),\n    arima = ARIMA(Exports)\n  )\n\n\nus_fc &lt;- us_fit %&gt;%\n  forecast(h = \"12 months\")\n\n\nus_fc %&gt;%\n  autoplot(us_exports2)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#time-series-forecasting",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#time-series-forecasting",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "4.2 Time-Series Forecasting",
    "text": "4.2 Time-Series Forecasting\nTo conduct the time-series analysis, the following code utilizes the dplyr and fable packages in R to fit multiple Exponential Smoothing State Space (ETS) models to the training dataset. The models applied include Simple Exponential Smoothing (SES), Holt’s Linear, Damped Holt’s Linear, and both Additive and Multiplicative versions of the Holt-Winter’s model. Apart from the ETS Models, an ARIMA model was also integrated in the code chunk below for comparison.\n\nPlotResultsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 6 × 12\n  Country       .model  sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE     MAE\n  &lt;chr&gt;         &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 United States SES    2.01e+5   -911. 1828. 1829. 1837. 197360. 213174. 288.   \n2 United States Holt   1.99e+5   -910. 1829. 1830. 1843. 191925. 200599. 293.   \n3 United States dampe… 2.04e+5   -910. 1833. 1834. 1849. 194515. 207201. 290.   \n4 United States WH_A   1.71e+5   -895. 1824. 1830. 1869. 145431. 153018. 272.   \n5 United States WH_M   2.53e-2   -865. 1764. 1771. 1810. 136458. 145095.   0.111\n6 United States ARIMA  1.91e+5   -802. 1610. 1611. 1618.     NA      NA   NA    \n# ℹ 2 more variables: ar_roots &lt;list&gt;, ma_roots &lt;list&gt;\n\n\n\n\n\nfit_ETS_ARIMA &lt;- us_exports_train %&gt;%\n  model(`SES` = ETS(Exports ~ error(\"A\") + \n                      trend(\"N\") + \n                      season(\"N\")),\n        `Holt`= ETS(Exports ~ error(\"A\") +\n                      trend(\"A\") +\n                      season(\"N\")),\n        `damped Holt` = \n          ETS(Exports ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")),\n        `WH_A` = ETS(\n          Exports ~ error(\"A\") + \n            trend(\"A\") + \n            season(\"A\")),\n        `WH_M` = ETS(Exports ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\")),\n        `ARIMA` = ARIMA(Exports)\n  )\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nAmong all the models trained, the ARIMA(0,1,1)(1,0,0)[12] model performed the best, evidenced by it having the lowest AIC and BIC values of 1,610 and 1,618 respectively. The derived model suggests the following:\n\nThe absence of the non-seasonal AR term indicates that the model does not predict current value of the time-series based on its immediately preceding values. It suggests that the time-series might be more influenced by random fluctuations than any underlying trend in the short-term.\nThe inclusion of 1 seasonal AR term indicates that the time-series has an annual seasonal pattern.\n\nHowever, the plot shows that the forecasted values during the hold-out period of Jan 24 - Dec 24 deviate significantly from the actual export data. While the ARIMA model predicts a peak in exports in 1H 2024, the actual data revealed that the peak occurred in 2H 2024.\nThis discrepancy suggests that the ARIMA model has several limitations in forecasting future values:\n\nBoth the ETS and ARIMA models rely on past data to forecast future values, making them inherently unable to account for sudden, unexpected disruptions such as the Red Sea Crisis in 2024 which impacted trade significantly.\nThe models also assume that past patterns remain stable over time, making them less effective when long-term structural changes occur (e.g. broader economic shifts to trade protectionist policies or external shocks)."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "",
    "text": "This take home exercise requires us to:\n\nDownload Merchandise Trade by Region/Market from Department of Statistics Singapore, DOS website,\n\n\n\nSelect three data visualisation on this page, comments on the pros and cons and provide sketches of the make-over,\nUsing appropriate ggplot2 and others packages create the make-over of the three data visualisation critic above, and\nAnalyse the data with either time-series analysis or time-series forecasting methods by compliment the analysis with appropriate data visualisation methods and R packages."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#the-task",
    "href": "Take-Home Exercise/Take-Home_Ex02/Take-Home_Ex02.html#the-task",
    "title": "Take-Home Exercise 2.0: Be Tradewise or Otherwise",
    "section": "",
    "text": "This take home exercise requires us to:\n\nDownload Merchandise Trade by Region/Market from Department of Statistics Singapore, DOS website,\n\n\n\nSelect three data visualisation on this page, comments on the pros and cons and provide sketches of the make-over,\nUsing appropriate ggplot2 and others packages create the make-over of the three data visualisation critic above, and\nAnalyse the data with either time-series analysis or time-series forecasting methods by compliment the analysis with appropriate data visualisation methods and R packages."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html",
    "title": "Hands-on Exercise 8.1: Choropleth Mapping with R",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nThe code chunk below uses st_read() function of the sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature dataframe called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sherylanntys\\ISSS608\\Hands-on Exercise\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nThe code chunk below uses the read_csv() function to import respopagsex2011to2020.csv into R Studio:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\n\n\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nNote\n\n\n\nThe left_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame\n\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 8.1: Choropleth Mapping with R",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#importing-data",
    "title": "Hands-on Exercise 8.1: Choropleth Mapping with R",
    "section": "",
    "text": "The code chunk below uses st_read() function of the sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature dataframe called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sherylanntys\\ISSS608\\Hands-on Exercise\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nThe code chunk below uses the read_csv() function to import respopagsex2011to2020.csv into R Studio:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#data-preparation",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#data-preparation",
    "title": "Hands-on Exercise 8.1: Choropleth Mapping with R",
    "section": "",
    "text": "popdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nNote\n\n\n\nThe left_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame\n\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#plotting-a-choropleth-map-by-using-qtm",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#plotting-a-choropleth-map-by-using-qtm",
    "title": "Hands-on Exercise 8.1: Choropleth Mapping with R",
    "section": "2.1 Plotting a Choropleth Map by Using qtm()",
    "text": "2.1 Plotting a Choropleth Map by Using qtm()\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\nPlot ModeView Mode\n\n\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"view\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUsing the plot option will produce a static map whereas using the view option will produce an interactive map.\nThe fill argument is used to map the attribute."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex081.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 8.1: Choropleth Mapping with R",
    "section": "2.2 Creating a Choropleth Map by Using tmap’s Elements",
    "text": "2.2 Creating a Choropleth Map by Using tmap’s Elements\nUtilising tmap’s drawing elements will provide more control over the individual aesthetics layer:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n2.2.1 Drawing a Base Map\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n2.2.2 Drawing a Choropleth Map Using tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n2.2.3 Drawing a Choropleth Map Using tm_fill() and tm_border()\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1) # The alpha value defines the transparency of the borders. \n\n\n\n\n\n\n\n\n\n\n2.2.4 Data Classification Methods of tmap\n\n2.2.4.1 Plotting Choropleth Maps with Built-In Classification Methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5, # 5 classes\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe code chunk below uses the equal data classification method:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.2.4.2 Preparing Choropleth Maps with Different Classification Methods\n\nQuantileStandard DeviationK-Means\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.4.3 Preparing Choropleth Maps with Different Number of Classes\n\nN = 2N = 6N = 10\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.5 Plotting Choropleth Maps with Custom Breaks\nThe code chunk below computes and displays the descriptive statistics of the DEPENDENCY field:\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. \n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.2.6 Colour Scheme\n\n2.2.6.1 Using ColourBrewer Palette\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n2.2.7 Map Layouts\n\n2.2.7.1 Map Legends\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.2.7.2 Map Styles\nThe code chunk below uses the classic style:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n2.2.7.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n2.2.8 Drawing Small Multiple Choropleth Maps\n\n2.2.8.1 Assigning Multiple Values to At Least One of the Aesthetic Arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n2.2.8.2 By Creating Multiple Stand-Alone Maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n2.2.9 Mapping Spatial Object Meeting a Selection Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#importing-the-relevant-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#importing-the-relevant-r-packages",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#data-import-and-preparation",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#data-import-and-preparation",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "",
    "text": "The code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "",
    "text": "The code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#interactive-point-symbol-map",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#interactive-point-symbol-map",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "2.1 Interactive point symbol map",
    "text": "2.1 Interactive point symbol map\nThe code chunks below creates an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#making-it-proportional",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#making-it-proportional",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "2.2 Making it proportional",
    "text": "2.2 Making it proportional\nThe code chunks below assigns Gp1Gp2Winnings is to the size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#giving-it-different-colours",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#giving-it-different-colours",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "2.3 Giving it different colours",
    "text": "2.3 Giving it different colours\nThe code chunk below assigns OUTLET_TYPE to the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#faceted-plots",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex082.html#faceted-plots",
    "title": "Hands-on Exercise 8.2: Visualising Geospatial Point Data",
    "section": "2.4 Faceted plots",
    "text": "2.4 Faceted plots\nThe argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSwitching tmap’s Viewer back to plot mode:\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\n\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#installing-and-loading-r-packages",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#importing-data",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "",
    "text": "NGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#visualising-distribution-of-non-functional-water-points",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#visualising-distribution-of-non-functional-water-points",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "2.1 Visualising distribution of non-functional water points",
    "text": "2.1 Visualising distribution of non-functional water points\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          fill.scale = tm_scale_intervals(values = 10), \n          palette = \"brewer.blues\") + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          fill.scale = tm_scale_intervals(values = 10),\n          palette = \"brewer.blues\") + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) + \n  tm_title(\"Distribution of total water point by LGAs\") \n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "3.1 Deriving proportion of functional water points and non-functional water points",
    "text": "3.1 Deriving proportion of functional water points and non-functional water points\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#plotting-map-of-rate",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#plotting-map-of-rate",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "3.2 Plotting map of rate",
    "text": "3.2 Plotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          fill.scale = tm_scale_intervals(values = 10),\n          palette = \"brewer.blues\", \n          legend.hist = TRUE) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) + \n  tm_title(\"Rate map of functional water point by LGAs\") + \n  tm_layout(legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#percentile-map",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#percentile-map",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "4.1 Percentile map",
    "text": "4.1 Percentile map\n\n4.1.1 Data preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values.\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n4.1.2 Creating the get.var function\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n4.1.3 A percentile mapping function\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n4.1.4 Test drive the percentile mapping function\n\npercentmap(\"total_wp\", NGA_wp)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#box-map",
    "href": "Hands-on Exercise/Hands-on_Ex08/Hands-on_Ex083.html#box-map",
    "title": "Hands-on Exercise 8.3: Analytical Mapping",
    "section": "4.2 Box map",
    "text": "4.2 Box map\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n4.2.1 Creating the boxbreaks function\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n4.2.2 Creating the get.var function\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n4.2.3 Test drive the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n4.2.4 Boxmap function\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle)\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\n\n\nThe code chunk below uses read_csv() to import the network data, GAStech_email_node.csv and GAStech_email_edges-v2.csv, into R.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nThe code chunk below uses glimpse() to examine the structure of the uploaded data:\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#importing-data",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "The code chunk below uses read_csv() to import the network data, GAStech_email_node.csv and GAStech_email_edges-v2.csv, into R.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nThe code chunk below uses glimpse() to examine the structure of the uploaded data:\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "GAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#using-tbl_graph-to-build-tidygraph-data-model",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#using-tbl_graph-to-build-tidygraph-data-model",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.1 Using tbl_graph() to Build tidygraph Data Model",
    "text": "2.1 Using tbl_graph() to Build tidygraph Data Model\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-active-object",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-active-object",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.2 Changing the Active Object",
    "text": "2.2 Changing the Active Object\nUtilising tmap’s drawing elements will provide more control over the individual aesthetics layer:\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#plotting-a-basic-network-graph",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#plotting-a-basic-network-graph",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.3 Plotting a Basic Network Graph",
    "text": "2.3 Plotting a Basic Network Graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-default-network-graph-theme",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-default-network-graph-theme",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.4 Changing the Default Network Graph Theme",
    "text": "2.4 Changing the Default Network Graph Theme\ntheme_graph() is used to remove the x and y axis:\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-colouring-of-the-plot",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-colouring-of-the-plot",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.5 Changing the Colouring of the Plot",
    "text": "2.5 Changing the Colouring of the Plot\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#fruchterman-and-reingold-layout",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#fruchterman-and-reingold-layout",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.6 Fruchterman and Reingold Layout",
    "text": "2.6 Fruchterman and Reingold Layout\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#modifying-the-network-nodes",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#modifying-the-network-nodes",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.7 Modifying the Network Nodes",
    "text": "2.7 Modifying the Network Nodes\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#modifying-the-edges",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#modifying-the-edges",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "2.8 Modifying the Edges",
    "text": "2.8 Modifying the Edges\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "3.1 Working with facet_edges()",
    "text": "3.1 Working with facet_edges()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges-1",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges-1",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "3.2 Working with facet_edges()",
    "text": "3.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend:\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#a-framed-facet-graph",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#a-framed-facet-graph",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "3.3 A Framed Facet Graph",
    "text": "3.3 A Framed Facet Graph\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_nodes",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_nodes",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "3.4 Working with facet_nodes()",
    "text": "3.4 Working with facet_nodes()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#computing-centrality-indices",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#computing-centrality-indices",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "4.1 Computing Centrality Indices",
    "text": "4.1 Computing Centrality Indices\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#visualising-network-metrics",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#visualising-network-metrics",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "4.2 Visualising Network Metrics",
    "text": "4.2 Visualising Network Metrics\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#visualising-community",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#visualising-community",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "4.3 Visualising Community",
    "text": "4.3 Visualising Community\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation-1",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation-1",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "5.1 Data Preparation",
    "text": "5.1 Data Preparation\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#plotting-the-first-interactive-network-graph",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#plotting-the-first-interactive-network-graph",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "5.2 Plotting the First Interactive Network Graph",
    "text": "5.2 Plotting the First Interactive Network Graph\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#wroking-with-layout",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#wroking-with-layout",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "5.3 Wroking with Layout",
    "text": "5.3 Wroking with Layout\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---nodes",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---nodes",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "5.4 Working with Visual Attributes - Nodes",
    "text": "5.4 Working with Visual Attributes - Nodes\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---edges",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---edges",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "5.5 Working with Visual Attributes - Edges",
    "text": "5.5 Working with Visual Attributes - Edges\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#interactivity",
    "href": "Hands-on Exercise/Hands-on_Ex09/Hands-on_Ex09.html#interactivity",
    "title": "Hands-on Exercise 9.0: Modelling, Visualising and Analysing Network Data with R",
    "section": "5.6 Interactivity",
    "text": "5.6 Interactivity\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse)\n\n\n\n\n\n\nThe code chunk below uses odbcConnectAccess() to import a database query table into R:\n\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess2007('data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"data/CoffeeChain.rds\")\nodbcClose(con)\n\n\n\n\n\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#installing-and-loading-the-packages",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "",
    "text": "The following code chunk loads the required packages into R:\n\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#importing-data",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#importing-data",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "",
    "text": "The code chunk below uses odbcConnectAccess() to import a database query table into R:\n\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess2007('data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"data/CoffeeChain.rds\")\nodbcClose(con)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#data-preparation",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#data-preparation",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "",
    "text": "The code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#bullet-chart-in-ggplot2",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#bullet-chart-in-ggplot2",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "",
    "text": "The code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#preparing-the-data",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#preparing-the-data",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "2.1 Preparing the data",
    "text": "2.1 Preparing the data\n\nsales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup() %&gt;%\n  select(Month, Product, Sales)\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nmins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nquarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-in-ggplot2",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-in-ggplot2",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "2.2 Sparklines in ggplot2",
    "text": "2.2 Sparklines in ggplot2\n\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-a-simple-bullet-chart",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-a-simple-bullet-chart",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "3.1 Plotting a simple bullet chart",
    "text": "3.1 Plotting a simple bullet chart\n\nproduct %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\nProduct\ncurrent\n\n\n\n\nAmaretto\n\n\n\n   \n\n\n\nCaffe Latte\n\n\n\n   \n\n\n\nCaffe Mocha\n\n\n\n   \n\n\n\nChamomile\n\n\n\n   \n\n\n\nColombian\n\n\n\n   \n\n\n\nDarjeeling\n\n\n\n   \n\n\n\nDecaf Espresso\n\n\n\n   \n\n\n\nDecaf Irish Cream\n\n\n\n   \n\n\n\nEarl Grey\n\n\n\n   \n\n\n\nGreen Tea\n\n\n\n   \n\n\n\nLemon\n\n\n\n   \n\n\n\nMint\n\n\n\n   \n\n\n\nRegular Espresso"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-coffeechain-sales-report",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-coffeechain-sales-report",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "4.1 Plotting Coffeechain Sales report",
    "text": "4.1 Plotting Coffeechain Sales report\n\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMonthly Sales\n\n\n\n\nAmaretto\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n\n\n\n   3.7K\n\n\n\nChamomile\n\n\n\n   3.3K\n\n\n\nColombian\n\n\n\n   5.5K\n\n\n\nDarjeeling\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n\n\n\n   2.7K\n\n\n\nEarl Grey\n\n\n\n   3.0K\n\n\n\nGreen Tea\n\n\n\n   1.5K\n\n\n\nLemon\n\n\n\n   4.4K\n\n\n\nMint\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n\n\n\n   1.1K"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-statistics",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-statistics",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "4.2 Adding statistics",
    "text": "4.2 Adding statistics\nThe code chunk below calculate the summary statistics\n\nreport %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\n\n\n\n\nAmaretto\n1016\n1210\n1,119.00\n\n\nCaffe Latte\n1398\n1653\n1,528.33\n\n\nCaffe Mocha\n3322\n3828\n3,613.92\n\n\nChamomile\n2967\n3395\n3,217.42\n\n\nColombian\n5132\n5961\n5,457.25\n\n\nDarjeeling\n2926\n3281\n3,112.67\n\n\nDecaf Espresso\n3181\n3493\n3,326.83\n\n\nDecaf Irish Cream\n2463\n2901\n2,648.25\n\n\nEarl Grey\n2730\n3005\n2,841.83\n\n\nGreen Tea\n1339\n1476\n1,398.75\n\n\nLemon\n3851\n4418\n4,080.83\n\n\nMint\n1388\n1669\n1,519.17\n\n\nRegular Espresso\n890\n1218\n1,023.42"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#combining-the-data.frame",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#combining-the-data.frame",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "4.3 Combining the data.frame",
    "text": "4.3 Combining the data.frame\n\nspark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\nsales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\nsales_data = left_join(sales, spark)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-the-updated-data.table",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-the-updated-data.table",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "4.4 Plotting the updated data.table",
    "text": "4.4 Plotting the updated data.table\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#combining-bullet-chart-and-sparklines",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#combining-bullet-chart-and-sparklines",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "4.5 Combining bullet chart and sparklines",
    "text": "4.5 Combining bullet chart and sparklines\n\nbullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\nsales_data = sales_data %&gt;%\n  left_join(bullet)\n\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\nActual\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\n\n   \n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\n\n   \n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\n\n   \n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\n\n   \n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\n\n   \n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\n\n   \n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\n\n   \n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-interactive-sparklines",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#plotting-interactive-sparklines",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "5.1 Plotting interactive sparklines",
    "text": "5.1 Plotting interactive sparklines\n\nreport &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\n\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#changing-the-pagesize",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#changing-the-pagesize",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "5.2 Changing the pagesize",
    "text": "5.2 Changing the pagesize\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-points-and-labels",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-points-and-labels",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "5.3 Adding points and labels",
    "text": "5.3 Adding points and labels\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-reference-line",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-reference-line",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "5.4 Adding reference line",
    "text": "5.4 Adding reference line\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-bandline",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#adding-bandline",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "5.5 Adding bandline",
    "text": "5.5 Adding bandline\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#changing-from-sparkline-to-sparkbar",
    "href": "Hands-on Exercise/Hands-on_Ex10/Hands-on_Ex10.html#changing-from-sparkline-to-sparkbar",
    "title": "Hands-on Exercise 10.0: Information Dashboard Design: R Methods",
    "section": "5.6 Changing from sparkline to sparkbar",
    "text": "5.6 Changing from sparkline to sparkbar\n\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#loading-packages",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#loading-packages",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "2.1 Loading Packages",
    "text": "2.1 Loading Packages\n\npacman::p_load(readxl, dplyr, readr, lubridate, sf, \n               tmap, tidyverse, DT, zoo, plotly, magrittr, ggstatsplot,\n               feasts, tsibble, fable, kableExtra, dplyr, ggrepel)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#data-scraping",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#data-scraping",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "2.2 Data Scraping",
    "text": "2.2 Data Scraping\nThe dataset was sourced from the Meteorological Service Singaproe (MSS) website1, which provides extensive historical daily records of rainfall, temperature and wind speed. Covering a period from 1980 to 2025, the data is segmented by month, and by each of the 64 weather stations across Singapore. For this project, we focused on the period from 2020 to 2024. We also noted that only 44 out of the 64 stations had downloadable records.\nThe code block below initializes the data scraping process by reading a list of station codes from a CSV file and setting up a loop to download data for the specified years and months.\n\nstations_df &lt;- read_csv(\"data/StationList.csv\")  \nstation_codes &lt;- stations_df$StationID  \n\nThe main scraping loop, designed to fetch and preprocess the data, is detailed in the code block below:\n\n\n\n\n\n\nImportant\n\n\n\nThe data from January 2020 to March 2020 are encoded in latin1, while the data starting from April 2020 are encoded in UTF-8. Therefore, it is essential for the main scraping loop to be robust enough to accommodate both encodings effectively.\n\n\n\n\n\n\n\n\nExpand to See the Code Block\n\n\n\n\n\n\nyears &lt;- 2020:2024\nmonths &lt;- sprintf(\"%02d\", 1:12)\n\nbase_url &lt;- \"https://www.weather.gov.sg/files/dailydata/DAILYDATA_%s_%d%s.csv\"\n\nall_data &lt;- list()\ni &lt;- 1\n\nfor (station in station_codes) {\n  for (year in years) {\n    for (month in months) {\n      url &lt;- sprintf(base_url, station, year, month)\n      cat(\"Downloading:\", url, \"\\n\")\n      \n      # Attempt to read with latin1, if it fails, try UTF-8\n      res &lt;- try({\n        read_csv(url, locale = locale(encoding = \"latin1\"), show_col_types = FALSE)\n      }, silent = TRUE)\n      \n      if (inherits(res, \"try-error\")) {\n        res &lt;- try({\n          read_csv(url, locale = locale(encoding = \"UTF-8\"), show_col_types = FALSE)\n        }, silent = TRUE)\n      }\n\n      # If both fail, continue to the next file\n      if (inherits(res, \"try-error\")) {\n        cat(\"Failed to read:\", url, \"\\n\")\n        next\n      }\n\n      res &lt;- res %&gt;%\n        mutate(across(\n          contains(c(\"Temperature\", \"Rainfall\", \"Wind\")),\n          ~ suppressWarnings(as.numeric(.))\n        )) %&gt;%\n        mutate(\n          station = as.character(station),\n          year = as.integer(year),\n          month = as.integer(month),\n          Day = as.integer(Day)\n        )\n      \n      all_data[[i]] &lt;- res\n      i &lt;- i + 1\n    }\n  }\n}\n\n\n\n\nOnce the monthly data for each station had been downloaded, the data was subsequently consolidated into a single DataFrame:\n\n\n\n\n\n\nExpand to See the Code Block\n\n\n\n\n\n\nclimate_data &lt;- bind_rows(all_data)\n\nclimate_data &lt;- climate_data %&gt;%\n  mutate(\n    date = make_date(year, month, Day)\n  )\n\n\n\n\nAfter the data has been consolidated, the glimpse() function was used to gain a quick understanding of the data structure.\n\nglimpse(climate_data1)\n\nRows: 80,388\nColumns: 17\n$ Station                         &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Leba…\n$ Year                            &lt;dbl&gt; 2020, 2020, 2020, 2020, 2020, 2020, 20…\n$ Month                           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;dbl&gt; 0.0, 0.2, 0.0, 0.8, 0.0, 31.2, 1.8, 0.…\n$ `Highest 30 Min Rainfall (mm)`  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Highest 60 Min Rainfall (mm)`  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Highest 120 Min Rainfall (mm)` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Mean Temperature (°C)`         &lt;dbl&gt; 28.7, 28.5, 28.6, 28.0, 28.7, 27.3, 26…\n$ `Maximum Temperature (°C)`      &lt;dbl&gt; 32.3, 31.2, 32.2, 31.6, 33.2, 32.6, 30…\n$ `Minimum Temperature (°C)`      &lt;dbl&gt; 26.3, 26.4, 26.0, 25.4, 25.5, 24.0, 24…\n$ `Mean Wind Speed (km/h)`        &lt;dbl&gt; 20.2, 17.3, 18.0, 19.1, 20.2, 14.8, 15…\n$ `Max Wind Speed (km/h)`         &lt;dbl&gt; 46.4, 42.5, 46.4, 48.2, 38.9, 46.4, 44…\n$ station                         &lt;chr&gt; \"S06\", \"S06\", \"S06\", \"S06\", \"S06\", \"S0…\n$ year                            &lt;dbl&gt; 2020, 2020, 2020, 2020, 2020, 2020, 20…\n$ month                           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ date                            &lt;date&gt; 2020-01-01, 2020-01-02, 2020-01-03, 2…\n\n\nTo facilitate the development of the R Shiny application, the weather data was split into three separate datasets — rainfall, temperature, and wind speed. Each dataset contains only the relevant variables for the respective weather parameter, alongside essential metadata such as station name, date, and time components.\nBy isolating each weather component, users can independently explore trends, seasonality, and anomalies for rainfall, temperature, and wind speed. Additionally, this approach simplifies backend logic, improves processing efficiency, and avoids unnecessary overhead from unrelated columns during visualisation and analysis.\n\n\n\n\n\n\nExpand to See Code Block\n\n\n\n\n\n\nclimate_rainfall &lt;- climate_data1 %&gt;%\n  select(Station, Year, Month, Day, date, station, year, month,\n         contains(\"Rainfall\"))\n\nclimate_temperature &lt;- climate_data1 %&gt;%\n  select(Station, Year, Month, Day, date, station, year, month,\n         contains(\"Temperature\"))\n\nclimate_windspeed &lt;- climate_data1 %&gt;%\n  select(Station, Year, Month, Day, date, station, year, month,\n         contains(\"Wind\"))"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#understanding-the-data",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#understanding-the-data",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "2.3 Understanding the Data",
    "text": "2.3 Understanding the Data\n\n2.3.1 Checking for Missing Values\nIt is crucial to identify the extent of missing data, which significantly impacts the subsequent analysis phases. The following code calculates the percentage of missing values for each of the weather variable dataset.\n\n2.3.1.1 Missing Values for the Rainfall Dataset\n\n\n\n\n\n\nExpand to See the Code Block\n\n\n\n\n\n\nrainfall_missing_by_station &lt;- climate_rainfall %&gt;%\n  group_by(station) %&gt;%\n  summarise(across(\n    contains(\"Rainfall\"),\n    ~mean(is.na(.)) * 100,\n    .names = \"missing_{.col}\"\n  )) %&gt;%\n  arrange(across(starts_with(\"missing\"), desc))\n\n\n\n\n\n\n\n\n\n\nBased on the results of the missing values analysis for the rainfall dataset, all stations contain some degree of missing data. However, a few stations exhibit a significantly higher proportion of missing data, such as Station S29 - Pasir Ris (West), which has more than 10% missing rainfall data primarily concentrated in the year 2021.\nTo resolve this issue, stations with more than 5% missing data will be excluded from the analysis as a high proportion of missing values may lead to biased trends or seasonality patterns, skewed aggregate statistics or unreliable forecasts. In this case, we will exclude S29, S92, S64, S06 from the rainfall dataset as shown in the code below:\n\nclimate_rainfall_filtered &lt;- climate_rainfall %&gt;%\n  filter(!station %in% c(\"S29\", \"S92\", \"S64\", \"S06\"))\n\nFor stations with &lt;5% missing data, we employ linear interpolation to estimate the missing values. This method assumes a linear relationship (straight line) between two known data points and calculates the missing values accordingly2. This method is effective for datasets where changes between consecutive data points are expected to be gradual / linear (i.e. weather parameters).\nThe following code chunk implements linear interpolation in R using the na.approx() function from the zoo` package:\n\nclimate_rainfall_interpolated &lt;- climate_rainfall_filtered %&gt;%\n  arrange(station, date) %&gt;%\n  group_by(station) %&gt;%\n  mutate(\n    `Daily Rainfall Total (mm)`     = na.approx(`Daily Rainfall Total (mm)`, x = date, na.rm = FALSE),\n    `Highest 30 Min Rainfall (mm)`  = na.approx(`Highest 30 Min Rainfall (mm)`, x = date, na.rm = FALSE),\n    `Highest 60 Min Rainfall (mm)`  = na.approx(`Highest 60 Min Rainfall (mm)`, x = date, na.rm = FALSE),\n    `Highest 120 Min Rainfall (mm)` = na.approx(`Highest 120 Min Rainfall (mm)`, x = date, na.rm = FALSE)\n  ) %&gt;%\n  ungroup()\n\n\n\n2.3.1.2 Missing Values for the Temperature Dataset\n\n\n\n\n\n\nExpand to See the Code Block\n\n\n\n\n\n\ntemperature_missing_by_station &lt;- climate_temperature %&gt;%\n  group_by(station) %&gt;%\n  summarise(across(\n    contains(\"Temperature\"),\n    ~mean(is.na(.)) * 100,\n    .names = \"missing_{.col}\"\n  )) %&gt;%\n  arrange(across(starts_with(\"missing\"), desc))\n\n\n\n\n\n\n\n\n\n\nBased on the results of the missing values analysis for the temperature dataset, several stations exhibited 100% missing data for temperature measurements, suggesting that these stations may lack the necessary equipment to record temperature.\nIn line with the approach taken for the rainfall dataset, stations with more than 5% missing data will be excluded from the analysis. The following stations will be removed from the temperature dataset: S07, S08, S112, S113, S114, S119, S123, S29, S33, S35, S40, S64, S66, S69, S71, S77, S78, S79, S81, S84, S88, S89, S90, S92, S94, S108, S23, S80, S25 and S06.\n\nclimate_temperature_filtered &lt;- climate_temperature %&gt;%\n  filter(!station %in% c(\"S07\", \"S08\", \"S112\", \"S113\", \"S114\", \"S119\", \"S123\", \n                         \"S29\", \"S33\", \"S35\", \"S40\", \"S64\", \"S66\", \"S69\", \"S71\", \n                         \"S77\", \"S78\", \"S79\", \"S81\", \"S84\", \"S88\", \"S89\", \"S90\", \n                         \"S92\", \"S94\", \"S108\", \"S23\", \"S80\", \"S25\", \"S06\"))\n\nSimilar to the rainfall dataset, for stations with &lt;5% missing data, we employ linear interpolation to estimate the missing values.\n\nclimate_temperature_interpolated &lt;- climate_temperature_filtered %&gt;%\n  arrange(station, date) %&gt;%\n  group_by(station) %&gt;%\n  mutate(\n    `Mean Temperature (°C)`     = na.approx(`Mean Temperature (°C)`, x = date, na.rm = FALSE),\n    `Maximum Temperature (°C)`  = na.approx(`Maximum Temperature (°C)`, x = date, na.rm = FALSE),\n    `Minimum Temperature (°C)`  = na.approx(`Minimum Temperature (°C)`, x = date, na.rm = FALSE)\n  ) %&gt;%\n  ungroup()\n\n\n\n2.3.1.3 Missing Values for the Wind Speed Dataset\n\n\n\n\n\n\nExpand to See the Code Block\n\n\n\n\n\n\nwindspeed_missing_by_station &lt;- climate_windspeed %&gt;%\n  group_by(station) %&gt;%\n  summarise(across(\n    contains(\"Wind\"),\n    ~mean(is.na(.)) * 100,\n    .names = \"missing_{.col}\"\n  )) %&gt;%\n  arrange(across(starts_with(\"missing\"), desc))\n\n\n\n\n\n\n\n\n\n\nLike the temperature dataset, several stations exhibited 100% missing data for wind speed measurements. In line with the approach taken for the rainfall and temperature datasets, stations with more than 5% missing data will be excluded from the analysis. The following stations will be removed from the temperature dataset: S07, S08, S112, S113, S114, S119, S123, S29, S33, S35, S40, S64, S66, S69, S71, S77, S78, S79, S81, S84, S88, S89, S90, S92, S94, S80, S23, S60, S44, S50, S43 and S117.\n\nclimate_windspeed_filtered &lt;- climate_windspeed %&gt;%\n  filter(!station %in% c(\"S07\", \"S08\", \"S112\", \"S113\", \"S114\", \"S119\", \"S123\", \n                         \"S29\", \"S33\", \"S35\", \"S40\", \"S64\", \"S66\", \"S69\", \"S71\", \n                         \"S77\", \"S78\", \"S79\", \"S81\", \"S84\", \"S88\", \"S89\", \"S90\", \n                         \"S92\", \"S94\", \"S80\", \"S23\", \"S60\", \"S44\", \"S50\", \"S43\", \n                         \"S117\"))\n\nSimilar to the rainfall dataset, for stations with &lt;5% missing data, we employ linear interpolation to estimate the missing values.\n\nclimate_windspeed_interpolated &lt;- climate_windspeed_filtered %&gt;%\n  arrange(station, date) %&gt;%\n  group_by(station) %&gt;%\n  mutate(\n    `Mean Wind Speed (km/h)`     = na.approx(`Mean Wind Speed (km/h)`, x = date, na.rm = FALSE),\n    `Max Wind Speed (km/h)`  = na.approx(`Max Wind Speed (km/h)`, x = date, na.rm = FALSE)\n  ) %&gt;%\n  ungroup()\n\n\n\n\n2.3.2 Ensuring Date Completeness\nTo verify date completeness, we checked that each weather station contains records spanning across 1 January 2020 to 31 December 2024. This step ensures that there are no structural gaps in the time data for any station. The following were computed for each station in the respective data sets:\n\nmin_date: The earliest date available in the dataset\nmax_date: The latest date available.\ntotal_days: The number of daily records\n\nKey Findings:\n\nAll stations have consistent start and end dates, with min_date = 2020-01-01 and max_date = 2024-12-31.\n\n\n\nThe total_days column confirms that each station has a complete set of daily records (1,827 days), corresponding to 5 full years (including 2020 as a leap year).\n\n\n\nThis indicates a uniform and complete time series across all stations and parameters.\n\nThe follow sub-sections show the code chunks and corresponding results of the date completeness check for each dataset.\n\n2.3.2.1 Rainfall Dataset\n\nclimate_rainfall_interpolated %&gt;%\n  group_by(station) %&gt;%\n  summarise(min_date = min(date), max_date = max(date), total_days = n())\n\n\n\n\n\n\n\n\n\n2.3.2.2 Temperature Dataset\n\nclimate_temperature_interpolated %&gt;%\n  group_by(station) %&gt;%\n  summarise(min_date = min(date), max_date = max(date), total_days = n())\n\n\n\n\n\n\n\n\n\n2.3.2.3 Wind Speed Dataset\n\nclimate_windspeed_interpolated %&gt;%\n  group_by(station) %&gt;%\n  summarise(min_date = min(date), max_date = max(date), total_days = n())"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#footnotes",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#footnotes",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMeteorological Service Singapore. (n.d.). Historical daily records. Meteorological Service Singapore. https://www.weather.gov.sg/climate-historical-daily/↩︎↩︎\nGore, R. (2023, January). Weather parameter analysis using interpolation methods. Artificial Intelligence and Applications, 1(4). https://doi.org/10.47852/bonviewAIA3202443↩︎"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#calendar-heatmap",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#calendar-heatmap",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "3.1 Calendar Heatmap",
    "text": "3.1 Calendar Heatmap\nA calendar heatmap would be used to visualise daily weather records across different stations and years. Each day is represented as a cell in the heatmap, with colour intensity varying according to value of weather data (such as temperature or rainfall) for that day. The calendar heatmap enables quick identification of trends and / or anomalies over the course of the year.\nKey Considerations for Implementation\n\nParameter Selection: Users should be able to select the following parameters: type of weather data (rainfall, temperature, wind speed), metrics (e.g. mean temperature, max temperature), station, year.\nTooltips: A tooltip that display detailed data values when a user hovers a over specific day’s cell would be implmented. This provide instant access to precise data values, eliminating the ambiguity that may arise from solely interpreting color intensities.\nColour Intensity: The color intensity of each monthly segment varies according to specific weather data values, such as average temperature, total rainfall, or other relevant metrics. A single colour scheme is selected for each variable (e.g. temperature in shades of red, rainfall in shades of blue) to avoid confusion that comes with diverging colour schemes.\n\nFunction Objectives\nThe goal of this functionality is to provide users with a detailed visual representation of daily weather data throughout a selected year. This visualisation enables users to quickly understand day-to-day and month-to-month variations in specific weather parameters.\nGeneral Implementation Method\nWe created a function called create_calendar_heatmap, that takes in four parameters: the dataset, the selected weather station, the year of interest and the variable of interest. The heatmap colour would update depending on the dataset used.\nParameters\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndata\nType of weather variable: rainfall, temperature, wind speed\nDropdown List\n\n\nvar_type\nType of metric for the selected weather variable. For example, under temperature, users can select mean temperature, max temperature, min temperature.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_year\nThe year from which the data is drawn.\nDropdown List\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_calendar_heatmap &lt;- function(data, selected_station, selected_year, dataset_type, var_type) {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Daily Rainfall Total\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n\n  color_schemes &lt;- list(\n    \"rainfall\" = \"Blues\",\n    \"temperature\" = \"Reds\",\n    \"windspeed\" = \"Greens\"\n  )\n  \n  selected_var &lt;- var_mapping[[dataset_type]][[var_type]]\n  selected_unit &lt;- units[[dataset_type]]\n  selected_colorscale &lt;- color_schemes[[dataset_type]]\n  \n  reverse_scale &lt;- ifelse(dataset_type == \"temperature\", FALSE, TRUE)\n  \n  first_day &lt;- as.Date(sprintf(\"%d-01-01\", selected_year))\n  last_date &lt;- as.Date(sprintf(\"%d-12-31\", selected_year))\n  \n  plot_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= first_day,\n           date &lt;= last_date) %&gt;%\n    mutate(\n      weekday = wday(date, label = TRUE, abbr = TRUE, week_start = 1),\n      week_num = floor((yday(date) + wday(first_day, week_start = 1) - 1) / 7),\n      month_label = factor(month(date, label = TRUE, abbr = TRUE))\n    ) %&gt;%\n    mutate(\n      weekday = factor(weekday, \n                      levels = c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"))\n    )\n  \n  week_to_month &lt;- plot_data %&gt;%\n    group_by(week_num) %&gt;%\n    summarise(month_label = first(month_label))\n  \n  p &lt;- plot_ly(\n    data = plot_data,\n    x = ~week_num,\n    y = ~weekday,\n    z = as.formula(paste0(\"~`\", selected_var, \"`\")),\n    type = \"heatmap\",\n    colorscale = selected_colorscale,\n    reversescale = reverse_scale,\n    text = ~paste(\n      \"Date:\", date,\n      \"&lt;br&gt;Day:\", weekday,\n      \"&lt;br&gt;Month:\", month_label,\n      \"&lt;br&gt;\", var_type, \":\", round(get(selected_var), 1), selected_unit\n    ),\n    hoverinfo = \"text\",\n    hoverongaps = FALSE\n  ) %&gt;%\n    layout(\n      title = paste(var_type, \"Calendar Heatmap -\", selected_station, \"(\",selected_year,\")\"),\n      xaxis = list(\n        title = \"Month\",\n        ticktext = as.character(unique(plot_data$month_label)),\n        tickvals = sapply(unique(plot_data$month_label), \n                         function(m) median(plot_data$week_num[plot_data$month_label == m]))  \n      ),\n      yaxis = list(\n        title = \"Day of Week\",\n        categoryarray = c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"),\n        categoryorder = \"array\",\n        autorange = \"reversed\"\n      ),\n      margin = list(\n        l = 50,\n        r = 50,\n        b = 50,\n        t = 50\n      )\n    ) %&gt;%\n    colorbar(\n      title = paste(var_type, \"(\",selected_unit,\")\"),\n      orientation = \"h\",\n      len = 0.8,\n      y = -0.4,\n      thickness = 15\n    )\n  \n  return(p)\n}\n\n\n\n\nExample Usage\n\nMax Wind Speed @ Changi (2020)Daily Rainfall @ Admiralty (2022)Mean Temperature @ Clementi (2024)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#sunburst-diagram",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#sunburst-diagram",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "3.2 Sunburst Diagram",
    "text": "3.2 Sunburst Diagram\nWhile the calendar heatmap helps to display daily weather records within the context of a single year, we would also need to visualise weather patterns over multiple years in order to capture longer-term cyclical trends. To achieve this, we intend to employ sunburst diagrams. The sunburst diagram would be structured as follows:\n\nYearly Segmentation: Each concentric ring in the diagram represents a single calendar year. For instance, the innermost ring might represent the year 2020, with subsequent outer rings representing 2021, 2022, 2023, and up to 2024.\nMonthly Segmentation: Within each annual ring, the circle is further divided into 12 equal segments, each representing a month from January to December.\nColour Intensity: The color intensity of each monthly segment varies according to specific weather data values, such as average temperature, total rainfall, or other relevant metrics. A single colour scheme is selected for each variable (e.g. temperature in shades of red, rainfall in shades of blue) to avoid confusion that comes with diverging colour schemes.\nTooltips: A tooltip that display detailed data values when a user hovers a over specific day’s cell would be implemented. This provide instant access to precise data values, eliminating the ambiguity that may arise from solely interpreting color intensities.\n\nKey Considerations for Implementation\n\nData Aggregation: Given the daily granularity of our data sets, we would need to aggregate these information into monthly metrics to align with our visualisation structure. However, the aggregation must be tailored to the nature of each metric. For example, for Maximum Temperature, we should find the highest temperature recorded in the month, whereas for Mean Temperature, we should find the average temperature for the month.\n\nFunction Objectives\nThe purpose of this functionality is to enable users to visually explore and understand the cyclical and seasonal patterns in weather parameters through a radial chart.\nGeneral Implementation Method\nWe created a create_sunburst function that generates a sunburst diagram visualisation using plotly. Users can select the following parameters, and the sunburst diagram would update accordingly:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndata\nType of weather variable: rainfall, temperature, wind speed\nDropdown List\n\n\nvar_type\nType of metric for the selected variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nyear_range\nDefines the range of years over which the data should be visualised.\nCheckbox\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_sunburst &lt;- function(data, selected_station, dataset_type, var_type, year_range) {\n\n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  agg_functions &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"sum\",\n      \"Highest 30 Min Rainfall\" = \"max\",\n      \"Highest 60 Min Rainfall\" = \"min\",\n      \"Highest 120 Min Rainfall\" = \"min\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"mean\",\n      \"Maximum Temperature\" = \"max\",\n      \"Minimum Temperature\" = \"min\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"mean\",\n      \"Max Wind Speed\" = \"max\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  color_schemes &lt;- list(\n    \"rainfall\" = \"Blues\",\n    \"temperature\" = \"OrRd\",\n    \"windspeed\" = \"Greens\"\n  )\n  \n  selected_var &lt;- var_mapping[[dataset_type]][[var_type]]\n  selected_unit &lt;- units[[dataset_type]]\n  selected_colorscale &lt;- color_schemes[[dataset_type]]\n  selected_agg &lt;- agg_functions[[dataset_type]][[var_type]]\n  \n  reverse_scale &lt;- ifelse(dataset_type == \"temperature\", FALSE, TRUE)\n  \n  plot_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           Year &gt;= year_range[1],\n           Year &lt;= year_range[2]) %&gt;%\n    group_by(Year, Month) %&gt;%\n    summarise(\n      Value = case_when(\n        selected_agg == \"mean\" ~ mean(get(selected_var), na.rm = TRUE),\n        selected_agg == \"max\" ~ max(get(selected_var), na.rm = TRUE),\n        selected_agg == \"min\" ~ min(get(selected_var), na.rm = TRUE),\n        selected_agg == \"sum\" ~ sum(get(selected_var), na.rm = TRUE)\n      ),\n      .groups = 'drop'\n    )\n  \n\n  p &lt;- plot_ly()\n  \n\n  years &lt;- year_range[1]:year_range[2]\n  months &lt;- 1:12\n  angles &lt;- seq(0, 330, by = 30)\n  \n  for(i in seq_along(years)) {\n    year &lt;- years[i]\n    radius &lt;- i\n    \n    year_data &lt;- plot_data %&gt;% filter(Year == year)\n    \n    vals &lt;- sapply(months, function(m) {\n      val &lt;- year_data$Value[year_data$Month == m]\n      if(length(val) == 0) return(0)\n      return(val)\n    })\n    \n    p &lt;- p %&gt;% add_trace(\n      type = \"barpolar\",\n      r = rep(1, 12),\n      theta = angles,\n      base = radius - 0.45,\n      width = 29,\n      marker = list(\n        color = vals,\n        colorscale = selected_colorscale,\n        reversescale = reverse_scale,\n        showscale = (i == 1),\n        colorbar = list(\n          title = paste(var_type, \"(\", selected_unit, \")\"),\n          len = 0.5,         \n          thickness = 10,   \n          x = 0.95,         \n          y = 0.5,          \n          tickfont = list(size = 10),  \n          titlefont = list(size = 10)  \n        ),\n        line = list(\n          color = 'white',\n          width = 2\n        )\n      ),\n      name = as.character(year),\n      text = paste0(\n        \"Year: \", year, \"&lt;br&gt;\",\n        \"Month: \", month.abb, \"&lt;br&gt;\",\n        var_type, \": \", round(vals, 1), \" \", selected_unit\n      ),\n      hoverinfo = \"text\"\n    )\n  }\n  \n\n  p &lt;- p %&gt;% layout(\n    polar = list(\n      radialaxis = list(\n        visible = FALSE,\n        range = c(0, length(years) + 1),\n        showline = FALSE,\n        showgrid = FALSE\n      ),\n      angularaxis = list(\n        ticktext = month.abb,\n        tickvals = angles,\n        direction = \"clockwise\",\n        showline = FALSE,\n        showgrid = FALSE\n      ),\n      bgcolor = \"white\"\n    ),\n    title = list(\n      text = paste(var_type, \"Patterns -\", selected_station, \n                  \"(\", year_range[1], \"-\", year_range[2], \")\"),\n      y = 0.95,\n      pad = list(b = 20)\n    ),\n    margin = list(\n      t = 100\n    ),\n    showlegend = FALSE,\n    paper_bgcolor = \"white\",\n    plot_bgcolor = \"white\"\n  )\n  \n  return(p)\n}\n\n\n\n\nExample Usage\n\nMean Temperature @ Pasir Panjang (2020-2024)Total Rainfall @ Tai Seng (2021-2022)Max Wind Speed @ Seletar (2021-2024)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#line-chart",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#line-chart",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "3.3 Line Chart",
    "text": "3.3 Line Chart\nLine charts may be used to visualise time-series data across multiple weather stations. This visualisation facilitates the comparison of weather trends / patterns over a continuous period.This function enables users to compare temporal variables.\nFunction Objectives\nThe purpose of this functionality is to provide users with a dynamic and detailed visualization of weather parameter trends across multiple stations within a specified date range.\nGeneral Implementation method\nWe developed a function named create_line_chart, using plotly.\n\nTooltips: A tooltip that display detailed data values when a user hovers a over specific day’s point on the line chart would be implemented. This provide instant access to precise data values, eliminating the ambiguity.\n\nUsers can also select the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndata\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn. Users can select multiple stations for comparison.\nCheckbox\n\n\nvar_type\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\ndate_range\nDefines the range of dateover which the data should be visualised.\nInput boxes for start date and end date\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_line_chart &lt;- function(data, selected_stations, dataset_type, var_type, date_range) {\n\n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  agg_functions &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"sum\",\n      \"Highest 30 Min Rainfall\" = \"max\",\n      \"Highest 60 Min Rainfall\" = \"min\",\n      \"Highest 120 Min Rainfall\" = \"min\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"mean\",\n      \"Maximum Temperature\" = \"max\",\n      \"Minimum Temperature\" = \"min\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"mean\",\n      \"Max Wind Speed\" = \"max\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  selected_var &lt;- var_mapping[[dataset_type]][[var_type]]\n  selected_unit &lt;- units[[dataset_type]]\n  selected_agg &lt;- agg_functions[[dataset_type]][[var_type]]\n  \n  plot_data &lt;- data %&gt;%\n    filter(Station %in% selected_stations,\n           date &gt;= as.Date(date_range[1]),\n           date &lt;= as.Date(date_range[2])) %&gt;%\n    group_by(Station, Year = year(date), Month = month(date)) %&gt;%\n    summarise(\n      Value = case_when(\n        selected_agg == \"mean\" ~ mean(get(selected_var), na.rm = TRUE),\n        selected_agg == \"max\" ~ max(get(selected_var), na.rm = TRUE),\n        selected_agg == \"min\" ~ min(get(selected_var), na.rm = TRUE),\n        selected_agg == \"sum\" ~ sum(get(selected_var), na.rm = TRUE)\n      ),\n      .groups = 'drop'\n    ) %&gt;%\n    mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\"))) %&gt;%\n    arrange(Station, Date)\n  \n  colors &lt;- RColorBrewer::brewer.pal(12, \"Dark2\")[1:length(selected_stations)]\n  \n  if(length(selected_stations) &gt; 12) {\n    colors &lt;- rep(colors, ceiling(length(selected_stations)/12))[1:length(selected_stations)]\n  }\n  \n  p &lt;- plot_ly() %&gt;%\n    layout(\n      xaxis = list(\n        title = \"\",\n        tickformat = \"%b %Y\",\n        tickangle = 45,\n        range = c(as.Date(date_range[1]), as.Date(date_range[2]))\n      ),\n      yaxis = list(\n        title = paste(var_type, \"(\", selected_unit, \")\")\n      ),\n      title = list(\n        text = paste(var_type, \"Trends by Station\"),\n        y = 0.95\n      ),\n      hovermode = \"x unified\",\n      showlegend = TRUE,\n      legend = list(\n        title = list(\n          text = \"Stations\"\n        ),\n        x = 1.02,\n        y = 1,\n        xanchor = \"left\",\n        font = list(\n          size = 10\n        ),\n        itemsizing = \"constant\"\n      ),\n      margin = list(\n        l = 50,\n        r = 150,\n        t = 50,\n        b = 100\n      )\n    )\n  \n  for(i in seq_along(selected_stations)) {\n    station_data &lt;- plot_data %&gt;% filter(Station == selected_stations[i])\n    \n    p &lt;- p %&gt;% add_trace(\n      data = station_data,\n      x = ~Date,\n      y = ~Value,\n      type = 'scatter',\n      mode = 'lines',\n      line = list(\n        color = colors[i],\n        width = 2\n      ),\n      hovertemplate = paste(\n        \"Station: %{fullData.name}&lt;br&gt;\",\n        \"Month: %{x|%b %Y}&lt;br&gt;\",\n        paste(var_type, \": %{y:.1f}\", selected_unit),\n        \"&lt;extra&gt;&lt;/extra&gt;\"\n      ),\n      name = selected_stations[i]\n    )\n  }\n  \n  return(p)\n}\n\n\n\n\nExample Usage\n\nMean Temperature @ Admiralty, Changi, Ang Mo Kio (2020 - 2024)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#stl-decomposition",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#stl-decomposition",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "3.4 STL Decomposition",
    "text": "3.4 STL Decomposition\nWe planned to include a STL Decomposition function in our Shiny application,decomposes time-series data into seasonal, trend, and residual components. While the initial EDA tools implemented is used primarily for initial data exploration (helping to uncover patterns, trends, and anomalies in a visually intuitive manner), STL decomposition visusalises a structural separation of components, allowing users to understand:\n\nUnderlying patterns explicitly\nWhich patterns in the data are predictable (trend and seasonal) and which are not (residual).\n\nBy understanding each component of the time series data, users can identify and shortlist the model required for time-series forecasting.\nFunction Objectives\nThe goal of this function is to empower users to decompose their selected time series data into its fundamental components in order to enhance user comprehension of the data, in preparation for advanced statistical modelling / forecasting.\nGeneral Implementation Method\nWe developed a function named create_ts_decomposition, using STL.\nUsers can also select the following parameters and the charts would be generated accordingly:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nCheckbox\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\ndate_range\nDefines the range of dateover which the data should be visualised.\nInput boxes for start date and end date\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_ts_decomposition &lt;- function(dataset_type,\n                                  selected_station,\n                                  selected_var,\n                                  date_range = c(\"2020-01-01\", \"2024-12-31\")) {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  data &lt;- switch(dataset_type,\n                 \"rainfall\" = climate_rainfall_interpolated,\n                 \"temperature\" = climate_temperature_interpolated,\n                 \"windspeed\" = climate_windspeed_interpolated,\n                 stop(\"Invalid dataset type\"))\n  \n  start_date &lt;- as.Date(date_range[1])\n  end_date &lt;- as.Date(date_range[2])\n  \n  months_diff &lt;- length(seq(start_date, end_date, by = \"month\"))\n  \n  message(\"Date range: \", start_date, \" to \", end_date)\n  message(\"Number of months in range: \", months_diff)\n  \n  ts_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= start_date,\n           date &lt;= end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date)\n    ) %&gt;%\n    group_by(year_month) %&gt;%\n    summarise(\n      Value = mean(Value, na.rm = TRUE),\n      .groups = 'drop'\n    ) %&gt;%\n    as_tsibble(index = year_month) %&gt;%\n    fill_gaps()\n  \n  message(\"Number of observations in dataset: \", nrow(ts_data))\n  \n  if (nrow(ts_data) &lt; 24) {\n    stop(\"Not enough data for decomposition. Need at least 24 months of data. Current months: \", nrow(ts_data))\n  }\n  \n  title &lt;- paste(selected_var, \"Time Series Decomposition at\", selected_station,\n                \"\\nPeriod:\", format(start_date, \"%b %Y\"), \n                \"to\", format(end_date, \"%b %Y\"))\n  \n  decomp_plot &lt;- ts_data %&gt;%\n    model(\n      stl = STL(Value ~ season(period = 12) + trend())\n    ) %&gt;%\n    components() %&gt;%\n    autoplot() +\n    theme_bw() +\n    labs(\n      title = title,\n      x = \"Period\",\n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\"),\n      season_year = \"Seasonal Pattern\",\n      trend = \"Trend\",\n      remainder = \"Random\"\n    ) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9),\n      legend.position = \"none\"\n    )\n  \n  return(decomp_plot)\n}\n\n\n\n\nExample Usage\n\nMean Wind Speed @ Changi (2020 - 2023)Total Rainfall @ Changi (2020 - 2022)Mean Wind Speed @ Changi (2020 - 2024)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-using-different-models",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-using-different-models",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.1 Time-Series Forecasting Using Different Models",
    "text": "5.1 Time-Series Forecasting Using Different Models\nAfter gaining an understanding of the time-series data via the EDA tools in Section 3.0, users can use the time-series forcasting tool to forecast weather parameters using various statistical models.\nFunction Objective\nThe goal of this functionality is to empower users to not only generate but also compare forecasts from multiple models, thereby identifying the most accurate predictive model for their specific context.\nGeneral Implementation Method\nWe developed a function, create_forecast, that users can interact with to perform weather forecasts based on historical data, using forecast() of fable. Users can select and interact with the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nmodels\nUsers can choose from a range of models, including SES, Holt, Damped Hold, Holt-Winters (additive and multiplicative), and ARIMA.\nCheckbox\n\n\ntraining_start, training_end, holdout_end\nUsers can specify training and holdout periods.\nInput fields.\n\n\n\nThe function outputs an interactive plot that visually compares the forecasted data against actual data. Users can hover over the line chart for more details on the data value. A reference line was added in the plot to allow users to know when the holdout period starts. The function also outputs a table that displays forecasting accuracy metrics such as AIC, BIC, and AICc. These plots are generated using ggplotly.\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_forecast &lt;- function(dataset_type,\n                          selected_station,\n                          selected_var,\n                          training_start = \"2020-01-01\",\n                          training_end = \"2023-12-31\",\n                          holdout_end = \"2024-12-31\",\n                          models = c(\"SES\", \"Holt\", \"Damped Holt\", \"Winter-Add\", \"Winter-Mult\", \"ARIMA\")) {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  data &lt;- switch(dataset_type,\n                 \"rainfall\" = climate_rainfall_interpolated,\n                 \"temperature\" = climate_temperature_interpolated,\n                 \"windspeed\" = climate_windspeed_interpolated,\n                 stop(\"Invalid dataset type\"))\n  \n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  holdout_end_date &lt;- as.Date(holdout_end)\n  \n  horizon &lt;- length(seq(training_end_date, holdout_end_date, by = \"month\")) - 1\n  \n  message(\"Training period: \", training_start_date, \" to \", training_end_date)\n  message(\"Holdout period end: \", holdout_end_date)\n  message(\"Forecast horizon (months): \", horizon)\n\n  ts_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= training_start_date,\n           date &lt;= holdout_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date),\n      Type = if_else(date &lt;= training_end_date, \"Training\", \"Hold-out\")\n    ) %&gt;%\n    group_by(year_month) %&gt;%\n    summarise(\n      Value = mean(Value, na.rm = TRUE),\n      Type = first(Type),\n      .groups = 'drop'\n    ) %&gt;%\n    as_tsibble(index = year_month) %&gt;%\n    fill_gaps()\n  \n  training_data &lt;- ts_data %&gt;%\n    filter(Type == \"Training\")\n  \n  model_spec &lt;- list()\n  \n  if (\"SES\" %in% models) {\n    model_spec$SES &lt;- ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\"))\n  }\n  if (\"Holt\" %in% models) {\n    model_spec$Holt &lt;- ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  }\n  if (\"Damped Holt\" %in% models) {\n    model_spec$`Damped Holt` &lt;- ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\"))\n  }\n  if (\"Winter-Add\" %in% models) {\n    model_spec$`Winter-Add` &lt;- ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\"))\n  }\n  if (\"Winter-Mult\" %in% models) {\n    model_spec$`Winter-Mult` &lt;- ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\"))\n  }\n  if (\"ARIMA\" %in% models) {\n    model_spec$ARIMA &lt;- ARIMA(Value)\n  }\n  \n  fit_models &lt;- training_data %&gt;%\n    model(!!!model_spec)\n  \n  forecast_data &lt;- fit_models %&gt;%\n    forecast(h = paste(horizon, \"months\"))\n  \n  base_plot &lt;- forecast_data %&gt;%\n    autoplot(ts_data, level = NULL) +\n    theme_light() +\n    geom_vline(xintercept = yearmonth(training_end_date +days(1)), \n               linetype = \"dashed\", \n               color = \"grey50\") +\n    labs(\n      title = paste(\"Forecast for\", selected_var, \"at\", selected_station),\n      subtitle = paste(\"Training:\", format(training_start_date, \"%b %Y\"),\n                      \"to\", format(training_end_date, \"%b %Y\"),\n                      \"| Holdout:\", format(holdout_end_date, \"%b %Y\")),\n      x = \"Period\",\n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\")\n    ) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9)\n    )\n  \n  forecast_plot &lt;- ggplotly(base_plot, tooltip = c(\"x\", \"y\", \".model\")) %&gt;%\n    layout(\n      hoverlabel = list(bgcolor = \"white\"),\n      showlegend = TRUE,\n      legend = list(title = list(text = \"Models\"))\n    )\n  \n  for(i in 1:length(forecast_plot$x$data)) {\n    forecast_plot$x$data[[i]]$text &lt;- format(as.Date(forecast_plot$x$data[[i]]$x), \"%b %Y\")\n    forecast_plot$x$data[[i]]$hovertemplate &lt;- paste(\n      \"%{text}&lt;br&gt;\",\n      \"Value: %{y:.1f}\", units[[dataset_type]], \"&lt;br&gt;\",\n      \"Model: \", forecast_plot$x$data[[i]]$name, \"&lt;br&gt;\",\n      \"&lt;extra&gt;&lt;/extra&gt;\"\n    )\n  }\n  \n  accuracy_table &lt;- fit_models %&gt;%\n    report() %&gt;%\n    select(.model, AIC, BIC, AICc) %&gt;%\n    rename(Model = .model) %&gt;%\n    kable(\n      caption = \"Model Accuracy Metrics\",\n      format = \"html\",\n      digits = 2\n    ) %&gt;%\n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n      full_width = FALSE\n    )\n  \n  return(list(\n    plot = forecast_plot,\n    table = accuracy_table\n  ))\n}\n\n\n\n\n\nMean Temperature @ Changi (Training: 2020 - 2023, Forecast: 2024)Total Rain @ Changi (Training: 2020 - 2023, Forecast: 2024 - 2025)Mean Wind Speed @ Changi (Training: 2020 - 2022, Forecast: 2023)\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nAIC\nBIC\nAICc\n\n\n\n\nSES\n148.34\n153.95\n148.88\n\n\nHolt\n152.38\n161.73\n153.80\n\n\nWinter-Add\n128.04\n159.85\n148.44\n\n\nARIMA\n61.68\n68.02\n62.97\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nAIC\nBIC\nAICc\n\n\n\n\nWinter-Add\n329.72\n361.53\n350.12\n\n\nWinter-Mult\n311.56\n343.37\n331.96\n\n\nARIMA\n258.75\n262.49\n259.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nAIC\nBIC\nAICc\n\n\n\n\nSES\n170.08\n174.83\n170.83\n\n\nHolt\n174.00\n181.92\n176.00\n\n\nARIMA\n76.63\n78.99\n77.20"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-comparing-across-models",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-comparing-across-models",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.2 Time-Series Forecasting: Comparing Across Models",
    "text": "5.2 Time-Series Forecasting: Comparing Across Models\nAfter gaining an understanding of the time-series data via the EDA tools in Section 3.0, users can use the time-series forcasting tool to forecast weather parameters using various statistical models.\nFunction Objective\nThe goal of this functionality is to empower users to not only generate but also compare forecasts from multiple models, thereby identifying the most accurate predictive model for their specific context.\nGeneral Implementation Method\nWe developed a function, create_forecast, that users can interact with to perform weather forecasts based on historical data, using forecast() of fable. Users can select and interact with the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nmodels\nUsers can choose from a range of models, including SES, Holt, Damped Hold, Holt-Winters (additive and multiplicative), and ARIMA.\nCheckbox\n\n\ntraining_start, training_end, holdout_end\nUsers can specify training and holdout periods.\nInput fields.\n\n\n\nThe function outputs an interactive plot that visually compares the forecasted data against actual data. Users can hover over the line chart for more details on the data value. A reference line was added in the plot to allow users to know when the holdout period starts. The function also outputs a table that displays forecasting accuracy metrics such as AIC, BIC, and AICc. These plots are generated using ggplotly.\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_forecast &lt;- function(dataset_type,\n                          selected_station,\n                          selected_var,\n                          training_start = \"2020-01-01\",\n                          training_end = \"2023-12-31\",\n                          holdout_end = \"2024-12-31\",\n                          models = c(\"SES\", \"Holt\", \"Damped Holt\", \"Winter-Add\", \"Winter-Mult\", \"ARIMA\")) {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  data &lt;- switch(dataset_type,\n                 \"rainfall\" = climate_rainfall_interpolated,\n                 \"temperature\" = climate_temperature_interpolated,\n                 \"windspeed\" = climate_windspeed_interpolated,\n                 stop(\"Invalid dataset type\"))\n  \n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  holdout_end_date &lt;- as.Date(holdout_end)\n  \n  horizon &lt;- length(seq(training_end_date, holdout_end_date, by = \"month\")) - 1\n  \n  message(\"Training period: \", training_start_date, \" to \", training_end_date)\n  message(\"Holdout period end: \", holdout_end_date)\n  message(\"Forecast horizon (months): \", horizon)\n\n  ts_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= training_start_date,\n           date &lt;= holdout_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date),\n      Type = if_else(date &lt;= training_end_date, \"Training\", \"Hold-out\")\n    ) %&gt;%\n    group_by(year_month) %&gt;%\n    summarise(\n      Value = mean(Value, na.rm = TRUE),\n      Type = first(Type),\n      .groups = 'drop'\n    ) %&gt;%\n    as_tsibble(index = year_month) %&gt;%\n    fill_gaps()\n  \n  training_data &lt;- ts_data %&gt;%\n    filter(Type == \"Training\")\n  \n  model_spec &lt;- list()\n  \n  if (\"SES\" %in% models) {\n    model_spec$SES &lt;- ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\"))\n  }\n  if (\"Holt\" %in% models) {\n    model_spec$Holt &lt;- ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  }\n  if (\"Damped Holt\" %in% models) {\n    model_spec$`Damped Holt` &lt;- ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\"))\n  }\n  if (\"Winter-Add\" %in% models) {\n    model_spec$`Winter-Add` &lt;- ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\"))\n  }\n  if (\"Winter-Mult\" %in% models) {\n    model_spec$`Winter-Mult` &lt;- ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\"))\n  }\n  if (\"ARIMA\" %in% models) {\n    model_spec$ARIMA &lt;- ARIMA(Value)\n  }\n  \n  fit_models &lt;- training_data %&gt;%\n    model(!!!model_spec)\n  \n  forecast_data &lt;- fit_models %&gt;%\n    forecast(h = paste(horizon, \"months\"))\n  \n  base_plot &lt;- forecast_data %&gt;%\n    autoplot(ts_data, level = NULL) +\n    theme_light() +\n    geom_vline(xintercept = yearmonth(training_end_date +days(1)), \n               linetype = \"dashed\", \n               color = \"grey50\") +\n    labs(\n      title = paste(\"Forecast for\", selected_var, \"at\", selected_station),\n      subtitle = paste(\"Training:\", format(training_start_date, \"%b %Y\"),\n                      \"to\", format(training_end_date, \"%b %Y\"),\n                      \"| Holdout:\", format(holdout_end_date, \"%b %Y\")),\n      x = \"Period\",\n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\")\n    ) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9)\n    )\n  \n  forecast_plot &lt;- ggplotly(base_plot, tooltip = c(\"x\", \"y\", \".model\")) %&gt;%\n    layout(\n      hoverlabel = list(bgcolor = \"white\"),\n      showlegend = TRUE,\n      legend = list(title = list(text = \"Models\"))\n    )\n  \n  for(i in 1:length(forecast_plot$x$data)) {\n    forecast_plot$x$data[[i]]$text &lt;- format(as.Date(forecast_plot$x$data[[i]]$x), \"%b %Y\")\n    forecast_plot$x$data[[i]]$hovertemplate &lt;- paste(\n      \"%{text}&lt;br&gt;\",\n      \"Value: %{y:.1f}\", units[[dataset_type]], \"&lt;br&gt;\",\n      \"Model: \", forecast_plot$x$data[[i]]$name, \"&lt;br&gt;\",\n      \"&lt;extra&gt;&lt;/extra&gt;\"\n    )\n  }\n  \n  accuracy_table &lt;- fit_models %&gt;%\n    accuracy() %&gt;%\n    select(.model, ME, RMSE, MAE, MPE, MAPE, MASE, RMSSE) %&gt;%\n    rename(\n      Model = .model,\n      \"Mean Error\" = ME,\n      \"Root Mean Square Error\" = RMSE,\n      \"Mean Absolute Error\" = MAE,\n      \"Mean Percentage Error\" = MPE,\n      \"Mean Absolute Percentage Error\" = MAPE,\n      \"Mean Absolute Scaled Error\" = MASE,\n      \"Root Mean Square Scaled Error\" = RMSSE\n    ) %&gt;%\n    kable(\n      caption = \"Model Accuracy Metrics\",\n      format = \"html\",\n      digits = 2\n    ) %&gt;%\n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n      full_width = FALSE\n    )\n  \n  return(list(\n    plot = forecast_plot,\n    table = accuracy_table\n  ))\n}\n\n\n\n\nExample Usage\n\nMean Temperature @ Changi (Training: 2020 - 2023, Forecast: 2024)Total Rain @ Changi (Training: 2020 - 2023, Forecast: 2024 - 2025)Mean Wind Speed @ Changi (Training: 2020 - 2022, Forecast: 2023)\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nSES\n-0.01\n0.64\n0.51\n-0.06\n1.83\n0.86\n0.89\n\n\nHolt\n0.00\n0.64\n0.51\n-0.02\n1.83\n0.86\n0.89\n\n\nWinter-Add\n-0.03\n0.38\n0.33\n-0.12\n1.19\n0.56\n0.54\n\n\nARIMA\n0.00\n0.40\n0.28\n-0.01\n1.01\n0.47\n0.55\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nWinter-Add\n0.06\n3.14\n2.31\n-283.72\n309.02\n0.63\n0.56\n\n\nWinter-Mult\n-0.62\n3.49\n2.39\n-616.32\n635.16\n0.65\n0.62\n\n\nARIMA\n0.00\n3.44\n2.47\n-390.88\n413.82\n0.67\n0.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nSES\n-0.09\n1.63\n1.37\n-2.71\n16.53\n1.43\n1.29\n\n\nHolt\n0.01\n1.63\n1.36\n-1.55\n16.39\n1.43\n1.29\n\n\nARIMA\n0.00\n0.90\n0.58\n-0.11\n7.05\n0.60\n0.71"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-comparing-across-multiple-stations",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-comparing-across-multiple-stations",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.2 Time-Series Forecasting: Comparing Across Multiple Stations",
    "text": "5.2 Time-Series Forecasting: Comparing Across Multiple Stations\n\ncreate_station_forecast &lt;- function(dataset_type,\n                                  selected_stations,\n                                  selected_var,\n                                  selected_model,\n                                  training_start = \"2020-01-01\",\n                                  training_end = \"2023-12-31\",\n                                  holdout_end = \"2024-12-31\") {\n  \n  # Basic setup\n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  # Get data\n  data &lt;- switch(dataset_type,\n                 \"rainfall\" = climate_rainfall_interpolated,\n                 \"temperature\" = climate_temperature_interpolated,\n                 \"windspeed\" = climate_windspeed_interpolated,\n                 stop(\"Invalid dataset type\"))\n  \n  # Process dates\n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  holdout_end_date &lt;- as.Date(holdout_end)\n  horizon &lt;- length(seq(training_end_date, holdout_end_date, by = \"month\")) - 1\n  \n  # Prepare data\n  ts_data &lt;- data %&gt;%\n    filter(Station %in% selected_stations,\n           date &gt;= training_start_date,\n           date &lt;= holdout_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date),\n      Station = factor(Station, levels = selected_stations)\n    ) %&gt;%\n    group_by(Station, year_month) %&gt;%\n    summarise(\n      Value = mean(Value, na.rm = TRUE),\n      .groups = 'drop'\n    ) %&gt;%\n    as_tsibble(index = year_month, key = Station) %&gt;%\n    fill_gaps()\n  \n  # Split training data\n  training_data &lt;- ts_data %&gt;%\n    filter(year_month &lt;= yearmonth(training_end_date))\n  \n  # Create model\n  model_spec &lt;- switch(selected_model,\n    \"SES\" = ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\")),\n    \"Holt\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n    \"Damped Holt\" = ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\")),\n    \"Winter-Add\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\")),\n    \"Winter-Mult\" = ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n    \"ARIMA\" = ARIMA(Value),\n    stop(\"Invalid model type\")\n  )\n  \n  # Fit model and forecast\n  fit_models &lt;- training_data %&gt;%\n    model(!!selected_model := model_spec)\n  \n  forecast_data &lt;- fit_models %&gt;%\n    forecast(h = horizon)\n  \n  # Create plot using autoplot\n  forecast_plot &lt;- forecast_data %&gt;%\n    autoplot(ts_data) +\n    geom_vline(xintercept = as.numeric(yearmonth(training_end_date)),\n               linetype = \"dashed\",\n               color = \"grey50\") +\n    # Try different faceting approaches\n    facet_grid(vars(Station), scales = \"free_y\", \n               labeller = label_both) +  # This should force labels to show\n    # Alternative approach if above doesn't work:\n    # facet_grid(Station ~ ., scales = \"free_y\",\n    #            labeller = as_labeller(function(x) paste(\"Station:\", x))) +\n    labs(\n      title = paste(\"Forecast for\", selected_var, \"using\", selected_model),\n      subtitle = paste(\"Training:\", format(training_start_date, \"%b %Y\"),\n                      \"to\", format(training_end_date, \"%b %Y\"),\n                      \"| Holdout:\", format(holdout_end_date, \"%b %Y\")),\n      x = \"Period\",\n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\")\n    ) +\n    theme_light() +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      plot.subtitle = element_text(size = 10),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9),\n      strip.text = element_text(size = 11, face = \"bold\"),\n      strip.background = element_rect(\n        fill = \"white\",\n        color = \"black\",\n        size = 0.5\n      ),\n      panel.spacing = unit(1.5, \"lines\")\n    )\n\n  # Debug print to check data structure\n  print(\"Checking data structure:\")\n  print(head(ts_data))\n  print(head(forecast_data))\n  \n  # Create accuracy table\n  accuracy_table &lt;- fit_models %&gt;%\n    accuracy() %&gt;%\n    select(Station, .model, RMSE, MAE, MAPE) %&gt;%\n    rename(\n      Model = .model,\n      \"Root Mean Square Error\" = RMSE,\n      \"Mean Absolute Error\" = MAE,\n      \"Mean Absolute Percentage Error\" = MAPE\n    ) %&gt;%\n    kable(\n      caption = \"Model Accuracy Metrics by Station\",\n      format = \"html\",\n      digits = 2\n    ) %&gt;%\n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n      full_width = FALSE\n    )\n  \n  return(list(\n    plot = forecast_plot,\n    table = accuracy_table\n  ))\n}\n\n\nstation_forecast &lt;- create_station_forecast(\n  dataset_type = \"temperature\",\n  selected_stations = c(\"Changi\", \"Admiralty\", \"Ang Mo Kio\"),\n  selected_var = \"Mean Temperature\",\n  selected_model = \"Winter-Add\"\n)\n\n[1] \"Checking data structure:\"\n# A tsibble: 6 x 3 [1M]\n# Key:       Station [1]\n  Station year_month Value\n  &lt;fct&gt;        &lt;mth&gt; &lt;dbl&gt;\n1 Changi    2020 Jan  27.7\n2 Changi    2020 Feb  27.9\n3 Changi    2020 Mar  28.6\n4 Changi    2020 Apr  28.8\n5 Changi    2020 May  28.9\n6 Changi    2020 Jun  28.1\n# A fable: 6 x 5 [1M]\n# Key:     Station, .model [1]\n  Station .model     year_month\n  &lt;fct&gt;   &lt;chr&gt;           &lt;mth&gt;\n1 Changi  Winter-Add   2024 Jan\n2 Changi  Winter-Add   2024 Feb\n3 Changi  Winter-Add   2024 Mar\n4 Changi  Winter-Add   2024 Apr\n5 Changi  Winter-Add   2024 May\n6 Changi  Winter-Add   2024 Jun\n# ℹ 2 more variables: Value &lt;dist&gt;, .mean &lt;dbl&gt;\n\n# Display results\nstation_forecast$plot"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#proposed-user-journey",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#proposed-user-journey",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "6.1 Proposed User Journey",
    "text": "6.1 Proposed User Journey"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#home-page",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#home-page",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "6.2 Home Page",
    "text": "6.2 Home Page"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#exploratory-data-analysis-1",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#exploratory-data-analysis-1",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "6.3 Exploratory Data Analysis",
    "text": "6.3 Exploratory Data Analysis"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "6.4 Time-Series Forecasting",
    "text": "6.4 Time-Series Forecasting"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "",
    "text": "Singapore’s climate has been experiencing rising temperatures and increasing weather extremes driven by climate change and urbanisation. In 2024, Singapore experienced one of its hottest years on record, with temperatures exceeding long-term averages. These climate trends pose significant risks, including heat stress, water resource management challenges and urban planning concerns.\n\nExisting reports and tools offer real-time weather forecasts and historical comparisons using long-term averages. However, they lack interactive analysis tools that would allow for a deeper exploration of historical trends and future projections.\nThis report covers the prototypes that were developed for inclusion in the Weather Pulse application."
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-model-assumptions",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-model-assumptions",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.1 Time-Series Forecasting: Model Assumptions",
    "text": "5.1 Time-Series Forecasting: Model Assumptions\nBefore users begin forecasting the various weather parameters, we created a create_model_diagnostics function to assist in validating the assumptions of the time-series models by visualising the residuals. These diagnostics are crucial for ensuring that the model fits the data appropriately and that the forecasts it produces are reliable. The function handles different types of weather data—rainfall, temperature, and windspeed—and supports several model types including Simple Exponential Smoothing (SES), Holt’s linear trend method, Holt-Winters seasonal methods, and ARIMA.\nThe diagnostics plots include the following:\n\nResiduals Plot: Shows the residuals over time to help identify any apparent trends or patterns that the model hasn’t captured. A random scatter of points around the zero line suggests that the model has successfully captured the underlying patterns in the data.\n\n\n\nACF Plot: Displays the autocorrelation of the residuals. For a well-fitted model, we expect no significant autocorrelation in the residuals; significant spikes might indicate a model misspecification.\nHistogram of Residuals: Aids in checking the normality of the residuals. The histogram should ideally resemble a normal distribution, indicating that the prediction errors are random and model assumptions hold.\n\nUsers can select the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nselected_model\nUsers can choose from a range of models, including SES, Holt, Damped Hold, Holt-Winters (additive and multiplicative), and ARIMA.\nDropdown List\n\n\ntraining_start, training_end\nUsers can specify training and holdout periods.\nInput fields.\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\nlibrary(fable)\nlibrary(feasts)\nlibrary(ggplot2)\n\ncreate_model_diagnostics &lt;- function(dataset_type,\n                                   selected_station,\n                                   selected_var,\n                                   selected_model,\n                                   training_start = \"2020-01-01\",\n                                   training_end = \"2023-12-31\") {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  data &lt;- switch(dataset_type,\n                \"rainfall\" = climate_rainfall_interpolated,\n                \"temperature\" = climate_temperature_interpolated,\n                \"windspeed\" = climate_windspeed_interpolated,\n                stop(\"Invalid dataset type\"))\n  \n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  \n  ts_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= training_start_date,\n           date &lt;= training_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(year_month = yearmonth(date)) %&gt;%\n    group_by(year_month) %&gt;%\n    summarise(Value = mean(Value, na.rm = TRUE),\n              .groups = 'drop') %&gt;%\n    as_tsibble(index = year_month) %&gt;%\n    fill_gaps()\n  \n  model_spec &lt;- switch(selected_model,\n                      \"SES\" = ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\")),\n                      \"Holt\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n                      \"Damped Holt\" = ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\")),\n                      \"Winter-Add\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\")),\n                      \"Winter-Mult\" = ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n                      \"ARIMA\" = ARIMA(Value),\n                      stop(\"Invalid model type\"))\n  \n  fit &lt;- ts_data %&gt;%\n    model(Model = model_spec) \n  \n  residuals_plot &lt;- fit %&gt;%\n    augment() %&gt;%\n    autoplot(.innov) +\n    labs(title = paste(\"Residuals Plot for\", selected_model, \"Model\"),\n         subtitle = paste(\"Station:\", selected_station, \"| Variable:\", selected_var),\n         y = \"Residuals\",\n         x = \"Time\") +\n    theme_light() +\n    theme(plot.title = element_text(size = 12, face = \"bold\"),\n          plot.subtitle = element_text(size = 10),\n          axis.title = element_text(size = 10),\n          axis.text = element_text(size = 9))\n  \n  acf_plot &lt;- fit %&gt;%\n    augment() %&gt;%\n    ACF(.innov) %&gt;%\n    autoplot() +\n    labs(title = \"ACF of Residuals\") +\n    theme_light()\n  \n  hist_plot &lt;- fit %&gt;%\n    augment() %&gt;%\n    ggplot(aes(x = .innov)) +\n    geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n    labs(title = \"Histogram of Residuals\",\n         x = \"Residuals\",\n         y = \"Count\") +\n    theme_light()\n  \n  combined_plot &lt;- gridExtra::grid.arrange(\n    residuals_plot, acf_plot, hist_plot,\n    ncol = 1,\n    heights = c(1, 1, 1)\n  )\n  \n  return(combined_plot)\n}\n\n\n\n\nExample Usage\n\nMean Temperature (SES)Total Rainfall (Winter-Additive)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#comparison",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#comparison",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.3 Comparison",
    "text": "5.3 Comparison\n\ncreate_station_comparison &lt;- function(dataset_type,\n                                    selected_stations,\n                                    selected_var,\n                                    selected_model,\n                                    training_start = \"2020-01-01\",\n                                    training_end = \"2023-12-31\",\n                                    holdout_end = \"2024-12-31\") {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  # Get the appropriate dataset\n  data &lt;- switch(dataset_type,\n                \"rainfall\" = climate_rainfall_interpolated,\n                \"temperature\" = climate_temperature_interpolated,\n                \"windspeed\" = climate_windspeed_interpolated,\n                stop(\"Invalid dataset type\"))\n  \n  # Prepare dates\n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  holdout_end_date &lt;- as.Date(holdout_end)\n  \n  # Calculate forecast horizon in months\n  horizon &lt;- ceiling(as.numeric(difftime(holdout_end_date, training_end_date, units = \"days\") / 30))\n  \n  # Prepare data\n  ts_data &lt;- data %&gt;%\n    filter(Station %in% selected_stations,\n           date &gt;= training_start_date,\n           date &lt;= holdout_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date),\n      Type = if_else(date &lt;= training_end_date, \"Training\", \"Hold-out\")\n    ) %&gt;%\n    group_by(year_month, Station, Type) %&gt;%\n    summarise(Value = mean(Value, na.rm = TRUE),\n              .groups = 'drop') %&gt;%\n    as_tsibble(key = Station, index = year_month) %&gt;%\n    fill_gaps()\n  \n  # Prepare training data\n  training_data &lt;- ts_data %&gt;%\n    filter(Type == \"Training\")\n  \n  # Fit the selected model\n  model_spec &lt;- switch(selected_model,\n                      \"SES\" = ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\")),\n                      \"Holt\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n                      \"Damped Holt\" = ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\")),\n                      \"Winter-Add\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\")),\n                      \"Winter-Mult\" = ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n                      \"ARIMA\" = ARIMA(Value),\n                      stop(\"Invalid model type\"))\n  \n  # Fit models and generate forecasts\n  fit_models &lt;- training_data %&gt;%\n    model(fcst = model_spec)\n  \n  forecasts &lt;- fit_models %&gt;%\n    forecast(h = horizon)\n  \n  # Create plot\n  forecast_plot &lt;- forecasts %&gt;%\n    autoplot(ts_data, level = NULL) +\n    geom_vline(xintercept = as.numeric(as.Date(training_end_date)), \n               linetype = \"dashed\", \n               color = \"grey50\") +\n    facet_wrap(~Station, scales = \"free_y\", ncol = 1) +  # Add faceting\n    labs(\n      title = paste(\"Forecast Comparison for\", selected_var),\n      subtitle = paste(\"Model:\", selected_model,\n                      \"| Training:\", format(training_start_date, \"%b %Y\"),\n                      \"to\", format(training_end_date, \"%b %Y\"),\n                      \"| Holdout:\", format(holdout_end_date, \"%b %Y\")),\n      x = \"Time\",\n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\")\n    ) +\n    theme_light() +\n    theme(\n      strip.text = element_text(face = \"bold\"),  # Station labels styling\n      strip.background = element_rect(fill = \"grey30\"),\n      panel.spacing = unit(1, \"lines\"),  # Space between facets\n      legend.position = \"right\",\n      plot.title = element_text(size = 12, face = \"bold\"),\n      plot.subtitle = element_text(size = 10),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9)\n    )\n  \n  plot_height &lt;- max(\n    # Minimum height per plot\n    length(selected_stations) * 250,  \n    # Scale with window height (approximately 80% of window)\n    length(selected_stations) * 300   \n  )\n\n  # Convert to plotly for interactivity\n  interactive_plot &lt;- ggplotly(forecast_plot, tooltip = c(\"x\", \"y\", \".model\")) %&gt;%\n    layout(\n      hoverlabel = list(bgcolor = \"white\"),\n      showlegend = TRUE,\n      legend = list(title = list(text = \"Type\")),\n      height = plot_height,  # Dynamic height\n      autosize = TRUE       # Enable auto-sizing\n    ) %&gt;%\n    # Ensure the plot is responsive\n    config(responsive = TRUE)\n  \n  return(interactive_plot)\n}\n\n\n# Example usage\ncomparison_plot &lt;- create_station_comparison(\n    dataset_type = \"temperature\",\n    selected_stations = c(\"Changi\", \"Admiralty\", \"Ang Mo Kio\"),\n    selected_var = \"Mean Temperature\",\n    selected_model = \"ARIMA\",\n    training_start = \"2020-01-01\",\n    training_end = \"2023-12-31\",\n    holdout_end = \"2024-12-31\"\n)\n\n# View plot\ncomparison_plot"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-model-diagnostics-assumptions",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-model-diagnostics-assumptions",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.1 Time-Series Forecasting: Model Diagnostics / Assumptions",
    "text": "5.1 Time-Series Forecasting: Model Diagnostics / Assumptions\nBefore users begin forecasting the various weather parameters, we created a create_model_diagnostics function to assist in validating the assumptions of the time-series models by visualising the residuals. These diagnostics are crucial for ensuring that the model fits the data appropriately and that the forecasts it produces are reliable. The function handles different types of weather data—rainfall, temperature, and windspeed—and supports several model types including Simple Exponential Smoothing (SES), Holt’s linear trend method, Holt-Winters seasonal methods, and ARIMA.\nThe diagnostics plots include the following:\n\nResiduals Plot: Shows the residuals over time to help identify any apparent trends or patterns that the model hasn’t captured. A random scatter of points around the zero line suggests that the model has successfully captured the underlying patterns in the data.\n\n\n\nACF Plot: Displays the autocorrelation of the residuals. For a well-fitted model, we expect no significant autocorrelation in the residuals; significant spikes might indicate a model misspecification.\nHistogram of Residuals: Aids in checking the normality of the residuals. The histogram should ideally resemble a normal distribution, indicating that the prediction errors are random and model assumptions hold.\n\nUsers can select the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nselected_model\nUsers can choose from a range of models, including SES, Holt, Damped Hold, Holt-Winters (additive and multiplicative), and ARIMA.\nDropdown List\n\n\ntraining_start, training_end\nUsers can specify training and holdout periods.\nInput fields.\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_model_diagnostics &lt;- function(dataset_type,\n                                   selected_station,\n                                   selected_var,\n                                   selected_model,\n                                   training_start = \"2020-01-01\",\n                                   training_end = \"2023-12-31\") {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  data &lt;- switch(dataset_type,\n                \"rainfall\" = climate_rainfall_interpolated,\n                \"temperature\" = climate_temperature_interpolated,\n                \"windspeed\" = climate_windspeed_interpolated,\n                stop(\"Invalid dataset type\"))\n  \n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  \n  ts_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= training_start_date,\n           date &lt;= training_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(year_month = yearmonth(date)) %&gt;%\n    group_by(year_month) %&gt;%\n    summarise(Value = mean(Value, na.rm = TRUE),\n              .groups = 'drop') %&gt;%\n    as_tsibble(index = year_month) %&gt;%\n    fill_gaps()\n  \n  model_spec &lt;- switch(selected_model,\n                      \"SES\" = ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\")),\n                      \"Holt\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n                      \"Damped Holt\" = ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\")),\n                      \"Winter-Add\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\")),\n                      \"Winter-Mult\" = ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n                      \"ARIMA\" = ARIMA(Value),\n                      stop(\"Invalid model type\"))\n  \n  fit &lt;- ts_data %&gt;%\n    model(Model = model_spec) \n  \n  residuals_plot &lt;- fit %&gt;%\n    augment() %&gt;%\n    autoplot(.innov) +\n    labs(title = paste(\"Residuals Plot for\", selected_model, \"Model\"),\n         subtitle = paste(\"Station:\", selected_station, \"| Variable:\", selected_var),\n         y = \"Residuals\",\n         x = \"Time\") +\n    theme_light() +\n    theme(plot.title = element_text(size = 12, face = \"bold\"),\n          plot.subtitle = element_text(size = 10),\n          axis.title = element_text(size = 10),\n          axis.text = element_text(size = 9))\n  \n  acf_plot &lt;- fit %&gt;%\n    augment() %&gt;%\n    ACF(.innov) %&gt;%\n    autoplot() +\n    labs(title = \"ACF of Residuals\") +\n    theme_light()\n  \n  hist_plot &lt;- fit %&gt;%\n    augment() %&gt;%\n    ggplot(aes(x = .innov)) +\n    geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n    labs(title = \"Histogram of Residuals\",\n         x = \"Residuals\",\n         y = \"Count\") +\n    theme_light()\n  \n  combined_plot &lt;- gridExtra::grid.arrange(\n    residuals_plot, acf_plot, hist_plot,\n    ncol = 1,\n    heights = c(1, 1, 1)\n  )\n  \n  return(combined_plot)\n}\n\n\n\n\nExample Usage\n\nMean Temperature (SES)Total Rainfall (Winter-Additive)"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-model-comparisons",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-model-comparisons",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.2 Time-Series Forecasting: Model Comparisons",
    "text": "5.2 Time-Series Forecasting: Model Comparisons\nAfter gaining an understanding of the time-series data via the EDA tools in Section 3.0, users can use the time-series forcasting tool to forecast weather parameters using various statistical models.\nFunction Objective\nThe goal of this functionality is to empower users to not only generate but also compare forecasts from multiple models, thereby identifying the most accurate predictive model for their specific context.\nGeneral Implementation Method\nWe developed a function, create_forecast, that users can interact with to perform weather forecasts based on historical data, using forecast() of fable. Users can select and interact with the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nmodels\nUsers can choose from a range of models, including SES, Holt, Damped Hold, Holt-Winters (additive and multiplicative), and ARIMA.\nCheckbox\n\n\ntraining_start, training_end, holdout_end\nUsers can specify training and holdout periods.\nInput fields\n\n\n\nThe function outputs an interactive plot that visually compares the forecasted data against actual data. Users can hover over the line chart for more details on the data value. A reference line was added in the plot to allow users to know when the holdout period starts. The function also outputs a table that displays forecasting accuracy metrics such as AIC, BIC, and AICc. These plots are generated using ggplotly.\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_forecast &lt;- function(dataset_type,\n                          selected_station,\n                          selected_var,\n                          training_start = \"2020-01-01\",\n                          training_end = \"2023-12-31\",\n                          holdout_end = \"2024-12-31\",\n                          models = c(\"SES\", \"Holt\", \"Damped Holt\", \"Winter-Add\", \"Winter-Mult\", \"ARIMA\")) {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  data &lt;- switch(dataset_type,\n                 \"rainfall\" = climate_rainfall_interpolated,\n                 \"temperature\" = climate_temperature_interpolated,\n                 \"windspeed\" = climate_windspeed_interpolated,\n                 stop(\"Invalid dataset type\"))\n  \n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  holdout_end_date &lt;- as.Date(holdout_end)\n  \n  horizon &lt;- length(seq(training_end_date, holdout_end_date, by = \"month\")) - 1\n  \n  message(\"Training period: \", training_start_date, \" to \", training_end_date)\n  message(\"Holdout period end: \", holdout_end_date)\n  message(\"Forecast horizon (months): \", horizon)\n\n  ts_data &lt;- data %&gt;%\n    filter(Station == selected_station,\n           date &gt;= training_start_date,\n           date &lt;= holdout_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date),\n      Type = if_else(date &lt;= training_end_date, \"Training\", \"Hold-out\")\n    ) %&gt;%\n    group_by(year_month) %&gt;%\n    summarise(\n      Value = mean(Value, na.rm = TRUE),\n      Type = first(Type),\n      .groups = 'drop'\n    ) %&gt;%\n    as_tsibble(index = year_month) %&gt;%\n    fill_gaps()\n  \n  training_data &lt;- ts_data %&gt;%\n    filter(Type == \"Training\")\n  \n  model_spec &lt;- list()\n  \n  if (\"SES\" %in% models) {\n    model_spec$SES &lt;- ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\"))\n  }\n  if (\"Holt\" %in% models) {\n    model_spec$Holt &lt;- ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  }\n  if (\"Damped Holt\" %in% models) {\n    model_spec$`Damped Holt` &lt;- ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\"))\n  }\n  if (\"Winter-Add\" %in% models) {\n    model_spec$`Winter-Add` &lt;- ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\"))\n  }\n  if (\"Winter-Mult\" %in% models) {\n    model_spec$`Winter-Mult` &lt;- ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\"))\n  }\n  if (\"ARIMA\" %in% models) {\n    model_spec$ARIMA &lt;- ARIMA(Value)\n  }\n  \n  fit_models &lt;- training_data %&gt;%\n    model(!!!model_spec)\n  \n  forecast_data &lt;- fit_models %&gt;%\n    forecast(h = paste(horizon, \"months\"))\n  \n  base_plot &lt;- forecast_data %&gt;%\n    autoplot(ts_data, level = NULL) +\n    theme_light() +\n    geom_vline(xintercept = yearmonth(training_end_date +days(1)), \n               linetype = \"dashed\", \n               color = \"grey50\") +\n    labs(\n      title = paste(\"Forecast for\", selected_var, \"at\", selected_station),\n      subtitle = paste(\"Training:\", format(training_start_date, \"%b %Y\"),\n                      \"to\", format(training_end_date, \"%b %Y\"),\n                      \"| Holdout:\", format(holdout_end_date, \"%b %Y\")),\n      x = \"Period\",\n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\")\n    ) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9)\n    )\n  \n  forecast_plot &lt;- ggplotly(base_plot, tooltip = c(\"x\", \"y\", \".model\")) %&gt;%\n    layout(\n      hoverlabel = list(bgcolor = \"white\"),\n      showlegend = TRUE,\n      legend = list(title = list(text = \"Models\"))\n    )\n  \n  for(i in 1:length(forecast_plot$x$data)) {\n    forecast_plot$x$data[[i]]$text &lt;- format(as.Date(forecast_plot$x$data[[i]]$x), \"%b %Y\")\n    forecast_plot$x$data[[i]]$hovertemplate &lt;- paste(\n      \"%{text}&lt;br&gt;\",\n      \"Value: %{y:.1f}\", units[[dataset_type]], \"&lt;br&gt;\",\n      \"Model: \", forecast_plot$x$data[[i]]$name, \"&lt;br&gt;\",\n      \"&lt;extra&gt;&lt;/extra&gt;\"\n    )\n  }\n  \n  accuracy_table &lt;- fit_models %&gt;%\n    accuracy() %&gt;%\n    select(.model, ME, RMSE, MAE, MPE, MAPE, MASE, RMSSE) %&gt;%\n    rename(\n      Model = .model,\n      \"Mean Error\" = ME,\n      \"Root Mean Square Error\" = RMSE,\n      \"Mean Absolute Error\" = MAE,\n      \"Mean Percentage Error\" = MPE,\n      \"Mean Absolute Percentage Error\" = MAPE,\n      \"Mean Absolute Scaled Error\" = MASE,\n      \"Root Mean Square Scaled Error\" = RMSSE\n    ) %&gt;%\n    kable(\n      caption = \"Model Accuracy Metrics\",\n      format = \"html\",\n      digits = 2\n    ) %&gt;%\n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n      full_width = FALSE\n    )\n  \n  return(list(\n    plot = forecast_plot,\n    table = accuracy_table\n  ))\n}\n\n\n\n\nExample Usage\n\nMean Temperature @ Changi (Training: 2020 - 2023, Forecast: 2024)Total Rain @ Changi (Training: 2020 - 2023, Forecast: 2024 - 2025)Mean Wind Speed @ Changi (Training: 2020 - 2022, Forecast: 2023)\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nSES\n-0.01\n0.64\n0.51\n-0.06\n1.83\n0.86\n0.89\n\n\nHolt\n0.00\n0.64\n0.51\n-0.02\n1.83\n0.86\n0.89\n\n\nWinter-Add\n-0.03\n0.38\n0.33\n-0.12\n1.19\n0.56\n0.54\n\n\nARIMA\n0.00\n0.40\n0.28\n-0.01\n1.01\n0.47\n0.55\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nWinter-Add\n0.06\n3.14\n2.31\n-283.72\n309.02\n0.63\n0.56\n\n\nWinter-Mult\n-0.62\n3.49\n2.39\n-616.32\n635.16\n0.65\n0.62\n\n\nARIMA\n0.00\n3.44\n2.47\n-390.88\n413.82\n0.67\n0.61\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Accuracy Metrics\n\n\nModel\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nSES\n-0.09\n1.63\n1.37\n-2.71\n16.53\n1.43\n1.29\n\n\nHolt\n0.01\n1.63\n1.36\n-1.55\n16.39\n1.43\n1.29\n\n\nARIMA\n0.00\n0.90\n0.58\n-0.11\n7.05\n0.60\n0.71"
  },
  {
    "objectID": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-forecasting-multiple-time-series-i.e.-stations",
    "href": "Take-Home Exercise/Take-Home_Ex03/Take-Home_Ex03.html#time-series-forecasting-forecasting-multiple-time-series-i.e.-stations",
    "title": "Take-Home Exercise 3.0: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "5.3 Time-Series Forecasting: Forecasting Multiple Time Series (i.e. Stations)",
    "text": "5.3 Time-Series Forecasting: Forecasting Multiple Time Series (i.e. Stations)\nWe developed the create_station_comparison function to enable the comparison of weather forecasts across different stations using a consistent statistical model. This functionality aims to identify how a specific model performs across various locations.\nFunction Objectives\nThe primary goal of this function is to provide users with the ability to generate and visualize weather forecasts for multiple stations simultaneously. This allows for an effective comparison of the model’s performance across different settings.\nGeneral Implementation Method\nThe function uses the forecast() method from the fable package to perform time series forecasting based on historical data. The results are visualized using ggplot2 and plotly for interactivity. A grey reference line was added to identify the start of the forecast period. The function also displays model accuracy metrics for each station.\nUsers can interact with the function through selecting the following parameters:\n\n\n\n\n\n\n\n\nParameter\nDescription\nUI For Parameter Selection\n\n\n\n\ndataset_type\nThe type of weather variable under study: rainfall, temperature or wind speed.\nDropdown List\n\n\nselected_station\nThe weather station from which the data is drawn.\nDropdown List\n\n\nselected_var\nThe type of metric for the selected weather variable. For example, for temperature, users can select mean temperature, max temperature or min temperature.\nDropdown List\n\n\nselected_model\nUsers can choose from a range of models, including SES, Holt, Damped Hold, Holt-Winters (additive and multiplicative), and ARIMA.\nDropdown List\n\n\ntraining_start, training_end, holdout_end\nUsers can specify training and holdout periods.\nInput fields\n\n\n\n\n\n\n\n\n\nExpand to See the Code Block on Function Implementation\n\n\n\n\n\n\ncreate_station_comparison &lt;- function(dataset_type,\n                                    selected_stations,\n                                    selected_var,\n                                    selected_model,\n                                    training_start = \"2020-01-01\",\n                                    training_end = \"2023-12-31\",\n                                    holdout_end = \"2024-12-31\") {\n  \n  var_mapping &lt;- list(\n    \"rainfall\" = list(\n      \"Total Rainfall\" = \"Daily Rainfall Total (mm)\",\n      \"Highest 30 Min Rainfall\" = \"Highest 30 Min Rainfall (mm)\",\n      \"Highest 60 Min Rainfall\" = \"Highest 60 Min Rainfall (mm)\",\n      \"Highest 120 Min Rainfall\" = \"Highest 120 Min Rainfall (mm)\"\n    ),\n    \"temperature\" = list(\n      \"Mean Temperature\" = \"Mean Temperature (°C)\",\n      \"Maximum Temperature\" = \"Maximum Temperature (°C)\",\n      \"Minimum Temperature\" = \"Minimum Temperature (°C)\"\n    ),\n    \"windspeed\" = list(\n      \"Mean Wind Speed\" = \"Mean Wind Speed (km/h)\",\n      \"Max Wind Speed\" = \"Max Wind Speed (km/h)\"\n    )\n  )\n  \n  units &lt;- list(\n    \"rainfall\" = \"mm\",\n    \"temperature\" = \"°C\",\n    \"windspeed\" = \"km/h\"\n  )\n  \n  data &lt;- switch(dataset_type,\n                \"rainfall\" = climate_rainfall_interpolated,\n                \"temperature\" = climate_temperature_interpolated,\n                \"windspeed\" = climate_windspeed_interpolated,\n                stop(\"Invalid dataset type\"))\n  \n  training_start_date &lt;- as.Date(training_start)\n  training_end_date &lt;- as.Date(training_end)\n  holdout_end_date &lt;- as.Date(holdout_end)\n  \n  horizon &lt;- ceiling(as.numeric(difftime(holdout_end_date, training_end_date, units = \"days\") / 30))\n  \n  ts_data &lt;- data %&gt;%\n    filter(Station %in% selected_stations,\n           date &gt;= training_start_date,\n           date &lt;= holdout_end_date) %&gt;%\n    select(date, Station, !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    rename(Value = !!sym(var_mapping[[dataset_type]][[selected_var]])) %&gt;%\n    mutate(\n      year_month = yearmonth(date),\n      Type = if_else(date &lt;= training_end_date, \"Training\", \"Hold-out\")\n    ) %&gt;%\n    group_by(year_month, Station, Type) %&gt;%\n    summarise(Value = mean(Value, na.rm = TRUE),\n              .groups = 'drop') %&gt;%\n    as_tsibble(key = Station, index = year_month) %&gt;%\n    fill_gaps()\n  \n  training_data &lt;- ts_data %&gt;%\n    filter(Type == \"Training\")\n  \n  model_spec &lt;- switch(selected_model,\n                      \"SES\" = ETS(Value ~ error(\"A\") + trend(\"N\") + season(\"N\")),\n                      \"Holt\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n                      \"Damped Holt\" = ETS(Value ~ error(\"A\") + trend(\"Ad\") + season(\"N\")),\n                      \"Winter-Add\" = ETS(Value ~ error(\"A\") + trend(\"A\") + season(\"A\")),\n                      \"Winter-Mult\" = ETS(Value ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n                      \"ARIMA\" = ARIMA(Value),\n                      stop(\"Invalid model type\"))\n  \n  fit_models &lt;- training_data %&gt;%\n    model(fcst = model_spec)\n  \n  forecasts &lt;- fit_models %&gt;%\n    forecast(h = horizon)\n\n  forecast_plot &lt;- forecasts %&gt;%\n    autoplot(ts_data, level = NULL) +\n    geom_vline(xintercept = as.numeric(as.Date(training_end_date)), \n               linetype = \"dashed\", \n               color = \"grey50\") +\n    facet_wrap(~Station, scales = \"free_y\", ncol = 1) + \n    labs(\n      title = paste(\"Forecast Comparison for\", selected_var),\n      subtitle = paste(\"Model:\", selected_model,\n                      \"| Training:\", format(training_start_date, \"%b %Y\"),\n                      \"to\", format(training_end_date, \"%b %Y\"),\n                      \"| Holdout:\", format(holdout_end_date, \"%b %Y\")),\n      x = \"Period\", \n      y = paste(selected_var, \"(\", units[[dataset_type]], \")\")\n    ) +\n    theme_light() +\n    theme(\n      strip.text = element_text(face = \"bold\"), \n      strip.background = element_rect(fill = \"grey30\"),\n      panel.spacing = unit(1, \"lines\"),  \n      legend.position = \"right\",\n      plot.title = element_text(size = 12, face = \"bold\"),\n      plot.subtitle = element_text(size = 10),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 9)\n    )\n  \n  plot_height &lt;- max(\n    length(selected_stations) * 150,  \n    length(selected_stations) * 200   \n  )\n  \n  interactive_plot &lt;- ggplotly(forecast_plot, tooltip = \"none\") %&gt;%\n    layout(\n      hoverlabel = list(bgcolor = \"white\"),\n      showlegend = TRUE,\n      legend = list(title = list(text = \"Type\")),\n      height = plot_height, \n      autosize = TRUE   \n    ) %&gt;%\n    config(responsive = TRUE)\n    \n  # Add custom hovertemplate for each trace\n  for(i in seq_along(interactive_plot$x$data)) {\n    interactive_plot$x$data[[i]]$text &lt;- format(as.Date(interactive_plot$x$data[[i]]$x), \"%b %Y\")\n    interactive_plot$x$data[[i]]$hovertemplate &lt;- paste(\n      \"%{text}&lt;br&gt;\",\n      paste(selected_var, \": %{y:.1f}\", units[[dataset_type]]),\n      \"&lt;extra&gt;&lt;/extra&gt;\"\n    )\n  }\n  \n  accuracy_table &lt;- fit_models %&gt;%\n    accuracy() %&gt;%\n    select(Station, ME, RMSE, MAE, MPE, MAPE, MASE, RMSSE) %&gt;%\n    rename(\n      \"Mean Error\" = ME,\n      \"Root Mean Square Error\" = RMSE,\n      \"Mean Absolute Error\" = MAE,\n      \"Mean Percentage Error\" = MPE,\n      \"Mean Absolute Percentage Error\" = MAPE,\n      \"Mean Absolute Scaled Error\" = MASE,\n      \"Root Mean Square Scaled Error\" = RMSSE\n    ) %&gt;%\n    kable(\n      caption = \"Model Accuracy Metrics by Station\",\n      format = \"html\",\n      digits = 2\n    ) %&gt;%\n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n      full_width = FALSE\n    )\n\n  # Return both plot and table\n  return(list(\n    plot = interactive_plot,\n    table = accuracy_table\n  ))\n}\n\n\n\n\nExample Usage\n\n\n\n\n\n\n\nModel Accuracy Metrics by Station\n\n\nStation\nMean Error\nRoot Mean Square Error\nMean Absolute Error\nMean Percentage Error\nMean Absolute Percentage Error\nMean Absolute Scaled Error\nRoot Mean Square Scaled Error\n\n\n\n\nAdmiralty\n-0.01\n0.48\n0.34\n-0.08\n1.24\n0.57\n0.64\n\n\nAng Mo Kio\n-0.02\n0.44\n0.33\n-0.09\n1.19\n0.54\n0.60\n\n\nChangi\n0.00\n0.40\n0.28\n-0.01\n1.01\n0.47\n0.55"
  }
]