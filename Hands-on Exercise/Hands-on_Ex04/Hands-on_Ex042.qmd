---
title: "Hands-on Exercise 4.2: Visual Statistics Analysis"
author: "Sheryl Ann Tan Yi-Shi"
date: "2025-02-01"
date-modified: "last-modified"
execute: 
  echo: true
  eval: true
  warning: false
  freeze: true
---

# 1.0 Getting Started

## 1.1 Installing and Loading the R Packages

In this exercise, `ggstatsplot` would be used to create visual graphics with rich statistical information.

```{r}
pacman::p_load(ggstatsplot, tidyverse)
```

## 1.2 Importing Data

The code chunk below uses `read_csv( )` to import *exam_data.csv* into R and save it into a tibble data frame:

```{r}
exam <- read_csv("data/Exam_data.csv")
```

# 2.0 Using `ggstatsplot` Package

## 2.1 One-Sample Test: `gghistostats()` Method

The code chunk below uses `gghistostats()` to build a visual of one-sample test on English scores.

```{r}
set.seed(1234)

gghistostats(
  data = exam,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores"
)
```

::: callout-note
-   `type` specifies the type of statistical analysis to be performed.

-   `test.value` refers to the value which the observed data (English scores) will be compared against.

-   Based on the plot above, the very negative log~e~(BF~01~) of -31.45 suggests a strong statistical evidence against the null hypothesis, implying that the mean English score is different from 60.
:::

## 2.2. Two-Sample Mean Test: `ggbetweenstats()`

The code chunk below uses `ggbetweenstats()` to build a bisual for two-sample mean test of Math scores by gender:

```{r}
ggbetweenstats(
  data = exam,
  x = GENDER, 
  y = MATHS,
  type = "np",
  messages = FALSE
)
```

::: callout-note
-   The Mann-Whitney U test is a non-parametric test, which is used to compare differences between two independent groups when the data cannot be assumed to be normally distributed.
-   Since the p-value is 0.91 (\>0.05) suggests that there is no statistically significant difference in Math scores between males and females. The high p-value implies that any observed differences in median scores is likely due to random chance rather than systematic differences between genders.
:::

## 2.3 One-Way ANOVA Test: `ggbetweenstats()` Method

```{r}
ggbetweenstats(
  data = exam,
  x = RACE, 
  y = ENGLISH,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

::: callout-note
-   The Welch ANOVA test is used to determine if there are statistically significant differences in the mean for \>3 groups. It is tailored for situations where the groups do not have equal variances ("heteroscedasticity").
-   Since the p-value is 1.71e-04 (\<0.05), the differences in English scores amongst racial groups is statistically significant.
:::

## 2.4 Significant Test of Correlation: `ggscatterstats()`

```{r}
ggscatterstats(
  data = exam,
  x = MATHS,
  y = ENGLISH,
  marginal = FALSE,
  )
```

::: callout-note
-   p-value of 1.70e-83 (\<0.05) suggests that the relationship between English and Maths is statistically significant.
-   Correlation Coefficient of 0.83 indicates a strong positive correlation between Math and English scores.
:::

## 2.5 Significant Test of Association

The code chunk below bins the Math scores into a 4-class variable:

```{r}
exam1 <- exam %>% 
  mutate(MATHS_bins = 
           cut(MATHS, 
               breaks = c(0,60,75,85,100))
)
```

The code chunk below uses `ggbarstats()` to build a visual for significant test of association:

```{r}
ggbarstats(exam1, 
           x = MATHS_bins, 
           y = GENDER)
```

# 3.0 Visualising Models

## 3.1 Getting Started

### 3.1.1 Installing and Loading the Required Libraries

```{r}
pacman::p_load(readxl, performance, parameters, see)
```

### 3.1.2 Importing Excel File

The code chunk below uses `read_xls()` to import the data worksheet of `ToyotaCorolla.xls` workbook into R:

```{r}
car_resale <- read_xls("data/ToyotaCorolla.xls", 
                       "data")
car_resale
```

## 3.2 Multiple Regression Model Using `lm()`

```{r}
model <- lm(Price ~ Age_08_04 + Mfg_Year + KM + 
              Weight + Guarantee_Period, data = car_resale)
model
```

## 3.3 Model Diagnostic: Checking for Multicollinearity

```{r}
check_collinearity(model)
```

```{r}
check_c <- check_collinearity(model)
plot(check_c)
```

Variables that are highly collinear with one or more other variables in the model. High VIF for these variables indicates that they share a substantial amount of information with other predictors, reducing the precision of the estimates of the model coefficients. Potential actions for high VIF variables include removing one of the highly collinear variables (either Age_08_04 or Mfg_Year) to reduce multicollinearity.

## 3.4 Model Diagnostics: Checking Normality Assumption

```{r}
model1 <- lm(Price ~ Age_08_04 + KM + 
              Weight + Guarantee_Period, data = car_resale)
```

```{r}
check_n <- check_normality(model1)
plot(check_n)
```

The assumption of normality of residuals is not fully met, as indicated by the outliers and the heavy tails.

## 3.5 Model Diagnostics: Check Model for Homogeneity of Variances

```{r}
check_h <- check_heteroscedasticity(model1)
plot(check_h)
```

## 3.6 Model Diagnostics: Complete Check

```{r}
check_model(model1)
```

## 3.7 Visualising Regression Parameters: `see` Methods

```{r}
plot(parameters(model1))
```

## 3.8 Visualising Regression Parameters: `ggcoefstats()` Methods

```{r}
ggcoefstats(model1, 
            output = "plot")
```
