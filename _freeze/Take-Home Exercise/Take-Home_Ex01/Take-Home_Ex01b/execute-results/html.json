{
  "hash": "c2e312e452047d4ecb3c955c54ce851d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-Home Exercise 1.0: Creating Data Visualisation Beyond Default\"\nauthor: \"Sheryl Ann Tan Yi-Shi\"\ndate: \"2025-02-15\"\ndate-modified: \"last-modified\"\nexecute: \n  echo: true\n  eval: true\n  warning: false\n  freeze: true\n---\n\n\n\n# 1.0 Introduction\n\n## 1.1 Background\n\nThe maritime sector is one of the most critical components of global trade, contributing significantly to economic growth and sustainability. Understanding ship performance, fuel efficiency, and operational cost factors are essential for improving decision-making and minimizing environmental impact.\n\n## 1.2 The Task\n\nThis exercise involves assuming the role of a graphical editor at an international media company that regularly publishes content on digital platforms. The company plans to release articles focused on one of the following themes:\n\n-   Heart Attack in Japan\n\n-   Ship Performance in the Gulf of Guinea\n\nFor the purposes of this take-home exercise, the theme, ***Ship Performance in the Gulf of Guinea***, was selected for the preparation of data visualizations for the article.\n\n## 1.3 About the Dataset\n\nThe dataset used in this exercise is sourced from Kaggle and can be accessed via this [link](https://www.kaggle.com/datasets/jeleeladekunlefijabi/ship-performance-clustering-dataset/data).\n\nThis dataset contains information on key operational metrics and attributes of various ship types in the Gulf of Guinea. The dataset includes numerical (e.g. `speed_over_ground_knots`, `revenue_per_voyage_usd`) and categorical variables (e.g. `ship_type`, `maintenance_status`) relevant to ship performance evaluation.\n\n# 2.0 Data Preparation\n\n## 2.1 Loading R Packages\n\nThe following R packages were used:\n\n| R Package   | Description |\n|-------------|-------------|\n| `dplyr`     |             |\n| `tidyverse` |             |\n|             |             |\n|             |             |\n|             |             |\n|             |             |\n|             |             |\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse, dplyr) \n```\n:::\n\n\n\n## 2.2 Importing the Data\n\nThe dataset was imported into R using the `read_csv` function from the `readr` package, which is part of the `tidyverse` suite.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nship_data <- read_csv(\"data/ship_performance_dataset.csv\")\n```\n:::\n\n\n\n## 2.3 Understanding the Data and Data Wrangling\n\nTo gain an initial understanding of the dataset, the following code chunk utilises the `glimpse` function from the `dplyr` package. This function provides a quick overview of the dataset's structure by displaying the first few entries of each column along with their data types.\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(ship_data)\n```\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,736\nColumns: 18\n$ Date                    <date> 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               <chr> \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              <chr> \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             <chr> \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      <chr> \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots <dbl> 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         <dbl> 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    <dbl> 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            <dbl> 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       <chr> \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       <dbl> 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    <dbl> 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  <dbl> 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   <dbl> 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   <dbl> 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   <dbl> 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     <dbl> 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage <dbl> 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n```\n\n\n:::\n:::\n\n\n:::\n\nBased on the output generated, the dataset consists of 2,736 rows and 18 columns.\n\n### 2.3.1 Duplicate and Missing Value Checks\n\n**Duplicate Data Check**\n\nAs duplicates can skew analysis results, identifying and removing them is crucial for subsequent analysis. Thus, a check for duplicate records was done using the `dplyr` package as shown in the code chunk below:\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nduplicate_count <- sum(duplicated(ship_data))\ncat(\"Number of duplicate rows:\", duplicate_count, \"\\n\")\n\nif (duplicate_count > 0) {\n  duplicate_rows <- ship_data[duplicated(ship_data), ]\n  print(duplicate_rows)\n} else {\n  cat(\"No duplicate rows found.\\n\")\n}\n```\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of duplicate rows: 0 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNo duplicate rows found.\n```\n\n\n:::\n:::\n\n\n:::\n\nBased on the output, there are no duplicate records in the dataset\n\n**Missing Value Check**\n\nMissing values in a dataset can introduce bias and affect the accuracy of subsequent analysis, potentially leading to misleading results. The following code chunk counts the number of missing values (`NA)` in the dataset:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmissing_value_count <- sum(rowSums(is.na(ship_data)) > 0)\ncat(\"Number of rows with missing values:\", missing_value_count, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of rows with missing values: 0 \n```\n\n\n:::\n:::\n\n\n\nAAlthough the output indicates that there are no missing values (`NA`) in the dataset, a further assessment of categorical columns is required to check for unrecorded data. The following code chunk generates the unique values for each categorical column in the dataset:\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncategorical_columns <- names(ship_data)[sapply(ship_data, is.character)]\n\nfor (col in categorical_columns) {\n  cat(\"\\nUnique values in\", col, \":\\n\")\n  print(unique(ship_data[[col]]))\n}\n```\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nUnique values in Ship_Type :\n[1] \"Container Ship\" \"Fish Carrier\"   \"Bulk Carrier\"   \"None\"          \n[5] \"Tanker\"        \n\nUnique values in Route_Type :\n[1] \"None\"         \"Short-haul\"   \"Long-haul\"    \"Transoceanic\" \"Coastal\"     \n\nUnique values in Engine_Type :\n[1] \"Heavy Fuel Oil (HFO)\" \"Steam Turbine\"        \"Diesel\"              \n[4] \"None\"                \n\nUnique values in Maintenance_Status :\n[1] \"Critical\" \"Good\"     \"Fair\"     \"None\"    \n\nUnique values in Weather_Condition :\n[1] \"Moderate\" \"Rough\"    \"Calm\"     \"None\"    \n```\n\n\n:::\n:::\n\n\n:::\n\nFrom the results, we observe that some categorical columns contain the value ***None***, which may indicate missing or unrecorded data rather than an actual category. To quantify this, the following code counts the occurrences of ***None*** values in the affected categorical columns:\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify categorical columns\ncategorical_columns <- names(ship_data)[sapply(ship_data, is.character)]\n\n# Create a dataframe to store missing counts\nmissing_categorical_counts <- data.frame(Column = categorical_columns, \n                                         Missing_Count = sapply(ship_data[categorical_columns], function(x) sum(is.na(x) | x == \"None\")))\n```\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n                               Column Missing_Count\nShip_Type                   Ship_Type           136\nRoute_Type                 Route_Type           136\nEngine_Type               Engine_Type           136\nMaintenance_Status Maintenance_Status           136\nWeather_Condition   Weather_Condition           136\n```\n\n\n:::\n:::\n\n\n:::\n\nBased on the results obtained above, each affected column contains 136 ***None*** values, representing approximately 5% of the total observations in the dataset. Since the percentage of missing values is relatively low, records containing ***None*** will be excluded from subsequent analysis.\n\n### 2.3.2 Creating New Variables\n\n**Profit (USD)**\n\nProfit is a key financial metric that reflects the overall economic performance of a ship's operation. To incorporate profit into the dataset, a new variable was created based on the difference between `Revenue_per_Voyage_USD` and `Operational_Cost_USD`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nship_data$Profit_USD <- ship_data$Revenue_per_Voyage_USD - ship_data$Operational_Cost_USD\n\n# Summary of the new Profit variable\nsummary(ship_data$Profit_USD)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-444584   40885  262716  266219  492216  977168 \n```\n\n\n:::\n:::\n\n\n\nBased on the summary statistics of the newly created `Profit_USD`, we can observe that some of the ships are loss-making.\n\n**Profit per Cargo Weight (USD per Ton)**\n\nThis metric evaluates how efficiently a ship generates profit relative to the amount of cargo it transports. It helps in understanding which ships or routes are most profitable in terms of cargo handling.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Avoid division by zero errors\nship_data$Profit_per_Cargo_ton <- ifelse(ship_data$Cargo_Weight_tons != 0, \n                                         ship_data$Profit_USD / ship_data$Cargo_Weight_tons, \n                                         NA)\n\n# Summary of the new variable\nsummary(ship_data$Profit_per_Cargo_ton)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-5656.77    38.84   251.55   475.64   553.79 13435.92 \n```\n\n\n:::\n:::\n\n\n\n### 2.3.3 Data Type Conversion\n\nThe data table below shows the current data type of each of the 19 columns, along with the proposed data type for conversion. To improve data handling and ensure accurate analysis, the proposed data type for each column should align with the nature of the data.\n\n| Variable                | Current Data Type | Proposed Data Type |\n|-------------------------|-------------------|--------------------|\n| Date                    | Date              | Date               |\n| Ship_Type               | Character         | Factor             |\n| Route_Type              | Character         | Factor             |\n| Engine_Type             | Character         | Factor             |\n| Maintenance_Status      | Character         | Ordered Factor     |\n| Speed_Over_Ground_knots | Double            | Double             |\n| Engine_Power_kW         | Double            | Double             |\n| Distance_Traveled_nm    | Double            | Double             |\n| Draft_meters            | Double            | Double             |\n| Weather_Condition       | Character         | Ordered Factor     |\n| Cargo_Weight_tons       | Double            | Double             |\n| Operational_Cost_USD    | Double            | Double             |\n| Revenue_per_Voyage_USD  | Double            | Double             |\n| Turnaround_Time_hours   | Double            | Double             |\n| Efficiency_nm_per_kWh   | Double            | Double             |\n| Seasonal_Impact_Score   | Double            | Double             |\n| Weekly_Voyage_Count     | Double            | Integer            |\n| Average_Load_Percentage | Double            | Double             |\n| Profit_USD              | Double            | Double             |\n| Profit_per_Cargo_ton    | Double            | Double             |\n\nThe following code chunk is used to implement the proposed data type conversions:\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nship_data$Ship_Type <- as.factor(ship_data$Ship_Type)\nship_data$Route_Type <- as.factor(ship_data$Route_Type)\nship_data$Engine_Type <- as.factor(ship_data$Engine_Type)\n\nship_data$Maintenance_Status <- factor(ship_data$Maintenance_Status, \n                                       levels = c(\"Critical\", \"Fair\", \"Good\",\"None\"), \n                                       ordered = TRUE)\n\nship_data$Weather_Condition <- factor(ship_data$Weather_Condition, \n                                      levels = c(\"Calm\", \"Moderate\", \"Rough\", \"Severe\",\"None\"), \n                                      ordered = TRUE)\n\nship_data$Weekly_Voyage_Count <- as.integer(ship_data$Weekly_Voyage_Count)\n```\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,736\nColumns: 20\n$ Date                    <date> 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               <fct> Container Ship, Fish Carrier, Container Ship, …\n$ Route_Type              <fct> None, Short-haul, Long-haul, Transoceanic, Tra…\n$ Engine_Type             <fct> Heavy Fuel Oil (HFO), Steam Turbine, Diesel, S…\n$ Maintenance_Status      <ord> Critical, Good, Fair, Fair, Fair, Fair, Critic…\n$ Speed_Over_Ground_knots <dbl> 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         <dbl> 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    <dbl> 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            <dbl> 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       <ord> Moderate, Rough, Moderate, Moderate, Moderate,…\n$ Cargo_Weight_tons       <dbl> 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    <dbl> 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  <dbl> 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   <dbl> 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   <dbl> 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   <dbl> 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     <int> 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage <dbl> 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n$ Profit_USD              <dbl> -191649.081, 400377.787, -54524.657, -173798.2…\n$ Profit_per_Cargo_ton    <dbl> -97.829164, 2465.460747, -306.247902, -100.034…\n```\n\n\n:::\n:::\n\n\n:::\n\n### 2.3.1 Filtering of Columns\n\nFrom the output generated in Section 2.3, the dataset includes 15 columns labelled from `Extra_Column_1` to `Extra_Column_15` . These columns do not have clear descriptions nor apparent relevance to the study. Hence, in order to streamline the dataset, these columns were removed. This would allow us to focus on variables that would be more relevant to the analysis.\n\nAfter filtering out the irrelevant columns, the dataset now comprises of 17 columns as shown in the *Results* tab below:\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n\n:::\n\n\n:::\n\n### 2.3.3 Recoding Variables\n\n**Recoding BMI**\n\nRaw BMI values alone do not provide an intuitive interpretation of body weight, making interpretation difficult for both technical and non-technical audiences. As such, there is a need to recode the BMI values into meaningful groups.\n\nIn this exercise, the BMI values were categorised into four distinct groups in accordance to the World Health Organisation's International BMI Classification. Applying this classification would simplify the interpretation of BMI values, allowing readers of the article to easily determine whether an individual falls within a healthy range or an at-risk category, and the potential relationship with heart attack incidence.\n\nThe categories used are as follows:\n\n| Classification | BMI         |\n|----------------|-------------|\n| Underweight    | \\<18.5      |\n| Normal Weight  | 18.5 - 24.9 |\n| Pre-Obese      | 25.0 - 29.9 |\n| Obese          | \\>=30       |\n\nThe `cut` function in R was employed to implement this classification. This function assigns each BMI value to one of the specified categories, creating a new column, `BMI_Category`, in the dataset.\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Categorizing BMI according to WHO standards\n```\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n\n:::\n\n\n:::\n\n**Recoding Age**\n\nIn epidemiological studies, age is often grouped into categories rather than analysed as a continuous variable. While age is a key determinant of health risks, raw age variables do not immediately provide clear insights. Binning age into meaningful categories simplifies interpretation, making it easier to identify trends across different life stages.\n\nThe `age` variable was binned into the following categories:\n\n| Classification     | Age Range |\n|--------------------|-----------|\n| Youth              | 0 - 17    |\n| Young Adult        | 18 - 35   |\n| Middle-Aged Adults | 36 - 64   |\n| Elderly            | \\>= 65    |\n\nThe code chunk below uses the `cut()` function in R to categorise the `age` variable into the aforementioned groupings. A new variable called `age_group` would be created:\n\n::: panel-tabset\n#### Code\n\n\n\n::: {.cell}\n\n:::\n\n\n\n#### Results\n\n\n\n::: {.cell}\n\n:::\n\n\n:::\n\n### \n\nOhira, T., Eguchi, E., Hayashi, F., Kinuta, M., & Imano, H. (2023). Epidemiology of cardiovascular disease in Japan: An overview study. *Journal of Cardiology, 81*(5), 379-387. https://doi.org/10.1016/j.jjcc.2023.07.007\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}